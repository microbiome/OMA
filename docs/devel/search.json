[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Orchestrating Microbiome Analysis",
    "section": "",
    "text": "Package: OMAAuthors: - Leo Lahti [aut] - Tuomas Borman [aut, cre] - Felix GM Ernst [aut] - and others (see the full list of contributors) [ctb]Compiled: 2023-12-12Package version: 0.98.16R version: R Under development (unstable) (2023-11-22 r85609)BioC version: 3.19License: CC BY-NC-SA 4.0\n\n\n\n\n\n\nWelcome\n\n\n\n\n\n\nImportant!\n\n\n\nThis is a development version of the Orchestrating Microbiome Analysis with Bioconductor (Lahti et al. 2021) book from the the miaverse.\n\n\n\nLahti, Leo, Sudarshan Shetty, Felix M Ernst, et al. 2021. Orchestrating Microbiome Analysis with Bioconductor [Beta Version]. microbiome.github.io/oma/.\nYou are reading the online book, Orchestrating Microbiome Analysis with Bioconductor (Lahti et al. 2021), where we walk through common strategies and workflows in microbiome data science.\nThe book shows through concrete examples how you can take advantage of the latest developments in R/Bioconductor for the manipulation, analysis, and reproducible reporting of hierarchical and heterogeneous microbiome profiling data sets. The book was borne out of necessity, while updating microbiome analysis tools to work with Bioconductor classes that provide support for multi-modal data collections. Many of these techniques are generic and widely applicable in other contexts as well.\nThis work has been heavily influenced by other similar resources, in particular the Orchestrating Single-Cell Analysis with Bioconductor (Amezquita et al. 2020), phyloseq tutorials (Callahan et al. 2016) and microbiome tutorials (Shetty and Lahti 2019). This book extends these resources to teach the grammar of Bioconductor workflows in the context of microbiome data science. As such, it supports the adoption of general skills in the analysis of large, hierarchical, and multi-modal data collections. We focus on microbiome analysis tools, including entirely new, partially updated as well as previously established methods.\n\nAmezquita, Robert, Aaron Lun, Stephanie Hicks, and Raphael Gottardo. 2020. Orchestrating Single-Cell Analysis with Bioconductor. Bioconductor. https://bioconductor.org/books/release/OSCA/.\n\nCallahan, Ben J., Kris Sankaran, Julia A. Fukuyama, Paul J. McMurdie, and Susan P. Holmes. 2016. ‚ÄúBioconductor Workflow for Microbiome Data Analysis: From Raw Reads to Community Analyses [Version 2; Peer Review: 3 Approved].‚Äù F1000Research 5: 1492. https://doi.org/10.12688/f1000research.8986.2.\n\nShetty, Sudarshan, and Leo Lahti. 2019. ‚ÄúMicrobiome Data Science.‚Äù Journal of Biosciences 44: 115. https://doi.org/10.1007/s12038-019-9930-2.\nThis online resource and its associated ecosystem of microbiome data science tools are a result of a community-driven development process, and welcoming new contributors. Several individuals have contributed methods, workflows and improvements as acknowledged in the Introduction. You can find more information on how to find us online and join the developer community through the project homepage at microbiome.github.io. This online resource has been written in RMarkdown with the bookdown R package. The material is free to use with the Creative Commons Attribution-NonCommercial 3.0 License.\nDocker image\nA Docker image built from this repository is available here:\nüëâ ghcr.io/microbiome/oma üê≥\n\n\n\n\n\n\nGet started now üéâ\n\n\n\nYou can get access to all the packages used in this book in &lt; 1 minute, using this command in a terminal:\n\n\n\nbash\n\ndocker run -it ghcr.io/microbiome/oma:devel R\n\n\n\n\nRStudio Server\nAn RStudio Server instance can be initiated from the Docker image as follows:\n\n\n\nbash\n\ndocker run \\\n    --volume &lt;local_folder&gt;:&lt;destination_folder&gt; \\\n    -e PASSWORD=OHCA \\\n    -p 8787:8787 \\\n    ghcr.io/microbiome/oma:devel\n\n\nThe initiated RStudio Server instance will be available at https://localhost:8787.\nSession info\n\n\n\n\n\n\nClick to expand üëá\n\n\n\n\n\n\nsessioninfo::session_info(\n    installed.packages()[,\"Package\"], \n    include_base = TRUE\n)\n##  ‚îÄ Session info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n##   setting  value\n##   version  R Under development (unstable) (2023-11-22 r85609)\n##   os       Ubuntu 22.04.3 LTS\n##   system   x86_64, linux-gnu\n##   ui       X11\n##   language (EN)\n##   collate  C\n##   ctype    en_US.UTF-8\n##   tz       Etc/UTC\n##   date     2023-12-12\n##   pandoc   3.1.1 @ /usr/local/bin/ (via rmarkdown)\n##  \n##  ‚îÄ Packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n##   package                  * version    date (UTC) lib source\n##   abind                      1.4-5      2016-07-21 [2] CRAN (R 4.4.0)\n##   additivityTests            1.1-4.1    2022-06-24 [2] CRAN (R 4.4.0)\n##   ade4                       1.7-22     2023-02-06 [2] CRAN (R 4.4.0)\n##   ALDEx2                     1.35.0     2023-10-24 [2] Bioconductor\n##   ANCOMBC                    2.5.0      2023-10-24 [2] Bioconductor\n##   AnnotationDbi              1.65.2     2023-11-03 [2] Bioconductor\n##   AnnotationHub              3.11.1     2023-12-11 [2] Bioconductor 3.19 (R 4.4.0)\n##   ape                        5.7-1      2023-03-13 [2] CRAN (R 4.4.0)\n##   aplot                      0.2.2      2023-10-06 [2] CRAN (R 4.4.0)\n##   arrayhelpers               1.1-0      2020-02-04 [2] CRAN (R 4.4.0)\n##   askpass                    1.2.0      2023-09-03 [2] CRAN (R 4.4.0)\n##   available                  1.1.0      2022-07-10 [2] CRAN (R 4.4.0)\n##   backports                  1.4.1      2021-12-13 [2] CRAN (R 4.4.0)\n##   base                     * 4.4.0      2023-11-26 [3] local\n##   base64enc                  0.1-3      2015-07-28 [2] CRAN (R 4.4.0)\n##   beachmat                   2.19.0     2023-10-24 [2] Bioconductor\n##   beeswarm                   0.4.0      2021-06-01 [2] CRAN (R 4.4.0)\n##   BH                         1.81.0-1   2023-01-22 [2] CRAN (R 4.4.0)\n##   biclust                    2.0.3.1    2023-05-19 [2] CRAN (R 4.4.0)\n##   biglm                      0.9-2.1    2020-11-27 [2] CRAN (R 4.4.0)\n##   Biobase                    2.63.0     2023-10-24 [2] Bioconductor\n##   BiocBaseUtils              1.5.0      2023-10-24 [2] Bioconductor\n##   BiocBook                   1.1.1      2023-11-17 [2] Bioconductor 3.19 (R 4.4.0)\n##   BiocFileCache              2.11.1     2023-10-26 [2] Bioconductor\n##   BiocGenerics               0.49.1     2023-11-01 [2] Bioconductor\n##   BiocManager                1.30.22    2023-08-08 [2] CRAN (R 4.4.0)\n##   BiocNeighbors              1.21.1     2023-11-30 [2] Bioconductor 3.19 (R 4.4.0)\n##   BiocParallel               1.37.0     2023-10-24 [2] Bioconductor\n##   BiocSingular               1.19.0     2023-10-24 [2] Bioconductor\n##   BiocStyle                  2.31.0     2023-10-24 [2] Bioconductor\n##   BiocVersion                3.19.1     2023-10-26 [2] Bioconductor\n##   biomformat                 1.31.0     2023-10-24 [2] Bioconductor\n##   Biostrings                 2.71.1     2023-10-25 [2] Bioconductor\n##   bit                        4.0.5      2022-11-15 [2] CRAN (R 4.4.0)\n##   bit64                      4.0.5      2020-08-30 [2] CRAN (R 4.4.0)\n##   bitops                     1.0-7      2021-04-24 [2] CRAN (R 4.4.0)\n##   blob                       1.2.4      2023-03-17 [2] CRAN (R 4.4.0)\n##   bluster                    1.13.0     2023-10-24 [2] Bioconductor\n##   bookdown                   0.37       2023-12-01 [2] CRAN (R 4.4.0)\n##   boot                       1.3-28.1   2022-11-22 [3] CRAN (R 4.4.0)\n##   brew                       1.0-8      2022-09-29 [2] CRAN (R 4.4.0)\n##   brio                       1.1.4      2023-12-10 [2] CRAN (R 4.4.0)\n##   broom                      1.0.5      2023-06-09 [2] CRAN (R 4.4.0)\n##   bslib                      0.6.1      2023-11-28 [2] CRAN (R 4.4.0)\n##   ca                         0.71.1     2020-01-24 [2] CRAN (R 4.4.0)\n##   cachem                     1.0.8      2023-05-01 [2] CRAN (R 4.4.0)\n##   Cairo                      1.6-2      2023-11-28 [2] CRAN (R 4.4.0)\n##   callr                      3.7.3      2022-11-02 [2] CRAN (R 4.4.0)\n##   car                        3.1-2      2023-03-30 [2] CRAN (R 4.4.0)\n##   carData                    3.0-5      2022-01-06 [2] CRAN (R 4.4.0)\n##   caret                      6.0-94     2023-03-21 [2] CRAN (R 4.4.0)\n##   caTools                    1.18.2     2021-03-28 [2] CRAN (R 4.4.0)\n##   cellranger                 1.1.0      2016-07-27 [2] CRAN (R 4.4.0)\n##   checkmate                  2.3.1      2023-12-04 [2] CRAN (R 4.4.0)\n##   chemometrics               1.4.4      2023-08-25 [2] CRAN (R 4.4.0)\n##   circlize                   0.4.15     2022-05-10 [2] CRAN (R 4.4.0)\n##   class                      7.3-22     2023-05-03 [3] CRAN (R 4.4.0)\n##   cli                        3.6.2      2023-12-11 [2] CRAN (R 4.4.0)\n##   clipr                      0.8.0      2022-02-22 [2] CRAN (R 4.4.0)\n##   clisymbols                 1.2.0      2017-05-21 [2] CRAN (R 4.4.0)\n##   clock                      0.7.0      2023-05-15 [2] CRAN (R 4.4.0)\n##   clue                       0.3-65     2023-09-23 [2] CRAN (R 4.4.0)\n##   cluster                    2.1.6      2023-12-01 [3] CRAN (R 4.4.0)\n##   cobiclust                  0.1.0      2018-10-15 [2] CRAN (R 4.4.0)\n##   coda                       0.19-4     2020-09-30 [2] CRAN (R 4.4.0)\n##   CodeDepends                0.6.5      2018-07-17 [2] CRAN (R 4.4.0)\n##   codetools                  0.2-19     2023-02-01 [3] CRAN (R 4.4.0)\n##   colorspace                 2.1-0      2023-01-23 [2] CRAN (R 4.4.0)\n##   commonmark                 1.9.0      2023-03-17 [2] CRAN (R 4.4.0)\n##   compiler                   4.4.0      2023-11-26 [3] local\n##   ComplexHeatmap             2.19.0     2023-10-24 [2] Bioconductor\n##   conflicted                 1.2.0      2023-02-01 [2] CRAN (R 4.4.0)\n##   corpcor                    1.6.10     2021-09-16 [2] CRAN (R 4.4.0)\n##   corrplot                   0.92       2021-11-18 [2] CRAN (R 4.4.0)\n##   cowplot                    1.1.1      2020-12-30 [2] CRAN (R 4.4.0)\n##   cplm                       0.7-11     2023-04-18 [2] CRAN (R 4.4.0)\n##   cpp11                      0.4.7      2023-12-02 [2] CRAN (R 4.4.0)\n##   crayon                     1.5.2      2022-09-29 [2] CRAN (R 4.4.0)\n##   credentials                2.0.1      2023-09-06 [2] CRAN (R 4.4.0)\n##   crosstalk                  1.2.1      2023-11-23 [2] CRAN (R 4.4.0)\n##   curatedMetagenomicData     3.11.0     2023-10-31 [2] Bioconductor\n##   curl                       5.2.0      2023-12-08 [2] CRAN (R 4.4.0)\n##   CVXR                       1.0-11     2022-10-30 [2] CRAN (R 4.4.0)\n##   data.table                 1.14.10    2023-12-08 [2] CRAN (R 4.4.0)\n##   datasets                 * 4.4.0      2023-11-26 [3] local\n##   DBI                        1.1.3      2022-06-18 [2] CRAN (R 4.4.0)\n##   dbplyr                     2.4.0      2023-10-26 [2] CRAN (R 4.4.0)\n##   DECIPHER                   2.31.0     2023-10-24 [2] Bioconductor\n##   decontam                   1.23.0     2023-10-24 [2] Bioconductor\n##   DelayedArray               0.29.0     2023-10-24 [2] Bioconductor\n##   DelayedMatrixStats         1.25.1     2023-11-09 [2] Bioconductor\n##   deldir                     2.0-2      2023-11-23 [2] CRAN (R 4.4.0)\n##   dendextend                 1.17.1     2023-03-25 [2] CRAN (R 4.4.0)\n##   DEoptimR                   1.1-3      2023-10-07 [2] CRAN (R 4.4.0)\n##   desc                       1.4.3      2023-12-10 [2] CRAN (R 4.4.0)\n##   DescTools                  0.99.52    2023-12-01 [2] CRAN (R 4.4.0)\n##   devtools                   2.4.5      2022-10-11 [2] CRAN (R 4.4.0)\n##   diagram                    1.6.5      2020-09-30 [2] CRAN (R 4.4.0)\n##   diffobj                    0.3.5      2021-10-05 [2] CRAN (R 4.4.0)\n##   digest                     0.6.33     2023-07-07 [2] CRAN (R 4.4.0)\n##   dir.expiry                 1.11.0     2023-10-24 [2] Bioconductor\n##   directlabels               2023.8.25  2023-09-01 [2] CRAN (R 4.4.0)\n##   DirichletMultinomial       1.45.0     2023-10-24 [2] Bioconductor\n##   dirmult                    0.1.3-5    2022-03-21 [2] CRAN (R 4.4.0)\n##   distributional             0.3.2      2023-03-22 [2] CRAN (R 4.4.0)\n##   docopt                     0.7.1      2020-06-24 [2] CRAN (R 4.4.0)\n##   doParallel                 1.0.17     2022-02-07 [2] CRAN (R 4.4.0)\n##   doRNG                      1.8.6      2023-01-16 [2] CRAN (R 4.4.0)\n##   downlit                    0.4.3      2023-06-29 [2] CRAN (R 4.4.0)\n##   dplyr                      1.1.4      2023-11-17 [2] CRAN (R 4.4.0)\n##   dqrng                      0.3.2      2023-11-29 [2] CRAN (R 4.4.0)\n##   DT                         0.31       2023-12-09 [2] CRAN (R 4.4.0)\n##   dtplyr                     1.3.1      2023-03-22 [2] CRAN (R 4.4.0)\n##   e1071                      1.7-14     2023-12-06 [2] CRAN (R 4.4.0)\n##   ECOSolveR                  0.5.5      2023-05-15 [2] CRAN (R 4.4.0)\n##   edgeR                      4.1.3      2023-12-10 [2] Bioconductor 3.19 (R 4.4.0)\n##   ellipsis                   0.3.2      2021-04-29 [2] CRAN (R 4.4.0)\n##   energy                     1.7-11     2022-12-22 [2] CRAN (R 4.4.0)\n##   evaluate                   0.23       2023-11-01 [2] CRAN (R 4.4.0)\n##   Exact                      3.2        2022-09-25 [2] CRAN (R 4.4.0)\n##   ExperimentHub              2.11.1     2023-12-11 [2] Bioconductor 3.19 (R 4.4.0)\n##   expm                       0.999-8    2023-11-29 [2] CRAN (R 4.4.0)\n##   fansi                      1.0.6      2023-12-08 [2] CRAN (R 4.4.0)\n##   farver                     2.1.1      2022-07-06 [2] CRAN (R 4.4.0)\n##   fastmap                    1.1.1      2023-02-24 [2] CRAN (R 4.4.0)\n##   fBasics                    4032.96    2023-11-03 [2] CRAN (R 4.4.0)\n##   fido                       1.0.4      2023-03-24 [2] CRAN (R 4.4.0)\n##   filelock                   1.0.3      2023-12-11 [2] CRAN (R 4.4.0)\n##   flexclust                  1.4-1      2022-04-08 [2] CRAN (R 4.4.0)\n##   FNN                        1.1.3.2    2023-03-20 [2] CRAN (R 4.4.0)\n##   fontawesome                0.5.2      2023-08-19 [2] CRAN (R 4.4.0)\n##   forcats                    1.0.0      2023-01-29 [2] CRAN (R 4.4.0)\n##   foreach                    1.5.2      2022-02-02 [2] CRAN (R 4.4.0)\n##   foreign                    0.8-86     2023-11-28 [3] CRAN (R 4.4.0)\n##   formatR                    1.14       2023-01-17 [2] CRAN (R 4.4.0)\n##   Formula                    1.2-5      2023-02-24 [2] CRAN (R 4.4.0)\n##   fs                         1.6.3      2023-07-20 [2] CRAN (R 4.4.0)\n##   futile.logger              1.4.3      2016-07-10 [2] CRAN (R 4.4.0)\n##   futile.options             1.0.1      2018-04-20 [2] CRAN (R 4.4.0)\n##   future                     1.33.0     2023-07-01 [2] CRAN (R 4.4.0)\n##   future.apply               1.11.0     2023-05-21 [2] CRAN (R 4.4.0)\n##   gargle                     1.5.2      2023-07-20 [2] CRAN (R 4.4.0)\n##   gclus                      1.3.2      2019-01-07 [2] CRAN (R 4.4.0)\n##   generics                   0.1.3      2022-07-05 [2] CRAN (R 4.4.0)\n##   GenomeInfoDb               1.39.1     2023-11-08 [2] Bioconductor\n##   GenomeInfoDbData           1.2.11     2023-12-12 [2] Bioconductor\n##   GenomicRanges              1.55.1     2023-10-29 [2] Bioconductor\n##   gert                       2.0.1      2023-12-04 [2] CRAN (R 4.4.0)\n##   getopt                     1.20.4     2023-10-01 [2] CRAN (R 4.4.0)\n##   GetoptLong                 1.0.5      2020-12-15 [2] CRAN (R 4.4.0)\n##   ggbeeswarm                 0.7.2      2023-04-29 [2] CRAN (R 4.4.0)\n##   ggdist                     3.3.1      2023-11-27 [2] CRAN (R 4.4.0)\n##   ggforce                    0.4.1      2022-10-04 [2] CRAN (R 4.4.0)\n##   ggfun                      0.1.3      2023-09-15 [2] CRAN (R 4.4.0)\n##   ggnewscale                 0.4.9      2023-05-25 [2] CRAN (R 4.4.0)\n##   ggplot2                    3.4.4      2023-10-12 [2] CRAN (R 4.4.0)\n##   ggplotify                  0.1.2      2023-08-09 [2] CRAN (R 4.4.0)\n##   ggpubr                     0.6.0      2023-02-10 [2] CRAN (R 4.4.0)\n##   ggraph                     2.1.0      2022-10-09 [2] CRAN (R 4.4.0)\n##   ggrastr                    1.0.2      2023-06-01 [2] CRAN (R 4.4.0)\n##   ggrepel                    0.9.4      2023-10-13 [2] CRAN (R 4.4.0)\n##   ggsci                      3.0.0      2023-03-08 [2] CRAN (R 4.4.0)\n##   ggsignif                   0.6.4      2022-10-13 [2] CRAN (R 4.4.0)\n##   ggtree                     3.11.0     2023-10-24 [2] Bioconductor\n##   gh                         1.4.0      2023-02-22 [2] CRAN (R 4.4.0)\n##   gitcreds                   0.1.2      2022-09-08 [2] CRAN (R 4.4.0)\n##   gld                        2.6.6      2022-10-23 [2] CRAN (R 4.4.0)\n##   glmmTMB                    1.1.8      2023-10-07 [2] CRAN (R 4.4.0)\n##   glmnet                     4.1-8      2023-08-22 [2] CRAN (R 4.4.0)\n##   GlobalOptions              0.1.2      2020-06-10 [2] CRAN (R 4.4.0)\n##   globals                    0.16.2     2022-11-21 [2] CRAN (R 4.4.0)\n##   glue                       1.6.2      2022-02-24 [2] CRAN (R 4.4.0)\n##   gmp                        0.7-3      2023-11-28 [2] CRAN (R 4.4.0)\n##   googledrive                2.1.1      2023-06-11 [2] CRAN (R 4.4.0)\n##   googlesheets4              1.1.1      2023-06-11 [2] CRAN (R 4.4.0)\n##   gower                      1.0.1      2022-12-22 [2] CRAN (R 4.4.0)\n##   gplots                     3.1.3      2022-04-25 [2] CRAN (R 4.4.0)\n##   graph                      1.81.0     2023-10-24 [2] Bioconductor\n##   graphics                 * 4.4.0      2023-11-26 [3] local\n##   graphlayouts               1.0.2      2023-11-03 [2] CRAN (R 4.4.0)\n##   grDevices                * 4.4.0      2023-11-26 [3] local\n##   grid                       4.4.0      2023-11-26 [3] local\n##   gridExtra                  2.3        2017-09-09 [2] CRAN (R 4.4.0)\n##   gridGraphics               0.5-1      2020-12-13 [2] CRAN (R 4.4.0)\n##   gsl                        2.1-8      2023-01-24 [2] CRAN (R 4.4.0)\n##   gss                        2.2-7      2023-08-16 [2] CRAN (R 4.4.0)\n##   gtable                     0.3.4      2023-08-21 [2] CRAN (R 4.4.0)\n##   gtools                     3.9.5      2023-11-20 [2] CRAN (R 4.4.0)\n##   GUniFrac                   1.8        2023-09-14 [2] CRAN (R 4.4.0)\n##   hardhat                    1.3.0      2023-03-30 [2] CRAN (R 4.4.0)\n##   hash                       2.2.6.3    2023-08-19 [2] CRAN (R 4.4.0)\n##   haven                      2.5.4      2023-11-30 [2] CRAN (R 4.4.0)\n##   here                       1.0.1      2020-12-13 [2] CRAN (R 4.4.0)\n##   highr                      0.10       2022-12-22 [2] CRAN (R 4.4.0)\n##   Hmisc                      5.1-1      2023-09-12 [2] CRAN (R 4.4.0)\n##   hms                        1.1.3      2023-03-21 [2] CRAN (R 4.4.0)\n##   htmlTable                  2.4.2      2023-10-29 [2] CRAN (R 4.4.0)\n##   htmltools                * 0.5.7      2023-11-03 [2] CRAN (R 4.4.0)\n##   htmlwidgets                1.6.4      2023-12-06 [2] CRAN (R 4.4.0)\n##   httpuv                     1.6.13     2023-12-06 [2] CRAN (R 4.4.0)\n##   httr                       1.4.7      2023-08-15 [2] CRAN (R 4.4.0)\n##   httr2                      1.0.0      2023-11-14 [2] CRAN (R 4.4.0)\n##   ids                        1.0.1      2017-05-31 [2] CRAN (R 4.4.0)\n##   igraph                     1.6.0      2023-12-11 [2] CRAN (R 4.4.0)\n##   ini                        0.3.1      2018-05-20 [2] CRAN (R 4.4.0)\n##   inline                     0.3.19     2021-05-31 [2] CRAN (R 4.4.0)\n##   interp                     1.1-5      2023-11-27 [2] CRAN (R 4.4.0)\n##   ipred                      0.9-14     2023-03-09 [2] CRAN (R 4.4.0)\n##   IRanges                    2.37.0     2023-10-24 [2] Bioconductor\n##   irlba                      2.3.5.1    2022-10-03 [2] CRAN (R 4.4.0)\n##   isoband                    0.2.7      2022-12-20 [2] CRAN (R 4.4.0)\n##   iterators                  1.0.14     2022-02-05 [2] CRAN (R 4.4.0)\n##   janeaustenr                1.0.0      2022-08-26 [2] CRAN (R 4.4.0)\n##   jpeg                       0.1-10     2022-11-29 [2] CRAN (R 4.4.0)\n##   jquerylib                  0.1.4      2021-04-26 [2] CRAN (R 4.4.0)\n##   jsonlite                   1.8.8      2023-12-04 [2] CRAN (R 4.4.0)\n##   kableExtra                 1.3.4      2021-02-20 [2] CRAN (R 4.4.0)\n##   KEGGREST                   1.43.0     2023-10-24 [2] Bioconductor\n##   kernlab                    0.9-32     2023-01-31 [2] CRAN (R 4.4.0)\n##   KernSmooth                 2.23-22    2023-07-10 [3] CRAN (R 4.4.0)\n##   knitr                      1.45       2023-10-30 [2] CRAN (R 4.4.0)\n##   labeling                   0.4.3      2023-08-29 [2] CRAN (R 4.4.0)\n##   lambda.r                   1.2.4      2019-09-18 [2] CRAN (R 4.4.0)\n##   lars                       1.3        2022-04-13 [2] CRAN (R 4.4.0)\n##   later                      1.3.2      2023-12-06 [2] CRAN (R 4.4.0)\n##   lattice                    0.22-5     2023-10-24 [3] CRAN (R 4.4.0)\n##   latticeExtra               0.6-30     2022-07-04 [2] CRAN (R 4.4.0)\n##   lava                       1.7.3      2023-11-04 [2] CRAN (R 4.4.0)\n##   lazyeval                   0.2.2      2019-03-15 [2] CRAN (R 4.4.0)\n##   lifecycle                  1.0.4      2023-11-07 [2] CRAN (R 4.4.0)\n##   limma                      3.59.1     2023-10-30 [2] Bioconductor\n##   listenv                    0.9.0      2022-12-16 [2] CRAN (R 4.4.0)\n##   littler                    0.3.18     2023-03-26 [2] CRAN (R 4.4.0)\n##   lme4                       1.1-35.1   2023-11-05 [2] CRAN (R 4.4.0)\n##   lmerTest                   3.1-3      2020-10-23 [2] CRAN (R 4.4.0)\n##   lmom                       3.0        2023-08-29 [2] CRAN (R 4.4.0)\n##   locfit                     1.5-9.8    2023-06-11 [2] CRAN (R 4.4.0)\n##   logging                    0.10-108   2019-07-14 [2] CRAN (R 4.4.0)\n##   lubridate                  1.9.3      2023-09-27 [2] CRAN (R 4.4.0)\n##   Maaslin2                   1.17.0     2023-10-24 [2] Bioconductor\n##   magrittr                   2.0.3      2022-03-30 [2] CRAN (R 4.4.0)\n##   MASS                       7.3-60.1   2023-11-26 [3] local\n##   Matrix                     1.6-4      2023-11-30 [3] CRAN (R 4.4.0)\n##   MatrixGenerics             1.15.0     2023-10-24 [2] Bioconductor\n##   MatrixModels               0.5-3      2023-11-06 [2] CRAN (R 4.4.0)\n##   matrixStats                1.2.0      2023-12-11 [2] CRAN (R 4.4.0)\n##   mclust                     6.0.1      2023-11-15 [2] CRAN (R 4.4.0)\n##   memoise                    2.0.1      2021-11-26 [2] CRAN (R 4.4.0)\n##   metagenomeSeq              1.45.0     2023-10-24 [2] Bioconductor\n##   methods                  * 4.4.0      2023-11-26 [3] local\n##   mgcv                       1.9-0      2023-07-11 [3] CRAN (R 4.4.0)\n##   mia                        1.11.0     2023-10-24 [2] Bioconductor\n##   miaTime                    0.1.21     2023-12-12 [2] Github (microbiome/miaTime@9fe9771)\n##   miaViz                     1.11.0     2023-10-25 [2] Bioconductor\n##   microbiomeDataSets         1.11.0     2023-10-26 [2] Bioconductor\n##   MicrobiomeStat             1.1        2022-01-24 [2] CRAN (R 4.4.0)\n##   mikropml                   1.6.1      2023-08-21 [2] CRAN (R 4.4.0)\n##   mime                       0.12       2021-09-28 [2] CRAN (R 4.4.0)\n##   miniUI                     0.1.1.1    2018-05-18 [2] CRAN (R 4.4.0)\n##   minqa                      1.2.6      2023-09-11 [2] CRAN (R 4.4.0)\n##   MLeval                     0.3        2020-02-12 [2] CRAN (R 4.4.0)\n##   MLmetrics                  1.1.1      2016-05-13 [2] CRAN (R 4.4.0)\n##   modeest                    2.4.0      2019-11-18 [2] CRAN (R 4.4.0)\n##   ModelMetrics               1.2.2.2    2020-03-17 [2] CRAN (R 4.4.0)\n##   modelr                     0.1.11     2023-03-22 [2] CRAN (R 4.4.0)\n##   modeltools                 0.2-23     2020-03-05 [2] CRAN (R 4.4.0)\n##   multcomp                   1.4-25     2023-06-20 [2] CRAN (R 4.4.0)\n##   MultiAssayExperiment       1.29.0     2023-10-24 [2] Bioconductor\n##   multtest                   2.59.0     2023-10-24 [2] Bioconductor\n##   munsell                    0.5.0      2018-06-12 [2] CRAN (R 4.4.0)\n##   mvtnorm                    1.2-4      2023-11-27 [2] CRAN (R 4.4.0)\n##   NADA                       1.6-1.1    2020-03-22 [2] CRAN (R 4.4.0)\n##   NbClust                    3.0.1      2022-05-02 [2] CRAN (R 4.4.0)\n##   nlme                       3.1-164    2023-11-27 [3] CRAN (R 4.4.0)\n##   nloptr                     2.0.3      2022-05-26 [2] CRAN (R 4.4.0)\n##   nnet                       7.3-19     2023-05-03 [3] CRAN (R 4.4.0)\n##   numDeriv                   2016.8-1.1 2019-06-06 [2] CRAN (R 4.4.0)\n##   OMA                        0.98.16    2023-12-12 [1] Bioconductor\n##   openssl                    2.1.1      2023-09-25 [2] CRAN (R 4.4.0)\n##   optparse                   1.7.3      2022-07-20 [2] CRAN (R 4.4.0)\n##   osqp                       0.6.3.2    2023-10-20 [2] CRAN (R 4.4.0)\n##   packrat                    0.9.2      2023-09-05 [2] CRAN (R 4.4.0)\n##   parallel                   4.4.0      2023-11-26 [3] local\n##   parallelly                 1.36.0     2023-05-26 [2] CRAN (R 4.4.0)\n##   patchwork                  1.1.3      2023-08-14 [2] CRAN (R 4.4.0)\n##   pbapply                    1.7-2      2023-06-27 [2] CRAN (R 4.4.0)\n##   pbkrtest                   0.5.2      2023-01-19 [2] CRAN (R 4.4.0)\n##   pcaPP                      2.0-4      2023-12-07 [2] CRAN (R 4.4.0)\n##   permute                    0.9-7      2022-01-27 [2] CRAN (R 4.4.0)\n##   pheatmap                   1.0.12     2019-01-04 [2] CRAN (R 4.4.0)\n##   phyloseq                   1.47.0     2023-10-24 [2] Bioconductor\n##   pillar                     1.9.0      2023-03-22 [2] CRAN (R 4.4.0)\n##   pixmap                     0.4-12     2021-01-29 [2] CRAN (R 4.4.0)\n##   pkgbuild                   1.4.3      2023-12-10 [2] CRAN (R 4.4.0)\n##   pkgconfig                  2.0.3      2019-09-22 [2] CRAN (R 4.4.0)\n##   pkgdown                    2.0.7      2022-12-14 [2] CRAN (R 4.4.0)\n##   pkgload                    1.3.3      2023-09-22 [2] CRAN (R 4.4.0)\n##   plogr                      0.2.0      2018-03-25 [2] CRAN (R 4.4.0)\n##   plotly                     4.10.3     2023-10-21 [2] CRAN (R 4.4.0)\n##   pls                        2.8-3      2023-11-17 [2] CRAN (R 4.4.0)\n##   plyr                       1.8.9      2023-10-02 [2] CRAN (R 4.4.0)\n##   png                        0.1-8      2022-11-29 [2] CRAN (R 4.4.0)\n##   polyclip                   1.10-6     2023-09-27 [2] CRAN (R 4.4.0)\n##   polynom                    1.4-1      2022-04-11 [2] CRAN (R 4.4.0)\n##   posterior                  1.5.0      2023-10-31 [2] CRAN (R 4.4.0)\n##   praise                     1.0.0      2015-08-11 [2] CRAN (R 4.4.0)\n##   preprocessCore             1.65.0     2023-10-24 [2] Bioconductor\n##   prettyunits                1.2.0      2023-09-24 [2] CRAN (R 4.4.0)\n##   pROC                       1.18.5     2023-11-01 [2] CRAN (R 4.4.0)\n##   processx                   3.8.3      2023-12-10 [2] CRAN (R 4.4.0)\n##   prodlim                    2023.08.28 2023-08-28 [2] CRAN (R 4.4.0)\n##   profvis                    0.3.8      2023-05-02 [2] CRAN (R 4.4.0)\n##   progress                   1.2.3      2023-12-06 [2] CRAN (R 4.4.0)\n##   progressr                  0.14.0     2023-08-10 [2] CRAN (R 4.4.0)\n##   promises                   1.2.1      2023-08-10 [2] CRAN (R 4.4.0)\n##   proxy                      0.4-27     2022-06-09 [2] CRAN (R 4.4.0)\n##   ps                         1.7.5      2023-04-18 [2] CRAN (R 4.4.0)\n##   pscl                       1.5.5.1    2023-05-10 [2] CRAN (R 4.4.0)\n##   purrr                      1.0.2      2023-08-10 [2] CRAN (R 4.4.0)\n##   qap                        0.1-2      2022-06-27 [2] CRAN (R 4.4.0)\n##   quadprog                   1.5-8      2019-11-20 [2] CRAN (R 4.4.0)\n##   quantreg                   5.97       2023-08-19 [2] CRAN (R 4.4.0)\n##   quarto                     1.3        2023-09-19 [2] CRAN (R 4.4.0)\n##   R6                         2.5.1      2021-08-19 [2] CRAN (R 4.4.0)\n##   ragg                       1.2.7      2023-12-11 [2] CRAN (R 4.4.0)\n##   randomcoloR                1.1.0.1    2019-11-24 [2] CRAN (R 4.4.0)\n##   randomForest               4.7-1.1    2022-05-23 [2] CRAN (R 4.4.0)\n##   rappdirs                   0.3.3      2021-01-31 [2] CRAN (R 4.4.0)\n##   rbibutils                  2.2.16     2023-10-25 [2] CRAN (R 4.4.0)\n##   rcmdcheck                  1.4.0      2021-09-27 [2] CRAN (R 4.4.0)\n##   RColorBrewer               1.1-3      2022-04-03 [2] CRAN (R 4.4.0)\n##   Rcpp                       1.0.11     2023-07-06 [2] CRAN (R 4.4.0)\n##   RcppAnnoy                  0.0.21     2023-07-02 [2] CRAN (R 4.4.0)\n##   RcppArmadillo              0.12.6.6.1 2023-12-04 [2] CRAN (R 4.4.0)\n##   RcppEigen                  0.3.3.9.4  2023-11-02 [2] CRAN (R 4.4.0)\n##   RcppGSL                    0.3.13     2023-01-13 [2] CRAN (R 4.4.0)\n##   RcppHNSW                   0.5.0      2023-09-19 [2] CRAN (R 4.4.0)\n##   RcppML                     0.3.7      2021-09-21 [2] CRAN (R 4.4.0)\n##   RcppNumerical              0.6-0      2023-09-06 [2] CRAN (R 4.4.0)\n##   RcppParallel               5.1.7      2023-02-27 [2] CRAN (R 4.4.0)\n##   RcppProgress               0.4.2      2020-02-06 [2] CRAN (R 4.4.0)\n##   RcppTOML                   0.2.2      2023-01-29 [2] CRAN (R 4.4.0)\n##   RcppZiggurat               0.1.6      2020-10-20 [2] CRAN (R 4.4.0)\n##   RCurl                      1.98-1.13  2023-11-02 [2] CRAN (R 4.4.0)\n##   Rdpack                     2.6        2023-11-08 [2] CRAN (R 4.4.0)\n##   readr                      2.1.4      2023-02-10 [2] CRAN (R 4.4.0)\n##   readxl                     1.4.3      2023-07-06 [2] CRAN (R 4.4.0)\n##   rebook                     1.13.0     2023-10-24 [2] Bioconductor\n##   recipes                    1.0.8      2023-08-25 [2] CRAN (R 4.4.0)\n##   registry                   0.5-1      2019-03-05 [2] CRAN (R 4.4.0)\n##   rematch                    2.0.0      2023-08-30 [2] CRAN (R 4.4.0)\n##   rematch2                   2.1.2      2020-05-01 [2] CRAN (R 4.4.0)\n##   remotes                    2.4.2.1    2023-07-18 [2] CRAN (R 4.4.0)\n##   renv                       1.0.3      2023-09-19 [2] CRAN (R 4.4.0)\n##   reprex                     2.0.2      2022-08-17 [2] CRAN (R 4.4.0)\n##   reshape2                   1.4.4      2020-04-09 [2] CRAN (R 4.4.0)\n##   reticulate                 1.34.0     2023-10-12 [2] CRAN (R 4.4.0)\n##   Rfast                      2.1.0      2023-11-09 [2] CRAN (R 4.4.0)\n##   rgl                        1.2.8      2023-11-29 [2] CRAN (R 4.4.0)\n##   rhdf5                      2.47.1     2023-11-29 [2] Bioconductor 3.19 (R 4.4.0)\n##   rhdf5filters               1.15.1     2023-11-06 [2] Bioconductor\n##   Rhdf5lib                   1.25.1     2023-12-11 [2] Bioconductor 3.19 (R 4.4.0)\n##   rjson                      0.2.21     2022-01-09 [2] CRAN (R 4.4.0)\n##   rlang                      1.1.2      2023-11-04 [2] CRAN (R 4.4.0)\n##   rmarkdown                  2.25       2023-09-18 [2] CRAN (R 4.4.0)\n##   Rmpfr                      0.9-4      2023-12-04 [2] CRAN (R 4.4.0)\n##   rmutil                     1.1.10     2022-10-27 [2] CRAN (R 4.4.0)\n##   rngtools                   1.5.2      2021-09-20 [2] CRAN (R 4.4.0)\n##   robustbase                 0.99-1     2023-11-29 [2] CRAN (R 4.4.0)\n##   ROCR                       1.0-11     2020-05-02 [2] CRAN (R 4.4.0)\n##   rootSolve                  1.8.2.4    2023-09-21 [2] CRAN (R 4.4.0)\n##   roxygen2                   7.2.3      2022-12-08 [2] CRAN (R 4.4.0)\n##   rpart                      4.1.23     2023-12-05 [3] CRAN (R 4.4.0)\n##   rprojroot                  2.0.4      2023-11-05 [2] CRAN (R 4.4.0)\n##   rsconnect                  1.1.1      2023-10-04 [2] CRAN (R 4.4.0)\n##   RSQLite                    2.3.4      2023-12-08 [2] CRAN (R 4.4.0)\n##   rstatix                    0.7.2      2023-02-01 [2] CRAN (R 4.4.0)\n##   rstudioapi                 0.15.0     2023-07-07 [2] CRAN (R 4.4.0)\n##   rsvd                       1.0.5      2021-04-16 [2] CRAN (R 4.4.0)\n##   Rtsne                      0.17       2023-12-07 [2] CRAN (R 4.4.0)\n##   rversions                  2.1.2      2022-08-31 [2] CRAN (R 4.4.0)\n##   rvest                      1.0.3      2022-08-19 [2] CRAN (R 4.4.0)\n##   S4Arrays                   1.3.1      2023-11-27 [2] Bioconductor 3.19 (R 4.4.0)\n##   S4Vectors                  0.41.2     2023-11-23 [2] Bioconductor 3.19 (R 4.4.0)\n##   sandwich                   3.1-0      2023-12-11 [2] CRAN (R 4.4.0)\n##   sass                       0.4.8      2023-12-06 [2] CRAN (R 4.4.0)\n##   ScaledMatrix               1.11.0     2023-10-24 [2] Bioconductor\n##   scales                     1.3.0      2023-11-28 [2] CRAN (R 4.4.0)\n##   scater                     1.31.1     2023-11-16 [2] Bioconductor 3.19 (R 4.4.0)\n##   scs                        3.2.4      2023-04-11 [2] CRAN (R 4.4.0)\n##   scuttle                    1.13.0     2023-10-24 [2] Bioconductor\n##   sechm                      1.11.0     2023-10-24 [2] Bioconductor\n##   selectr                    0.4-2      2019-11-20 [2] CRAN (R 4.4.0)\n##   seriation                  1.5.4      2023-12-12 [2] CRAN (R 4.4.0)\n##   sessioninfo                1.2.2      2021-12-06 [2] CRAN (R 4.4.0)\n##   shape                      1.4.6      2021-05-19 [2] CRAN (R 4.4.0)\n##   shiny                      1.8.0      2023-11-17 [2] CRAN (R 4.4.0)\n##   SingleCellExperiment       1.25.0     2023-10-24 [2] Bioconductor\n##   sitmo                      2.0.2      2021-10-13 [2] CRAN (R 4.4.0)\n##   snow                       0.4-4      2021-10-27 [2] CRAN (R 4.4.0)\n##   SnowballC                  0.7.1      2023-04-25 [2] CRAN (R 4.4.0)\n##   som                        0.3-5.1    2016-07-06 [2] CRAN (R 4.4.0)\n##   sourcetools                0.1.7-1    2023-02-01 [2] CRAN (R 4.4.0)\n##   sp                         2.1-2      2023-11-26 [2] CRAN (R 4.4.0)\n##   SparseArray                1.3.1      2023-11-07 [2] Bioconductor\n##   SparseM                    1.81       2021-02-18 [2] CRAN (R 4.4.0)\n##   sparseMatrixStats          1.15.0     2023-10-24 [2] Bioconductor\n##   spatial                    7.3-17     2023-07-20 [3] CRAN (R 4.4.0)\n##   splines                    4.4.0      2023-11-26 [3] local\n##   SQUAREM                    2021.1     2021-01-13 [2] CRAN (R 4.4.0)\n##   stable                     1.1.6      2022-03-02 [2] CRAN (R 4.4.0)\n##   stabledist                 0.7-1      2016-09-12 [2] CRAN (R 4.4.0)\n##   statip                     0.2.3      2019-11-17 [2] CRAN (R 4.4.0)\n##   statmod                    1.5.0      2023-01-06 [2] CRAN (R 4.4.0)\n##   stats                    * 4.4.0      2023-11-26 [3] local\n##   stats4                     4.4.0      2023-11-26 [3] local\n##   stringdist                 0.9.12     2023-11-28 [2] CRAN (R 4.4.0)\n##   stringi                    1.8.3      2023-12-11 [2] CRAN (R 4.4.0)\n##   stringr                    1.5.1      2023-11-14 [2] CRAN (R 4.4.0)\n##   SummarizedExperiment       1.33.1     2023-11-28 [2] Bioconductor 3.19 (R 4.4.0)\n##   survival                   3.5-7      2023-08-14 [3] CRAN (R 4.4.0)\n##   svglite                    2.1.3      2023-12-08 [2] CRAN (R 4.4.0)\n##   svUnit                     1.0.6      2021-04-19 [2] CRAN (R 4.4.0)\n##   sys                        3.4.2      2023-05-23 [2] CRAN (R 4.4.0)\n##   systemfonts                1.0.5      2023-10-09 [2] CRAN (R 4.4.0)\n##   tcltk                      4.4.0      2023-11-26 [3] local\n##   tensorA                    0.36.2     2020-11-19 [2] CRAN (R 4.4.0)\n##   testthat                   3.2.1      2023-12-02 [2] CRAN (R 4.4.0)\n##   textshaping                0.3.7      2023-10-09 [2] CRAN (R 4.4.0)\n##   TH.data                    1.1-2      2023-04-17 [2] CRAN (R 4.4.0)\n##   tibble                     3.2.1      2023-03-20 [2] CRAN (R 4.4.0)\n##   tidybayes                  3.0.6      2023-08-12 [2] CRAN (R 4.4.0)\n##   tidygraph                  1.2.3      2023-02-01 [2] CRAN (R 4.4.0)\n##   tidyr                      1.3.0      2023-01-24 [2] CRAN (R 4.4.0)\n##   tidyselect                 1.2.0      2022-10-10 [2] CRAN (R 4.4.0)\n##   tidytext                   0.4.1      2023-01-07 [2] CRAN (R 4.4.0)\n##   tidytree                   0.4.6      2023-12-12 [2] CRAN (R 4.4.0)\n##   tidyverse                  2.0.0      2023-02-22 [2] CRAN (R 4.4.0)\n##   timechange                 0.2.0      2023-01-11 [2] CRAN (R 4.4.0)\n##   timeDate                   4022.108   2023-01-07 [2] CRAN (R 4.4.0)\n##   timeSeries                 4031.107   2023-08-26 [2] CRAN (R 4.4.0)\n##   tinytex                    0.49       2023-11-22 [2] CRAN (R 4.4.0)\n##   TMB                        1.9.10     2023-12-12 [2] CRAN (R 4.4.0)\n##   tokenizers                 0.3.0      2022-12-22 [2] CRAN (R 4.4.0)\n##   tools                      4.4.0      2023-11-26 [3] local\n##   treeio                     1.27.0     2023-10-24 [2] Bioconductor\n##   TreeSummarizedExperiment   2.11.0     2023-10-24 [2] Bioconductor\n##   truncnorm                  1.0-9      2023-03-20 [2] CRAN (R 4.4.0)\n##   TSP                        1.2-4      2023-04-04 [2] CRAN (R 4.4.0)\n##   tweedie                    2.3.5      2022-08-17 [2] CRAN (R 4.4.0)\n##   tweenr                     2.0.2      2022-09-06 [2] CRAN (R 4.4.0)\n##   tzdb                       0.4.0      2023-05-12 [2] CRAN (R 4.4.0)\n##   urlchecker                 1.0.1      2021-11-30 [2] CRAN (R 4.4.0)\n##   usethis                    2.2.2      2023-07-06 [2] CRAN (R 4.4.0)\n##   utf8                       1.2.4      2023-10-22 [2] CRAN (R 4.4.0)\n##   utils                    * 4.4.0      2023-11-26 [3] local\n##   uuid                       1.1-1      2023-08-17 [2] CRAN (R 4.4.0)\n##   uwot                       0.1.16     2023-06-29 [2] CRAN (R 4.4.0)\n##   V8                         4.4.1      2023-12-04 [2] CRAN (R 4.4.0)\n##   vctrs                      0.6.5      2023-12-01 [2] CRAN (R 4.4.0)\n##   vegan                      2.6-4      2022-10-11 [2] CRAN (R 4.4.0)\n##   vipor                      0.4.5      2017-03-22 [2] CRAN (R 4.4.0)\n##   viridis                    0.6.4      2023-07-22 [2] CRAN (R 4.4.0)\n##   viridisLite                0.4.2      2023-05-02 [2] CRAN (R 4.4.0)\n##   vroom                      1.6.5      2023-12-05 [2] CRAN (R 4.4.0)\n##   waldo                      0.5.2      2023-11-02 [2] CRAN (R 4.4.0)\n##   webshot                    0.5.5      2023-06-26 [2] CRAN (R 4.4.0)\n##   whisker                    0.4.1      2022-12-05 [2] CRAN (R 4.4.0)\n##   withr                      2.5.2      2023-10-30 [2] CRAN (R 4.4.0)\n##   Wrench                     1.21.0     2023-10-24 [2] Bioconductor\n##   xfun                       0.41       2023-11-01 [2] CRAN (R 4.4.0)\n##   xgboost                    1.7.6.1    2023-12-06 [2] CRAN (R 4.4.0)\n##   XML                        3.99-0.16  2023-11-29 [2] CRAN (R 4.4.0)\n##   xml2                       1.3.6      2023-12-04 [2] CRAN (R 4.4.0)\n##   xopen                      1.0.0      2018-09-17 [2] CRAN (R 4.4.0)\n##   xtable                     1.8-4      2019-04-21 [2] CRAN (R 4.4.0)\n##   XVector                    0.43.0     2023-10-24 [2] Bioconductor\n##   yaml                       2.3.8      2023-12-11 [2] CRAN (R 4.4.0)\n##   yesno                      0.1.2      2020-07-10 [2] CRAN (R 4.4.0)\n##   yulab.utils                0.1.1      2023-12-11 [2] CRAN (R 4.4.0)\n##   zCompositions              1.5        2023-12-07 [2] CRAN (R 4.4.0)\n##   zip                        2.3.0      2023-04-17 [2] CRAN (R 4.4.0)\n##   zlibbioc                   1.49.0     2023-10-24 [2] Bioconductor\n##   zoo                        1.8-12     2023-04-13 [2] CRAN (R 4.4.0)\n##  \n##   [1] /tmp/Rtmpe5QBwZ/Rinstb8ef89be\n##   [2] /usr/local/lib/R/site-library\n##   [3] /usr/local/lib/R/library\n##  \n##  ‚îÄ Python configuration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n##   Python is not available\n##  \n##  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/01_intro.html",
    "href": "pages/01_intro.html",
    "title": "Preamble",
    "section": "",
    "text": "This work - Orchestrating Microbiome Analysis with Bioconductor (Lahti et al. 2021) - contributes novel methods and educational resources for microbiome data science. It aims to teach the grammar of Bioconductor workflows in the context of microbiome data science. We show through concrete examples how to use the latest developments and data analytical strategies in R/Bioconductor for the manipulation, analysis, and reproducible reporting of hierarchical, heterogeneous, and multi-modal microbiome profiling data. The data science methodology is tightly integrated with the broader R/Bioconductor ecosystem that focuses on the development of high-quality open research software for life sciences (Gentleman et al. (2004), Huber et al. (2015)). The support for modularity and interoperability is a key to efficient resource sharing and collaborative development both within and across research fields. The central data infrastructure, the SummarizedExperiment data container and its derivatives, have already been widely adopted in microbiome research, single cell sequencing, and in other fields, allowing a rapid adoption and extensions of emerging data science techniques across application domains.\n\nLahti, Leo, Sudarshan Shetty, Felix M Ernst, et al. 2021. Orchestrating Microbiome Analysis with Bioconductor [Beta Version]. microbiome.github.io/oma/.\n\nGentleman, Robert C, Vincent J Carey, Douglas M Bates, Ben Bolstad, Marcel Dettling, Sandrine Dudoit, Byron Ellis, et al. 2004. ‚ÄúBioconductor: Open Software Development for Computational Biology and Bioinformatics.‚Äù Genome Biology 5: R80.\n\nHuber, W., V. J. Carey, R. Gentleman, S. Anders, M. Carlson, B. S. Carvalho, H. C. Bravo, et al. 2015. ‚ÄúOrchestrating High-Throughput Genomic Analysis with Bioconductor.‚Äù Nature Methods 12 (2): 115‚Äì21. http://www.nature.com/nmeth/journal/v12/n2/full/nmeth.3252.html.\nWe assume that the reader is already familiar with R programming. For references and tips on introductory material for R and Bioconductor, see Chapter¬†17. This online resource and its associated ecosystem of microbiome data science tools are a result of a community-driven development process, and welcoming new users and contributors. You can find more information on how to find us online and join the developer community through the project homepage at microbiome.github.io.\nThe book is organized into three parts. We start by introducing the material and link to further resources for learning R and Bioconductor. We describe the key data infrastructure, the TreeSummarizedExperiment class that provides a container for microbiome data, and how to get started by loading microbiome data set in the context of this new framework. The second section, Focus Topics, covers the common steps in microbiome data analysis, beginning with the most common steps and progressing to more specialized methods in subsequent sections. Third, Workflows, provides case studies for the various datasets used throughout the book. Finally, Appendix, links to further resources and acknowledgments.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/06_packages.html#package-installation",
    "href": "pages/06_packages.html#package-installation",
    "title": "1¬† Packages",
    "section": "\n1.1 Package installation",
    "text": "1.1 Package installation\nYou can install all packages that are required to run every example in this book via the following command:\n\nremotes::install_github('microbiome/OMA')\n\n\n1.1.1 Installing specific packages\nYou can install R packages of your choice with the following command line procedure.\n\n\n\n\n\n\n\nBioconductor development version requires the installation of the latest R beta version. This is primarily recommended for those who already have experience with R/Bioconductor and need access to the latest updates.\n\nBiocManager::install(\"microbiome/mia\", version=\"devel\")\n\nGithub development version provides access to the latest but potentially unstable features. This is useful when you want access to all available tools.\n\ndevtools::install_github(\"microbiome/mia\")"
  },
  {
    "objectID": "pages/06_packages.html#sec-ecosystem",
    "href": "pages/06_packages.html#sec-ecosystem",
    "title": "1¬† Packages",
    "section": "\n1.2 Package ecosystem",
    "text": "1.2 Package ecosystem\nMethods for (Tree)SummarizedExperiment and MultiAssayExperiment data containers are provided by multiple independent developers through R/Bioconductor packages. Some of these are listed below (tips on new packages are welcome).\n\n1.2.1 mia package family\nThe mia package family provides general methods for microbiome data wrangling, analysis and visualization.\n\n\nmia: Microbiome analysis tools (Ernst, Shetty, and Lahti 2020)\n\n\nmiaViz: Microbiome analysis specific visualization (Ernst, Borman, and Lahti 2022)\n\n\nmiaSim: Microbiome data simulations (Simsek et al. 2021)\n\n\nmiaTime: Microbiome time series analysis (Lahti 2021)\n\n\nErnst, Felix G. M., Sudarshan Shetty, and Leo Lahti. 2020. Mia: Microbiome Analysis.\n\nErnst, Felix G. M., Tuomas Borman, and Leo Lahti. 2022. miaViz: Microbiome Analysis Plotting and Visualization.\n\nSimsek, Yagmur, Leo Lahti, Daniel Garza, and Karoline Faust. 2021. ‚ÄúmiaSim r Package.‚Äù microbiome.github.io/miaSim.\n\nLahti, L. 2021. miaTime: Time Series Analysis.\n\n1.2.2 Differential abundance\nThe following DA methods support (Tree)SummarizedExperiment.\n\n\nANCOMBC for differential abundance analysis\n\nbenchdamic for benchmarking differential abundance methods\n\nALDEx2 for differential abundance analysis\n\n1.2.3 Other packages\n\n\nphilr (Silverman et al. (2017)) phylogeny-aware phILR transformation\n\nMicrobiotaProcess for ‚Äútidy‚Äù analysis of microbiome and other ecological data\n\nTools for Microbiome Analysis site listed over 130 R packages for microbiome data science in\n\nMany of these are not in Bioconductor, or do not directly support the data containers used in this book but can be often used with minor modifications. The phyloseq-based tools can be used by converting the TreeSE data into phyloseq with makePhyloseqFromTreeSummarizedExperiment.\n\n\n\nSilverman, Justin D, Alex D Washburne, Sayan Mukherjee, and Lawrence A David. 2017. ‚ÄúA Phylogenetic Transform Enhances Analysis of Compositional Microbiota Data.‚Äù eLife 6. https://doi.org/10.7554/eLife.21887.\n\n1.2.4 Open microbiome data\nHundreds of published microbiome data sets are readily available in these data containers (see Section¬†2.3)."
  },
  {
    "objectID": "pages/04_containers.html#data-science-framework",
    "href": "pages/04_containers.html#data-science-framework",
    "title": "2¬† Microbiome Data",
    "section": "\n2.1 Data science framework",
    "text": "2.1 Data science framework\nThe building blocks of the framework are data container (SummarizedExperiment and its derivatives), packages from various developers using the TreeSE container, open demonstration data sets, in a separate chapter Section¬†2.3, and online tutorials including this online book as well as the various package vignettes and other materials."
  },
  {
    "objectID": "pages/04_containers.html#data-containers",
    "href": "pages/04_containers.html#data-containers",
    "title": "2¬† Microbiome Data",
    "section": "\n2.2 Data containers",
    "text": "2.2 Data containers\nSummarizedExperiment (SE) (Morgan et al. 2020) is a generic and highly optimized container for complex data structures. It has become a common choice for analysing various types of biomedical profiling data, such as RNAseq, ChIp-Seq, microarrays, flow cytometry, proteomics, and single-cell sequencing.\n\nMorgan, Martin, Valerie Obenchain, Jim Hester, and Herv√© Pag√®s. 2020. SummarizedExperiment: SummarizedExperiment Container. https://bioconductor.org/packages/SummarizedExperiment.\n\nHuang, Ruizhu. 2020. TreeSummarizedExperiment: A S4 Class for Data with Tree Structures.\n[TreeSummarizedExperiment] (TreeSE) (Huang 2020) was developed as an extension to incorporate hierarchical information (such as phylogenetic trees and sample hierarchies) and reference sequences.\n[MultiAssayExperiment] (MAE) (Ramos et al. 2017) provides an organized way to bind several different data containers together in a single object. For example, we can bind microbiome data (in TreeSE container) with metabolomic profiling data (in SE) container, with (partially) shared sample metadata. This is convenient and robust for instance in subsetting and other data manipulation tasks. Microbiome data can be part of multiomics experiments and analysis strategies. We highlight how the methods used througout in this book relate to this data framework by using the TreeSummarizedExperiment, MultiAssayExperiment, and classes beyond.\nThis section provides an introductions to these data containers. In microbiome data science, these containers link taxonomic abundance tables with rich side information on the features and samples. Taxonomic abundance data can be obtained by 16S rRNA amplicon or metagenomic sequencing, phylogenetic microarrays, or by other means. Many microbiome experiments include multiple versions and types of data generated independently or derived from each other through transformation or agglomeration. We start by providing recommendations on how to represent different varieties of multi-table data within the TreeSummarizedExperiment class.\nThe options and recommendations are summarized in Table¬†2.1.\n\n2.2.1 Assay data\nThe original count-based taxonomic abundance tables may have different transformations, such as logarithmic, Centered Log-Ratio (CLR), or relative abundance. These are typically stored in assays.\nLet us load example data and rename it as tse.\n\nlibrary(mia)\ndata(\"hitchip1006\", package = \"miaTime\")\ntse &lt;- hitchip1006\n\nThe assays slot contains the experimental data as multiple count matrices. The result of assays is a list of matrices.\n\nassays(tse)\n##  List of length 1\n##  names(1): counts\n\nIndividual assays can be accessed via assay\n\nassay(tse, \"counts\")[1:5,1:7]\n##                               Sample-1 Sample-2 Sample-3 Sample-4 Sample-5\n##  Actinomycetaceae                    0        0        0        0        0\n##  Aerococcus                          0        0        0        0        0\n##  Aeromonas                           0        0        0        0        0\n##  Akkermansia                        21       36      475       61       34\n##  Alcaligenes faecalis et rel.        1        1        1        2        1\n##                               Sample-6 Sample-7\n##  Actinomycetaceae                    0        0\n##  Aerococcus                          0        0\n##  Aeromonas                           0        0\n##  Akkermansia                        14       27\n##  Alcaligenes faecalis et rel.        1        1\n\nTo illustrate the use of multiple assays, the relative abundance data can be calculated and stored along the original count data using transformAssay.\n\ntse &lt;- transformAssay(tse, assay.type = \"counts\", method = \"relabundance\")\nassays(tse)\n##  List of length 2\n##  names(2): counts relabundance\n\nNow there are two assays available in the tse object, counts and relabundance.\n\nassay(tse, \"relabundance\")[1:5,1:7]\n##                                Sample-1  Sample-2  Sample-3  Sample-4\n##  Actinomycetaceae             0.0000000 0.000e+00 0.0000000 0.0000000\n##  Aerococcus                   0.0000000 0.000e+00 0.0000000 0.0000000\n##  Aeromonas                    0.0000000 0.000e+00 0.0000000 0.0000000\n##  Akkermansia                  0.0027657 3.547e-03 0.0666106 0.0056195\n##  Alcaligenes faecalis et rel. 0.0001317 9.854e-05 0.0001402 0.0001842\n##                                Sample-5  Sample-6  Sample-7\n##  Actinomycetaceae             0.000e+00 0.0000000 0.0000000\n##  Aerococcus                   0.000e+00 0.0000000 0.0000000\n##  Aeromonas                    0.000e+00 0.0000000 0.0000000\n##  Akkermansia                  2.833e-03 0.0017690 0.0045570\n##  Alcaligenes faecalis et rel. 8.333e-05 0.0001264 0.0001688\n\nHere the dimension of the count data remains unchanged in transformation. This is in fact, a requirement for the assays.\n\n2.2.2 colData\ncolData contains data on the samples.\n\ncolData(tse)\n##  DataFrame with 1151 rows and 10 columns\n##                    age      sex nationality DNA_extraction_method  project\n##              &lt;integer&gt; &lt;factor&gt;    &lt;factor&gt;              &lt;factor&gt; &lt;factor&gt;\n##  Sample-1           28   male            US                    NA        1\n##  Sample-2           24   female          US                    NA        1\n##  Sample-3           52   male            US                    NA        1\n##  Sample-4           22   female          US                    NA        1\n##  Sample-5           25   female          US                    NA        1\n##  ...               ...      ...         ...                   ...      ...\n##  Sample-1168        50   female Scandinavia                     r       40\n##  Sample-1169        31   female Scandinavia                     r       40\n##  Sample-1170        31   female Scandinavia                     r       40\n##  Sample-1171        52   male   Scandinavia                     r       40\n##  Sample-1172        52   male   Scandinavia                     r       40\n##              diversity   bmi_group  subject      time      sample\n##              &lt;numeric&gt;    &lt;factor&gt; &lt;factor&gt; &lt;numeric&gt; &lt;character&gt;\n##  Sample-1         5.76 severeobese        1         0    Sample-1\n##  Sample-2         6.06 obese              2         0    Sample-2\n##  Sample-3         5.50 lean               3         0    Sample-3\n##  Sample-4         5.87 underweight        4         0    Sample-4\n##  Sample-5         5.89 lean               5         0    Sample-5\n##  ...               ...         ...      ...       ...         ...\n##  Sample-1168      5.87 severeobese      244       8.1 Sample-1168\n##  Sample-1169      5.87 overweight       245       2.3 Sample-1169\n##  Sample-1170      5.92 overweight       245       8.2 Sample-1170\n##  Sample-1171      6.04 overweight       246       2.1 Sample-1171\n##  Sample-1172      5.74 overweight       246       7.9 Sample-1172\n\n\n2.2.3 rowData\nrowData contains data on the features of the analyzed samples. Of particular interest to the microbiome field, this is used to store taxonomic information.\n\nrowData(tse)\n##  DataFrame with 130 rows and 3 columns\n##                                        Phylum          Family\n##                                   &lt;character&gt;     &lt;character&gt;\n##  Actinomycetaceae              Actinobacteria  Actinobacteria\n##  Aerococcus                        Firmicutes         Bacilli\n##  Aeromonas                     Proteobacteria  Proteobacteria\n##  Akkermansia                  Verrucomicrobia Verrucomicrobia\n##  Alcaligenes faecalis et rel.  Proteobacteria  Proteobacteria\n##  ...                                      ...             ...\n##  Vibrio                        Proteobacteria  Proteobacteria\n##  Weissella et rel.                 Firmicutes         Bacilli\n##  Wissella et rel.                  Firmicutes         Bacilli\n##  Xanthomonadaceae              Proteobacteria  Proteobacteria\n##  Yersinia et rel.              Proteobacteria  Proteobacteria\n##                                                Genus\n##                                          &lt;character&gt;\n##  Actinomycetaceae                   Actinomycetaceae\n##  Aerococcus                               Aerococcus\n##  Aeromonas                                 Aeromonas\n##  Akkermansia                             Akkermansia\n##  Alcaligenes faecalis et rel. Alcaligenes faecalis..\n##  ...                                             ...\n##  Vibrio                                       Vibrio\n##  Weissella et rel.                 Weissella et rel.\n##  Wissella et rel.                   Wissella et rel.\n##  Xanthomonadaceae                   Xanthomonadaceae\n##  Yersinia et rel.                   Yersinia et rel.\n\n\n2.2.4 rowTree\nPhylogenetic trees also play an important role in the microbiome field. The TreeSummarizedExperiment class can keep track of features and node relations via two functions, rowTree and rowLinks.\nA tree can be accessed via rowTree as phylo object.\n\nrowTree(tse)\n##  NULL\n\nThe links to the individual features are available through rowLinks.\n\nrowLinks(tse)\n##  NULL\n\nPlease note that there can be a 1:1 relationship between tree nodes and features, but this is not a must-have. This means there can be features, which are not linked to nodes, and nodes, which are not linked to features. To change the links in an existing object, the changeTree function is available.\n\n2.2.5 Alternative experiments\nAlternative experiments complement assays. They can contain complementary data, which is no longer tied to the same dimensions as the assay data. However, the number of samples (columns) must be the same.\nThis can come into play, for instance, when one has taxonomic abundance profiles quantified with different measurement technologies, such as phylogenetic microarrays, amplicon sequencing, or metagenomic sequencing. Another common use case is including abundance tables for different taxonomic ranks. Such alternative experiments concerning the same set of samples can be stored as\n\nSeparate assays assuming that the taxonomic information can be mapped between features directly 1:1; or\nData in the altExp slot of the TreeSummarizedExperiment, if the feature dimensions differ. Each element of the altExp slot is a SummarizedExperiment or an object from a derived class with independent feature data.\n\nThe following shows how to store taxonomic abundance tables agglomerated at different taxonomic levels. However, the data could as well originate from entirely different measurement sources as long as the samples match.\nLet us first agglomerate the data to Phylum level. This yields a new TreeSE data object.\n\ntse_phylum &lt;- mergeFeaturesByRank(tse, \"Phylum\", na.rm=TRUE)\n# Both have the same number of columns (samples)\ndim(tse)\n##  [1]  130 1151\ndim(tse_phylum)\n##  [1]    8 1151\n\nThen we can add the new phylum-level data object as an alternative experiment in the original data.\n\n# Add the new data object to the original data object as an alternative experiment with the name \"Phylum\"\naltExp(tse, \"Phylum\") &lt;- tse_phylum\n\n# Check the alternative experiment names available in the data\naltExpNames(tse)\n##  [1] \"Phylum\"\n\nWe can now subset the data, for instance, and this acts on both altExp and assay data.\n\ntse[,1:10]\n##  class: TreeSummarizedExperiment \n##  dim: 130 10 \n##  metadata(0):\n##  assays(2): counts relabundance\n##  rownames(130): Actinomycetaceae Aerococcus ... Xanthomonadaceae\n##    Yersinia et rel.\n##  rowData names(3): Phylum Family Genus\n##  colnames(10): Sample-1 Sample-2 ... Sample-9 Sample-10\n##  colData names(10): age sex ... time sample\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(1): Phylum\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\ndim(altExp(tse[,1:10],\"Phylum\"))\n##  [1]  8 10\n\nFor more details on altExp, you can check the introduction to the SingleCellExperiment package (Lun and Risso 2020).\n\nLun, Aaron, and Davide Risso. 2020. SingleCellExperiment: S4 Classes for Single Cell Data.\n\n2.2.6 MultiAssayExperiments\nMultiple experiments relate to complementary measurement types, such as transcriptomic or metabolomic profiling of the microbiome or the host. Multiple experiments can be represented using the same options as alternative experiments, or by using the MultiAssayExperiment class (Ramos et al. 2017). Depending on how the datasets relate to each other the data can be stored as:\n\nRamos, Marcel, Lucas Schiffer, Angela Re, Rimsha Azhar, Azfar Basunia, Carmen Rodriguez Cabrera, Tiffany Chan, et al. 2017. ‚ÄúSoftware for the Integration of Multiomics Experiments in Bioconductor.‚Äù Cancer Research. https://doi.org/10.1158/0008-5472.CAN-17-0344.\n\nSeparate altExp if the samples can be matched directly 1:1; or\nAs MultiAssayExperiment objects, in which the connections between samples are defined through a sampleMap. Each element on the experimentsList of an MultiAssayExperiment is matrix or matrix-like objects, including SummarizedExperiment objects, and the number of samples can differ between the elements.\n\nFor information have a look at the intro vignette of the MultiAssayExperiment package.\n\n\nTable¬†2.1: Recommended options for storing multiple data tables in microbiome studies The assays are best suited for data transformations (one-to-one match between samples and columns across the assays). The alternative experiments are particularly suitable for alternative versions of the data that are of same type but may have a different number of features (e.g.¬†taxonomic groups); this is for instance the case with taxonomic abundance tables agglomerated at different levels (e.g.¬†genus vs.¬†phyla) or alternative profiling technologies (e.g.¬†amplicon sequencing vs.¬†shallow shotgun metagenomics). For alternative experiments one-to-one match between samples (cols) is libraryd but the alternative experiment tables can have different numbers of features (rows). Finally, elements of the MultiAssayExperiment provide the most flexible way to incorporate multi-omic data tables with flexible numbers of samples and features. We recommend these conventions as the basis for methods development and application in microbiome studies.\n\nOption\nRows (features)\nCols (samples)\nRecommended\n\n\n\nassays\nmatch\nmatch\nData transformations\n\n\naltExp\nfree\nmatch\nAlternative experiments\n\n\nMultiAssay\nfree\nfree (mapping)\nMulti-omic experiments"
  },
  {
    "objectID": "pages/04_containers.html#sec-example-data",
    "href": "pages/04_containers.html#sec-example-data",
    "title": "2¬† Microbiome Data",
    "section": "\n2.3 Demonstration data",
    "text": "2.3 Demonstration data\nOpen demonstration data for testing and benchmarking purposes is available from multiple locations. This chapter introduces some options. The other chapters of this book provide ample examples about the use of the data.\n\n2.3.1 Package data\nThe mia R package contains example datasets that are direct conversions from the alternative phyloseq container to the TreeSummarizedExperiment container.\nList the available datasets in the mia package:\n\nlibrary(mia)\ndata(package=\"mia\")\n\nLoad the GlobalPatterns data from the mia package:\n\ndata(\"GlobalPatterns\", package=\"mia\")\nGlobalPatterns\n##  class: TreeSummarizedExperiment \n##  dim: 19216 26 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(19216): 549322 522457 ... 200359 271582\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (19216 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\n\n2.3.1.1 Tengeler2020\nTengeler2020 is derived from a randomised blinded study on the effects of gut microbiome on attention-deficit/hyperactivity disorder (ADHD) in humanised mice (C Tengeler et al. 2020). The dataset is briefly presented in these slides.\n\nC Tengeler, Anouk, Sarita A Dam, Maximilian Wiesmann, Jilly Naaijen, Miranda van Bodegom, Clara Belzer, Pieter J Dederen, et al. 2020. ‚ÄúGut Microbiota from Persons with Attention-Deficit/Hyperactivity Disorder Affects the Brain in Mice.‚Äù Microbiome 8: 1‚Äì14. https://doi.org/10.1186/s40168-020-00816-x.\n\n2.3.1.2 HintikkaXOData\nHintikkaXOData is derived from a study about the effects of fat diet and prebiotics on the microbiome of rat models (Hintikka et al. 2021). It is available in the MAE data container for R. The dataset is briefly summarized in these slides.\n\nHintikka, Jukka, Sanna Lensu, Elina M√§kinen, Sira Karvinen, Marjaana Honkanen, Jere Lind√©n, Tim Garrels, Satu Pekkala, and Leo Lahti. 2021. ‚ÄúXylo-Oligosaccharides in Prevention of Hepatic Steatosis and Adipose Tissue Inflammation: Associating Taxonomic and Metabolomic Patterns in Fecal Microbiomes with Biclustering.‚Äù International Journal of Environmental Research and Public Health 18 (8): 4049.\n\n2.3.2 ExperimentHub data\nExperimentHub provides a variety of data resources, including the microbiomeDataSets package (Morgan and Shepherd 2021; Lahti, Ernst, and Shetty 2021).\n\nMorgan, Martin, and Lori Shepherd. 2021. ExperimentHub: Client to Access ExperimentHub Resources.\n\nLahti, Leo, Felix G. M. Ernst, and Sudarshan Shetty. 2021. microbiomeDataSets: Experiment Hub Based Microbiome Datasets.\nA table of the available datasets is available through the availableDataSets function.\n\nlibrary(microbiomeDataSets)\navailableDataSets()\n##              Dataset\n##  1  GrieneisenTSData\n##  2    HintikkaXOData\n##  3       LahtiMLData\n##  4        LahtiMData\n##  5       LahtiWAData\n##  6      OKeefeDSData\n##  7 SilvermanAGutData\n##  8        SongQAData\n##  9   SprockettTHData\n\nAll data are downloaded from ExperimentHub and cached for local re-use. Check the man pages of each function for a detailed documentation of the data contents and references. Let us retrieve a MultiAssayExperiment dataset:\n\n# mae &lt;- HintikkaXOData()\n# Since HintikkaXOData is now added to mia, we can load it directly from there\n# We suggest to check other datasets from microbiomeDataSets\ndata(HintikkaXOData, package = \"mia\")\nmae &lt;- HintikkaXOData\n\nData is available in SummarizedExperiment, r Biocpkg(\"TreeSummarizedExperiment\") and r Biocpkg(\"MultiAssayExperiment\") data containers; see the separate page on alternative containers for more details.\n\n2.3.3 Curated metagenomic data\ncuratedMetagenomicData is a large collection of curated human microbiome datasets, provided as (Tree)SummarizedExperiment objects (Pasolli et al. 2017). The resource provides curated human microbiome data including gene families, marker abundance, marker presence, pathway abundance, pathway coverage, and relative abundance for samples from different body sites. See the package homepage for more details on data availability and access.\n\nPasolli, E, L Schiffer, P Manghi, A Renson, V Obenchain, D Truong, F Beghini, et al. 2017. ‚ÄúAccessible, Curated Metagenomic Data Through ExperimentHub.‚Äù Nature Methods 14: 1023‚Äì24. https://doi.org/10.1038/nmeth.4468.\n\nVatanen, Tommi, Aleksandar D. Kostic, Eva d‚ÄôHennezel, Heli Siljander, Eric A. Franzosa, Moran Yassour, Raivo Kolde, et al. 2016. ‚ÄúVariation in Microbiome LPS Immunogenicity Contributes to Autoimmunity in Humans.‚Äù Cell 165 (May): 842‚Äì53. https://doi.org/10.1016/j.cell.2016.04.007.\nAs one example, let us retrieve the Vatanen (2016) (Vatanen et al. 2016) data set. This is a larger collection with a bit longer download time.\n\nlibrary(curatedMetagenomicData)\ntse &lt;- curatedMetagenomicData(\"Vatanen*\", dryrun = FALSE, counts = TRUE)\n\n\n2.3.4 Human microbiome compendium\nMicroBioMap dataset includes over 170k samples of publicly available 16S rRNA amplicon sequencing data, all processed using the same pipeline and reference database(Abdill2023?). After installing the MicroBioMap package (see the original website for instructions), you can load the compendium with\n\nlibrary(MicroBioMap)\ncpd &lt;- getCompendium()\n\nThis returns a TreeSummarizedExperiment object. Currently, the ‚Äútree‚Äù part of the TreeSummarizedExperiment is not populated, but that is on the roadmap(compendiumpackage?).\nAfter loading the compendium, you will have immediate access to nearly 170,000 microbiome samples of publicly available 16S rRNA amplicon sequencing data, all processed using the same pipeline and reference database. For more use examples in R/Bioconductor, see the MicroBioMap vignette.\n\n2.3.5 Other data sources\nThe current collections provide access to vast microbiome data resources. The output has to be converted into TreeSE/MAE separately.\n\n\nMGnifyR provides access to EBI/MGnify\n\n\nqiitr provides access to QIITA"
  },
  {
    "objectID": "pages/04_containers.html#sec-loading-experimental-microbiome-data",
    "href": "pages/04_containers.html#sec-loading-experimental-microbiome-data",
    "title": "2¬† Microbiome Data",
    "section": "\n2.4 Loading experimental microbiome data",
    "text": "2.4 Loading experimental microbiome data\n\n2.4.1 16S workflow\nResult of amplicon sequencing is a large number of files that include all the sequences that were read from samples. Those sequences need to be matched with taxa. Additionally, we need to know how many times each taxa were found from each sample.\nThere are several algorithms to do that, and DADA2 is one of the most common. You can find DADA2 pipeline tutorial, for example, here. After the DADA2 portion of the tutorial is completed, the data is stored into phyloseq object (Bonus: Handoff to phyloseq). To store the data to TreeSummarizedExperiment, follow the example below.\nYou can find full workflow script without further explanations and comments from here\nLoad required packages.\n\nlibrary(mia)\nlibrary(ggplot2)\nlibrary(BiocManager)\nlibrary(Biostrings)\n\nCreate arbitrary example sample metadata like it was done in the tutorial. Usually, sample metadata is imported as a file.\n\nsamples.out &lt;- rownames(seqtab.nochim)\nsubject &lt;- sapply(strsplit(samples.out, \"D\"), `[`, 1)\ngender &lt;- substr(subject,1,1)\nsubject &lt;- substr(subject,2,999)\nday &lt;- as.integer(sapply(strsplit(samples.out, \"D\"), `[`, 2))\nsamdf &lt;- data.frame(Subject=subject, Gender=gender, Day=day)\nsamdf$When &lt;- \"Early\"\nsamdf$When[samdf$Day&gt;100] &lt;- \"Late\"\nrownames(samdf) &lt;- samples.out\n\nConvert data into right format and create a TreeSE object.\n\n# Create a list that contains assays\ncounts &lt;- t(seqtab.nochim)\ncounts &lt;- as.matrix(counts)\nassays &lt;- SimpleList(counts = counts)\n\n# Convert colData and rowData into DataFrame\nsamdf &lt;- DataFrame(samdf)\ntaxa &lt;- DataFrame(taxa)\n\n# Create TreeSE\ntse &lt;- TreeSummarizedExperiment(assays = assays,\n                                colData = samdf,\n                                rowData = taxa\n                                )\n\n# Remove mock sample like it is also done in DADA2 pipeline tutorial\ntse &lt;- tse[ , colnames(tse) != \"mock\"]\n\nAdd sequences into referenceSeq slot and convert rownames into simpler format.\n\n# Convert sequences into right format\ndna &lt;- Biostrings::DNAStringSet( rownames(tse) )\n# Add sequences into referenceSeq slot\nreferenceSeq(tse) &lt;- dna\n# Convert rownames into ASV_number format\nrownames(tse) &lt;- paste0(\"ASV\", seq( nrow(tse) ))\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 232 20 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(232): ASV1 ASV2 ... ASV231 ASV232\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(20): F3D0 F3D1 ... F3D9 Mock\n##  colData names(4): Subject Gender Day When\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n##  referenceSeq: a DNAStringSet (232 sequences)\n\n\n2.4.2 Import from external files\nMicrobiome (taxonomic) profiling data is commonly distributed in various file formats. You can import such external data files as a (Tree)SummarizedExperiment object, but the details depend on the file format. Here, we provide examples for common formats. Some datasets and raw files to learn how to import raw data and construct TreeSE/MAE containers are available in the microbiome data repository.\n\n2.4.2.1 CSV import\nCSV data tables can be imported with the standard R functions, then converted to the desired format. For detailed examples, you can check the Bioconductor course material by Martin Morgan. You can also check the example files and construct your own CSV files accordingly.\nRecommendations for the CSV files are the following. File names are arbitrary; we refer here to the same names as in the examples:\n\nAbundance table (assay_taxa.csv): data matrix (features x samples); first column provides feature IDs, the first row provides sample IDs; other values should be numeric (abundances).\nRow data (rowdata_taxa.csv): data table (features x info); first column provides feature IDs, the first row provides column headers; this file usually contains the taxonomic mapping between different taxonomic levels. Ideally, the feature IDs (row names) match one-to-one with the abundance table row names.\nColumn data (coldata.csv): data table (samples x info); first column provides sample IDs, the first row provides column headers; this file usually contains the sample metadata/phenodata (such as subject age, health etc). Ideally, the sample IDs match one-to-one with the abundance table column names.\n\nAfter you have set up the CSV files, you can read them in R:\n\ncount_file  &lt;- system.file(\"extdata\", \"assay_taxa.csv\", package = \"OMA\")\ntax_file    &lt;- system.file(\"extdata\", \"rowdata_taxa.csv\", package = \"OMA\")\nsample_file &lt;- system.file(\"extdata\", \"coldata.csv\", package = \"OMA\")\n\n# Load files\ncounts  &lt;- read.csv(count_file, row.names=1)   # Abundance table (e.g. ASV data; to assay data)\ntax     &lt;- read.csv(tax_file, row.names=1)     # Taxonomy table (to rowData)\nsamples &lt;- read.csv(sample_file, row.names=1)  # Sample data (to colData)\n\nAfter reading the data in R, ensure the following:\n\nabundance table (counts): numeric matrix, with feature IDs as rownames and sample IDs as column names\nrowdata (tax): DataFrame, with feature IDs as rownames. If this is a data.frame you can use the function DataFrame() to change the format. Column names are free but in microbiome analysis they usually they refer to taxonomic ranks. The rownames in rowdata should match with rownames in abundance table.\ncoldata (samples): DataFrame, with sample IDs as rownames. If this is a data.frame you can use the function DataFrame() to change the format. Column names are free. The rownames in coldata should match with colnames in abundance table.\n\nAlways ensure that the tables have rownames! The TreeSE constructor compares rownames and ensures that, for example, right samples are linked with right patient.\nAlso ensure that the row and column names match one-to-one between abundance table, rowdata, and coldata:\n\n# Match rows and columns\ncounts &lt;- counts[rownames(tax), rownames(samples)]\n\n# Let us ensure that the data is in correct (numeric matrix) format:\ncounts &lt;- as.matrix(counts)\n\nIf you hesitate about the format of the data, you can compare to one of the available demonstration datasets, and make sure that your data components have the same format.\nThere are many different source files and many different ways to read data in R. One can do data manipulation in R as well. Investigate the entries as follows.\n\n# coldata rownames match assay colnames\nall(rownames(samples) == colnames(counts)) # our dataset\n##  [1] TRUE\nclass(samples) # should be data.frame or DataFrame\n##  [1] \"data.frame\"\n\n# rowdata rownames match assay rownames\nall(rownames(tax) == rownames(counts)) # our dataset\n##  [1] TRUE\nclass(tax) # should be data.frame or DataFrame\n##  [1] \"data.frame\"\n\n# Counts \nclass(counts) # should be a numeric matrix\n##  [1] \"matrix\" \"array\"\n\n\n2.4.3 Constructing TreeSummarizedExperiment\nNow let us create the TreeSE object from the input data tables. Here we also convert the data objects in their preferred formats:\n\ncounts ‚Äì&gt; numeric matrix\nrowData ‚Äì&gt; DataFrame\ncolData ‚Äì&gt; DataFrame\n\nThe SimpleList could be used to include multiple alternative assays, if necessary.\n\n# Create a TreeSE\ntse_taxa &lt;- TreeSummarizedExperiment(assays =  SimpleList(counts = counts),\n                                     colData = DataFrame(samples),\n                                     rowData = DataFrame(tax))\n\ntse_taxa\n##  class: TreeSummarizedExperiment \n##  dim: 12706 40 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(12706): GAYR01026362.62.2014 CVJT01000011.50.2173 ...\n##    JRJTB:03787:02429 JRJTB:03787:02478\n##  rowData names(7): Phylum Class ... Species OTU\n##  colnames(40): C1 C2 ... C39 C40\n##  colData names(6): Sample Rat ... Fat XOS\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n\nNow you should have a ready-made TreeSE data object that can be used in downstream analyses.\n\n2.4.4 Constructing MultiAssayExperiment\nTo construct a MultiAssayExperiment object, just combine multiple TreeSE data containers. Here we import metabolite data from the same study.\n\ncount_file &lt;- system.file(\"extdata\", \"assay_metabolites.csv\", package = \"OMA\")\nsample_file &lt;- system.file(\"extdata\", \"coldata.csv\", package = \"OMA\")\n\n# Load files\ncounts  &lt;- read.csv(count_file, row.names=1)  \nsamples &lt;- read.csv(sample_file, row.names=1)\n\n# Create a TreeSE for the metabolite data\ntse_metabolite &lt;- TreeSummarizedExperiment(assays = SimpleList(concs = as.matrix(counts)),\n                                           colData = DataFrame(samples))\n\ntse_metabolite\n##  class: TreeSummarizedExperiment \n##  dim: 38 40 \n##  metadata(0):\n##  assays(1): concs\n##  rownames(38): Butyrate Acetate ... Malonate 1,3-dihydroxyacetone\n##  rowData names(0):\n##  colnames(40): C1 C2 ... C39 C40\n##  colData names(6): Sample Rat ... Fat XOS\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n\nNow we can combine these two experiments into MAE.\n\n# Create an ExperimentList that includes experiments\nexperiments &lt;- ExperimentList(microbiome = tse_taxa, \n                              metabolite = tse_metabolite)\n\n# Create a MAE\nmae &lt;- MultiAssayExperiment(experiments = experiments)\n\nmae\n##  A MultiAssayExperiment object of 2 listed\n##   experiments with user-defined names and respective classes.\n##   Containing an ExperimentList class object of length 2:\n##   [1] microbiome: TreeSummarizedExperiment with 12706 rows and 40 columns\n##   [2] metabolite: TreeSummarizedExperiment with 38 rows and 40 columns\n##  Functionality:\n##   experiments() - obtain the ExperimentList instance\n##   colData() - the primary/phenotype DataFrame\n##   sampleMap() - the sample coordination DataFrame\n##   `$`, `[`, `[[` - extract colData columns, subset, or experiment\n##   *Format() - convert into a long or wide DataFrame\n##   assays() - convert ExperimentList to a SimpleList of matrices\n##   exportClass() - save data to flat files\n\n\n2.4.5 Import functions for standard formats\nSpecific import functions are provided for:\n\nBiom files (see help(mia::loadFromBiom))\nQIIME2 files (see help(mia::loadFromQIIME2))\nMothur files (see help(mia::loadFromMothur))\n\n\n2.4.5.1 Biom import\nHere we show how Biom files are imported into a TreeSE object using as an example Tengeler2020, which is further described in section Section¬†2.3.1.1. This dataset consists of 3 files, which can be fetched or downloaded from this repository:\n\nbiom file: abundance table and taxonomy information\ncsv file: sample metadata\ntree file: phylogenetic tree\n\nTo begin with, we store the data in a local directory within the working directory, such as data/, and define the source file paths.\n\nbiom_file_path &lt;- system.file(\"extdata\", \"Aggregated_humanization2.biom\", package = \"OMA\")\nsample_meta_file_path &lt;- system.file(\"extdata\", \"Mapping_file_ADHD_aggregated.csv\", package = \"OMA\")\ntree_file_path &lt;- system.file(\"extdata\", \"Data_humanization_phylo_aggregation.tre\", package = \"OMA\")\n\nNow we can read in the biom file and convert it into a TreeSE object. In addition, we retrieve the rank names from the prefixes of the feature names and then remove them with the rankFromPrefix and removeTaxaPrefixes optional arguments.\n\nlibrary(mia)\n\n# read biom and convert it to TreeSE\ntse &lt;- loadFromBiom(biom_file_path,\n                    rankFromPrefix = TRUE,\n                    removeTaxaPrefixes = TRUE)\n\n# Check\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 151 27 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(151): 1726470 1726471 ... 17264756 17264757\n##  rowData names(6): taxonomy1 Phylum ... Family Genus\n##  colnames(27): A110 A111 ... A38 A39\n##  colData names(0):\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n\nThe assays slot includes a list of abundance tables. The imported abundance table is named as ‚Äúcounts‚Äù. Let us inspect only the first cols and rows.\n\nassay(tse, \"counts\")[1:3, 1:3]\n##            A110  A111  A12\n##  1726470  17722 11630    0\n##  1726471  12052     0 2679\n##  17264731     0   970    0\n\nThe rowdata includes taxonomic information from the biom file. The head() command shows just the beginning of the data table for an overview.\nknitr::kable() helps print the information more nicely.\n\nhead(rowData(tse))\n##  DataFrame with 6 rows and 6 columns\n##             taxonomy1          Phylum            Class              Order\n##           &lt;character&gt;     &lt;character&gt;      &lt;character&gt;        &lt;character&gt;\n##  1726470    \"Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##  1726471    \"Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##  17264731   \"Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##  17264726   \"Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##  1726472    \"Bacteria Verrucomicrobia Verrucomicrobiae Verrucomicrobiales\n##  17264724   \"Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##                        Family            Genus\n##                   &lt;character&gt;      &lt;character&gt;\n##  1726470       Bacteroidaceae     Bacteroides\"\n##  1726471       Bacteroidaceae     Bacteroides\"\n##  17264731  Porphyromonadaceae Parabacteroides\"\n##  17264726      Bacteroidaceae     Bacteroides\"\n##  1726472  Verrucomicrobiaceae     Akkermansia\"\n##  17264724      Bacteroidaceae     Bacteroides\"\n\nWe further polish the feature names by removing unnecessary characters and then replace the original rowData with its updated version.\n\n# Genus level has additional '\\\"', so let's delete that also\nrowdata_modified &lt;- BiocParallel::bplapply(rowData(tse), \n                                           FUN = stringr::str_remove, \n                                           pattern = '\\\"')\n\n# rowdata_modified is a list, so convert this back to DataFrame format. \n# and assign the cleaned data back to the TSE rowData\nrowData(tse) &lt;- DataFrame(rowdata_modified)\n\n# Now we have a nicer table\nhead(rowData(tse))\n##  DataFrame with 6 rows and 6 columns\n##             taxonomy1          Phylum            Class              Order\n##           &lt;character&gt;     &lt;character&gt;      &lt;character&gt;        &lt;character&gt;\n##  1726470     Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##  1726471     Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##  17264731    Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##  17264726    Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##  1726472     Bacteria Verrucomicrobia Verrucomicrobiae Verrucomicrobiales\n##  17264724    Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##                        Family           Genus\n##                   &lt;character&gt;     &lt;character&gt;\n##  1726470       Bacteroidaceae     Bacteroides\n##  1726471       Bacteroidaceae     Bacteroides\n##  17264731  Porphyromonadaceae Parabacteroides\n##  17264726      Bacteroidaceae     Bacteroides\n##  1726472  Verrucomicrobiaceae     Akkermansia\n##  17264724      Bacteroidaceae     Bacteroides\n\nWe notice that the imported biom file did not contain any colData yet, so only an empty dataframe appears in this slot.\n\nhead(colData(tse))\n##  DataFrame with 6 rows and 0 columns\n\nLet us add colData from the sample metadata, which is stored in a CSV file.\n\n# CSV file with colnames in the first row and rownames in the first column\nsample_meta &lt;- read.csv(sample_meta_file_path,\n                        sep = \",\", row.names = 1)\n\n# Add this sample data to colData of the taxonomic data object\n# Note that the data must be given in a DataFrame format (required for our purposes)\ncolData(tse) &lt;- DataFrame(sample_meta)\n\nNow the colData includes the sample metadata.\n\nhead(colData(tse))\n##  DataFrame with 6 rows and 4 columns\n##         Treatment      Cohort TreatmentxCohort Description\n##       &lt;character&gt; &lt;character&gt;      &lt;character&gt; &lt;character&gt;\n##  A110        ADHD    Cohort_1    ADHD_Cohort_1        A110\n##  A12         ADHD    Cohort_1    ADHD_Cohort_1         A12\n##  A15         ADHD    Cohort_1    ADHD_Cohort_1         A15\n##  A19         ADHD    Cohort_1    ADHD_Cohort_1         A19\n##  A21         ADHD    Cohort_2    ADHD_Cohort_2         A21\n##  A23         ADHD    Cohort_2    ADHD_Cohort_2         A23\n\nFinally, we add a phylogenetic tree to the rowData slot. Such feature is available only in TreeSE objects. Similarly, Trees specifying the sample hierarchy can be stored in the colTree slot.\nHere, we read in the file containing the phylogenetic tree and insert it in corresponding slot of the TreeSE object.\n\n# Reads the tree file\ntree &lt;- ape::read.tree(tree_file_path)\n\n# Add tree to rowTree\nrowTree(tse) &lt;- tree\n\n# Check\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 151 27 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(151): 1726470 1726471 ... 17264756 17264757\n##  rowData names(6): taxonomy1 Phylum ... Family Genus\n##  colnames(27): A110 A12 ... A35 A38\n##  colData names(4): Treatment Cohort TreatmentxCohort Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (151 rows)\n##  rowTree: 1 phylo tree(s) (151 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nNow the rowTree slot contains the phylogenetic tree:\n\nhead(rowTree(tse))\n\n\n2.4.6 Conversions between data formats in R\nIf the data has already been imported in R in another format, it can be readily converted into TreeSummarizedExperiment, as shown in our next example. Note that similar conversion functions to TreeSummarizedExperiment are available for multiple data formats via the mia package (see makeTreeSummarizedExperimentFrom* for phyloseq, Biom, and DADA2).\n\nlibrary(mia)\n\n# phyloseq example data\ndata(GlobalPatterns, package=\"phyloseq\") \nGlobalPatterns_phyloseq &lt;- GlobalPatterns\nGlobalPatterns_phyloseq\n##  phyloseq-class experiment-level object\n##  otu_table()   OTU Table:         [ 19216 taxa and 26 samples ]\n##  sample_data() Sample Data:       [ 26 samples by 7 sample variables ]\n##  tax_table()   Taxonomy Table:    [ 19216 taxa by 7 taxonomic ranks ]\n##  phy_tree()    Phylogenetic Tree: [ 19216 tips and 19215 internal nodes ]\n\n\n# convert phyloseq to TSE\nGlobalPatterns_TSE &lt;- makeTreeSummarizedExperimentFromPhyloseq(GlobalPatterns_phyloseq) \nGlobalPatterns_TSE\n##  class: TreeSummarizedExperiment \n##  dim: 19216 26 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(19216): 549322 522457 ... 200359 271582\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (19216 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nWe can also convert TreeSummarizedExperiment objects into phyloseq with respect to the shared components that are supported by both formats (i.e.¬†taxonomic abundance table, sample metadata, taxonomic table, phylogenetic tree, sequence information). This is useful for instance when additional methods are available for phyloseq.\n\n# convert TSE to phyloseq\nGlobalPatterns_phyloseq2 &lt;- makePhyloseqFromTreeSummarizedExperiment(GlobalPatterns_TSE) \nGlobalPatterns_phyloseq2\n##  phyloseq-class experiment-level object\n##  otu_table()   OTU Table:         [ 19216 taxa and 26 samples ]\n##  sample_data() Sample Data:       [ 26 samples by 7 sample variables ]\n##  tax_table()   Taxonomy Table:    [ 19216 taxa by 7 taxonomic ranks ]\n##  phy_tree()    Phylogenetic Tree: [ 19216 tips and 19215 internal nodes ]\n\nConversion is possible between other data formats. Interested readers can refer to the following functions:\n\n\nmakeTreeSummarizedExperimentFromDADA2\n\n\nmakeSummarizedExperimentFromBiom\n\n\nloadFromMetaphlan\n\nreadQZA"
  },
  {
    "objectID": "pages/10_manipulation.html#tidying-and-subsetting",
    "href": "pages/10_manipulation.html#tidying-and-subsetting",
    "title": "3¬† Data Manipulation",
    "section": "\n3.1 Tidying and subsetting",
    "text": "3.1 Tidying and subsetting\n\n3.1.1 Tidy data\nFor several custom analysis and visualization packages, such as those from tidyverse, the SE data can be converted to a long data.frame format with meltAssay.\n\nlibrary(mia)\ndata(GlobalPatterns, package=\"mia\")\ntse &lt;- GlobalPatterns\ntse &lt;- transformAssay(tse, MARGIN = \"samples\", method=\"relabundance\")\nmolten_tse &lt;- mia::meltAssay(tse,\n                        add_row_data = TRUE,\n                        add_col_data = TRUE,\n                        assay.type = \"relabundance\")\nmolten_tse\n##  # A tibble: 499,616 √ó 17\n##    FeatureID SampleID relabundance Kingdom Phylum        Class        Order\n##    &lt;fct&gt;     &lt;fct&gt;           &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt;        &lt;chr&gt;\n##  1 549322    CL3                 0 Archaea Crenarchaeota Thermoprotei &lt;NA&gt; \n##  2 549322    CC1                 0 Archaea Crenarchaeota Thermoprotei &lt;NA&gt; \n##  3 549322    SV1                 0 Archaea Crenarchaeota Thermoprotei &lt;NA&gt; \n##  4 549322    M31Fcsw             0 Archaea Crenarchaeota Thermoprotei &lt;NA&gt; \n##  5 549322    M11Fcsw             0 Archaea Crenarchaeota Thermoprotei &lt;NA&gt; \n##  6 549322    M31Plmr             0 Archaea Crenarchaeota Thermoprotei &lt;NA&gt; \n##  # ‚Ñπ 499,610 more rows\n##  # ‚Ñπ 10 more variables: Family &lt;chr&gt;, Genus &lt;chr&gt;, Species &lt;chr&gt;, ‚Ä¶\n\n\n3.1.2 Subsetting\nSubsetting data helps to draw the focus of analysis on particular sets of samples and / or features. When dealing with large datasets, the subset of interest can be extracted and investigated separately. This might improve performance and reduce the computational load.\nLoad:\n\nmia\ndplyr\nknitr\ndata GlobalPatterns\n\n\nLet us store GlobalPatterns into tse and check its original number of features (rows) and samples (columns). Note: when subsetting by sample, expect the number of columns to decrease; when subsetting by feature, expect the number of rows to decrease.\n\n# Store data into se and check dimensions\ndata(\"GlobalPatterns\", package=\"mia\")\ntse &lt;- GlobalPatterns\n# Show dimensions (features x samples)\ndim(tse) \n##  [1] 19216    26\n\n\n3.1.2.1 Subset by sample (column-wise)\nFor the sake of demonstration, here we will extract a subset containing only the samples of human origin (feces, skin or tongue), stored as SampleType within colData(tse) and also in tse.\nFirst, we would like to see all the possible values that SampleType can take on and how frequent those are:\n\n# Inspect possible values for SampleType\nunique(tse$SampleType)\n##  [1] Soil               Feces              Skin              \n##  [4] Tongue             Freshwater         Freshwater (creek)\n##  [7] Ocean              Sediment (estuary) Mock              \n##  9 Levels: Feces Freshwater Freshwater (creek) Mock ... Tongue\n\n\n# Show the frequency of each value\ntse$SampleType %&gt;% table()\n\n\n\n\n\n\n.\nFreq\n\n\n\nFeces\n4\n\n\nFreshwater\n2\n\n\nFreshwater (creek)\n3\n\n\nMock\n3\n\n\nOcean\n3\n\n\nSediment (estuary)\n3\n\n\nSkin\n3\n\n\nSoil\n3\n\n\nTongue\n2\n\n\n\n\n\n\n\nNote: after subsetting, expect the number of columns to equal the sum of the frequencies of the samples that you are interested in. For instance, ncols = Feces + Skin + Tongue = 4 + 3 + 2 = 9.\nNext, we logical index across the columns of tse (make sure to leave the first index empty to select all rows) and filter for the samples of human origin. For this, we use the information on the samples from the meta data colData(tse).\n\n# Subset by sample\ntse_subset_by_sample &lt;- tse[ , tse$SampleType %in% c(\"Feces\", \"Skin\", \"Tongue\")]\n\n# Show dimensions\ndim(tse_subset_by_sample)\n##  [1] 19216     9\n\nAs a sanity check, the new object tse_subset_by_sample should have the original number of features (rows) and a number of samples (columns) equal to the sum of the samples of interest (in this case 9).\nSeveral characteristics can be used to subset by sample:\n\norigin\nsampling time\nsequencing method\nDNA / RNA barcode\ncohort\n\n3.1.2.2 Subset by feature (row-wise)\nSimilarly, here we will extract a subset containing only the features that belong to the phyla Actinobacteria and Chlamydiae, stored as Phylum within rowData(tse). However, subsetting by feature implies a few more obstacles, such as the presence of NA elements and the possible need for agglomeration.\nAs previously, we would first like to see all the possible values that Phylum can take on and how frequent those are:\n\n# Inspect possible values for phylum\nunique(rowData(tse)$Phylum)\n##   [1] \"Crenarchaeota\"    \"Euryarchaeota\"    \"Actinobacteria\"  \n##   [4] \"Spirochaetes\"     \"MVP-15\"           \"Proteobacteria\"  \n##   [7] \"SBR1093\"          \"Fusobacteria\"     \"Tenericutes\"     \n##  [10] \"ZB3\"              \"Cyanobacteria\"    \"GOUTA4\"          \n##  [13] \"TG3\"              \"Chlorobi\"         \"Bacteroidetes\"   \n##  [16] \"Caldithrix\"       \"KSB1\"             \"SAR406\"          \n##  [19] \"LCP-89\"           \"Thermi\"           \"Gemmatimonadetes\"\n##  [22] \"Fibrobacteres\"    \"GN06\"             \"AC1\"             \n##  [25] \"TM6\"              \"OP8\"              \"Elusimicrobia\"   \n##  [28] \"NC10\"             \"SPAM\"             NA                \n##  [31] \"Acidobacteria\"    \"CCM11b\"           \"Nitrospirae\"     \n##  [34] \"NKB19\"            \"BRC1\"             \"Hyd24-12\"        \n##  [37] \"WS3\"              \"PAUC34f\"          \"GN04\"            \n##  [40] \"GN12\"             \"Verrucomicrobia\"  \"Lentisphaerae\"   \n##  [43] \"LD1\"              \"Chlamydiae\"       \"OP3\"             \n##  [46] \"Planctomycetes\"   \"Firmicutes\"       \"OP9\"             \n##  [49] \"WPS-2\"            \"Armatimonadetes\"  \"SC3\"             \n##  [52] \"TM7\"              \"GN02\"             \"SM2F11\"          \n##  [55] \"ABY1_OD1\"         \"ZB2\"              \"OP11\"            \n##  [58] \"Chloroflexi\"      \"SC4\"              \"WS1\"             \n##  [61] \"GAL15\"            \"AD3\"              \"WS2\"             \n##  [64] \"Caldiserica\"      \"Thermotogae\"      \"Synergistetes\"   \n##  [67] \"SR1\"\n\n\n# Show the frequency of each value\nrowData(tse)$Phylum %&gt;% table()\n\n\n\n\n\n\n.\nFreq\n\n\n\nABY1_OD1\n7\n\n\nAC1\n1\n\n\nAD3\n9\n\n\nAcidobacteria\n1021\n\n\nActinobacteria\n1631\n\n\nArmatimonadetes\n61\n\n\nBRC1\n13\n\n\nBacteroidetes\n2382\n\n\nCCM11b\n2\n\n\nCaldiserica\n3\n\n\nCaldithrix\n10\n\n\nChlamydiae\n21\n\n\nChlorobi\n64\n\n\nChloroflexi\n437\n\n\nCrenarchaeota\n106\n\n\nCyanobacteria\n393\n\n\nElusimicrobia\n31\n\n\nEuryarchaeota\n102\n\n\nFibrobacteres\n7\n\n\nFirmicutes\n4356\n\n\nFusobacteria\n37\n\n\nGAL15\n2\n\n\nGN02\n8\n\n\nGN04\n7\n\n\nGN06\n2\n\n\nGN12\n1\n\n\nGOUTA4\n11\n\n\nGemmatimonadetes\n191\n\n\nHyd24-12\n4\n\n\nKSB1\n6\n\n\nLCP-89\n2\n\n\nLD1\n2\n\n\nLentisphaerae\n21\n\n\nMVP-15\n5\n\n\nNC10\n9\n\n\nNKB19\n16\n\n\nNitrospirae\n74\n\n\nOP11\n6\n\n\nOP3\n30\n\n\nOP8\n27\n\n\nOP9\n4\n\n\nPAUC34f\n3\n\n\nPlanctomycetes\n638\n\n\nProteobacteria\n6416\n\n\nSAR406\n21\n\n\nSBR1093\n9\n\n\nSC3\n8\n\n\nSC4\n8\n\n\nSM2F11\n5\n\n\nSPAM\n22\n\n\nSR1\n5\n\n\nSpirochaetes\n124\n\n\nSynergistetes\n7\n\n\nTG3\n5\n\n\nTM6\n27\n\n\nTM7\n32\n\n\nTenericutes\n143\n\n\nThermi\n46\n\n\nThermotogae\n1\n\n\nVerrucomicrobia\n470\n\n\nWPS-2\n20\n\n\nWS1\n5\n\n\nWS2\n2\n\n\nWS3\n70\n\n\nZB2\n2\n\n\nZB3\n2\n\n\n\n\n\n\n\nNote: after subsetting, expect the number of columns to equal the sum of the frequencies of the feature(s) that you are interested in. For instance, nrows = Actinobacteria + Chlamydiae = 1631 + 21 =   1652.\nDepending on your research question, you might or might not need to agglomerate the data in the first place: if you want to find the abundance of each and every feature that belongs to Actinobacteria and Chlamydiae, agglomeration is not needed; if you want to find the total abundance of all features that belong to Actinobacteria or Chlamydiae, agglomeration is recommended.\n\n3.1.2.2.1 Non-agglomerated data\nNext, we logical index across the rows of tse (make sure to leave the second index empty to select all columns) and filter for the features that fall in either Actinobacteria or Chlamydiae group. For this, we use the information on the samples from the metadata rowData(tse).\nThe first term with the %in% operator includes all the features of interest, whereas the second term after the AND operator & filters out all features that have an NA in place of the phylum variable.\n\n# Subset by feature\ntse_subset_by_feature &lt;- tse[rowData(tse)$Phylum %in% c(\"Actinobacteria\", \"Chlamydiae\") & !is.na(rowData(tse)$Phylum), ]\n\n# Show dimensions\ndim(tse_subset_by_feature)\n##  [1] 1652   26\n\nAs a sanity check, the new object, tse_subset_by_feature, should have the original number of samples (columns) and a number of features (rows) equal to the sum of the features of interest (in this case, 1652).\n\n3.1.2.2.2 Agglomerated data\nWhen total abundances of certain phyla are of relevance, the data is initially agglomerated by Phylum. Then, similar steps as in the case of non-agglomerated data are followed.\n\n# Agglomerate by phylum\ntse_phylum &lt;- tse %&gt;% mergeFeaturesByRank(rank = \"Phylum\")\n\n# Subset by feature and remove NAs\ntse_phylum_subset_by_feature &lt;- tse_phylum[rowData(tse_phylum)$Phylum %in% c(\"Actinobacteria\", \"Chlamydiae\") & !is.na(rowData(tse_phylum)$Phylum), ]\n\n# Show dimensions\ndim(tse_phylum_subset_by_feature)\n##  [1]  2 26\n\nNote: as data was agglomerated, the number of rows should equal the number of phyla used to index (in this case, just 2).\nAlternatively:\n\n# Store features of interest into phyla\nphyla &lt;- c(\"Phylum:Actinobacteria\", \"Phylum:Chlamydiae\")\n# subset by feature\ntse_phylum_subset_by_feature &lt;- tse_phylum[phyla, ]\n# Show dimensions\ndim(tse_subset_by_feature)\n##  [1] 1652   26\n\nThe code above returns the non-agglomerated version of the data.\nFewer characteristics can be used to subset by feature:\n\nTaxonomic rank\nMeta-taxonomic group\n\nFor subsetting by kingdom, agglomeration does not apply, whereas for the other ranks it can be applied if necessary.\n\n3.1.2.3 Subset by sample and feature\nFinally, we can subset data by sample and feature at once. The resulting subset contains all the samples of human origin and all the features of phyla Actinobacteria or Chlamydiae.\n\n# Subset by sample and feature and remove NAs\ntse_subset_by_sample_feature &lt;- tse[rowData(tse)$Phylum %in% c(\"Actinobacteria\", \"Chlamydiae\") & !is.na(rowData(tse)$Phylum), tse$SampleType %in% c(\"Feces\", \"Skin\", \"Tongue\")]\n\n# Show dimensions\ndim(tse_subset_by_sample_feature)\n##  [1] 1652    9\n\nNote: the dimensions of tse_subset_by_sample_feature agree with those of the previous subsets (9 columns filtered by sample and 1652 rows filtered by feature).\nIf a study was to consider and quantify the presence of Actinobacteria as well as Chlamydiae in different sites of the human body, tse_subset_by_sample_feature might be a suitable subset to start with.\n\n3.1.2.4 Remove empty columns and rows\nSometimes data might contain, e.g., features that are not present in any of the samples. This can occur, for example, after the data subsetting. In certain analyses, we might want to remove those instances.\n\n# Agglomerate data at Genus level \ntse_genus &lt;- mergeFeaturesByRank(tse, rank = \"Genus\")\n# List bacteria that we want to include\ngenera &lt;- c(\"Class:Thermoprotei\", \"Genus:Sulfolobus\", \"Genus:Sediminicola\")\n# Subset data\ntse_genus_sub &lt;- tse_genus[genera, ]\n\ntse_genus_sub\n##  class: TreeSummarizedExperiment \n##  dim: 3 26 \n##  metadata(1): agglomerated_by_rank\n##  assays(1): counts\n##  rownames(3): Class:Thermoprotei Genus:Sulfolobus Genus:Sediminicola\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (3 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\n\n# List total counts of each sample\ncolSums(assay(tse_genus_sub, \"counts\"))\n##       CL3      CC1      SV1  M31Fcsw  M11Fcsw  M31Plmr  M11Plmr  F21Plmr \n##         1        0        0        1        1        0        4        1 \n##   M31Tong  M11Tong LMEpi24M SLEpi20M   AQC1cm   AQC4cm   AQC7cm      NP2 \n##         7        3        0        2       64      105      136      222 \n##       NP3      NP5  TRRsed1  TRRsed2  TRRsed3     TS28     TS29    Even1 \n##      6433     1154        2        2        2        0        0        0 \n##     Even2    Even3 \n##         2        0\n\nNow we can see that certain samples do not include any bacteria. We can remove those.\n\n# Remove samples that do not contain any bacteria\ntse_genus_sub &lt;- tse_genus_sub[ , colSums(assay(tse_genus_sub, \"counts\")) != 0 ]\ntse_genus_sub\n##  class: TreeSummarizedExperiment \n##  dim: 3 18 \n##  metadata(1): agglomerated_by_rank\n##  assays(1): counts\n##  rownames(3): Class:Thermoprotei Genus:Sulfolobus Genus:Sediminicola\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(18): CL3 M31Fcsw ... TRRsed3 Even2\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (3 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nThe same action can also be applied to the features.\n\n# Take only those samples that are collected from feces, skin, or tongue\ntse_genus_sub &lt;- tse_genus[ , tse_genus$SampleType %in% c(\"Feces\", \"Skin\", \"Tongue\")]\n\ntse_genus_sub\n##  class: TreeSummarizedExperiment \n##  dim: 1516 9 \n##  metadata(1): agglomerated_by_rank\n##  assays(1): counts\n##  rownames(1516): Class:Thermoprotei Genus:Sulfolobus ...\n##    Genus:Coprothermobacter Phylum:SR1\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(9): M31Fcsw M11Fcsw ... TS28 TS29\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (1516 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\n\n# What is the number of bacteria that are not present?\nsum(rowSums(assay(tse_genus_sub, \"counts\")) == 0)\n##  [1] 435\n\nWe can see that there are bacteria that are not present in these samples we chose. We can remove those bacteria from the data.\n\n# Take only those bacteria that are present\ntse_genus_sub &lt;- tse_genus_sub[rowSums(assay(tse_genus_sub, \"counts\")) &gt; 0, ]\n\ntse_genus_sub\n##  class: TreeSummarizedExperiment \n##  dim: 1081 9 \n##  metadata(1): agglomerated_by_rank\n##  assays(1): counts\n##  rownames(1081): Genus:Sulfolobus Order:NRP-J ...\n##    Genus:Coprothermobacter Phylum:SR1\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(9): M31Fcsw M11Fcsw ... TS28 TS29\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (1081 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\n\n3.1.3 Splitting\nYou can split the data based on variables by using the functions splitByRanks and splitOn.\nsplitByRanks splits the data based on taxonomic ranks. Since the elements of the output list share columns, they can be stored into altExp.\n\naltExps(tse) &lt;- splitByRanks(tse)\naltExps(tse)\n##  List of length 7\n##  names(7): Kingdom Phylum Class Order Family Genus Species\n\nIf you want to split the data based on another variable than taxonomic rank, use splitOn. It works for row-wise and column-wise splitting.\n\nsplitOn(tse, \"SampleType\")\n##  List of length 9\n##  names(9): Soil Feces Skin Tongue ... Ocean Sediment (estuary) Mock"
  },
  {
    "objectID": "pages/10_manipulation.html#add-or-modify-data",
    "href": "pages/10_manipulation.html#add-or-modify-data",
    "title": "3¬† Data Manipulation",
    "section": "\n3.2 Add or modify data",
    "text": "3.2 Add or modify data\nThe information contained by the colData of a TreeSE can be modified by accessing the desired variables.\n\n# modify the Description entries\ncolData(tse)$Description &lt;- paste(colData(tse)$Description, \"modified description\")\n\n# view modified variable\nhead(tse$Description)\n##  [1] \"Calhoun South Carolina Pine soil, pH 4.9 modified description\"  \n##  [2] \"Cedar Creek Minnesota, grassland, pH 6.1 modified description\"  \n##  [3] \"Sevilleta new Mexico, desert scrub, pH 8.3 modified description\"\n##  [4] \"M3, Day 1, fecal swab, whole body study modified description\"   \n##  [5] \"M1, Day 1, fecal swab, whole body study  modified description\"  \n##  [6] \"M3, Day 1, right palm, whole body study modified description\"\n\nNew information can also be added to the experiment by creating a new variable.\n\n# simulate new data\nnew_data &lt;- runif(ncol(tse))\n\n# store new data as new variable in colData\ncolData(tse)$NewVariable &lt;- new_data\n\n# view new variable\nhead(tse$NewVariable)\n##  [1] 0.657163 0.003116 0.186356 0.636827 0.577807 0.937516"
  },
  {
    "objectID": "pages/10_manipulation.html#merge-data",
    "href": "pages/10_manipulation.html#merge-data",
    "title": "3¬† Data Manipulation",
    "section": "\n3.3 Merge data",
    "text": "3.3 Merge data\nmia package has mergeSEs function that merges multiple SummarizedExperiment objects. For example, it is possible to combine multiple TreeSE objects which each includes one sample.\nmergeSEs works like dplyr joining functions. In fact, there are available dplyr-like aliases of mergeSEs, such as full_join.\n\n# Take subsets for demonstration purposes\ntse1 &lt;- tse[, 1]\ntse2 &lt;- tse[, 2]\ntse3 &lt;- tse[, 3]\ntse4 &lt;- tse[1:100, 4]\n\n\n# With inner join, we want to include all shared rows. When using mergeSEs function\n# all samples are always preserved.\ntse &lt;- mergeSEs(list(tse1, tse2, tse3, tse4), join = \"inner\")\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 100 4 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(100): 239672 243675 ... 104332 159421\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(4): CC1 CL3 M31Fcsw SV1\n##  colData names(8): X.SampleID Primer ... Description NewVariable\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (100 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\n\n# Left join preserves all rows of the 1st object\ntse &lt;- mia::left_join(tse1, tse4, missing_values = 0)\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 19216 2 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(19216): 239672 243675 ... 239967 254851\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(2): CL3 M31Fcsw\n##  colData names(8): X.SampleID Primer ... Description NewVariable\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (19216 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\n\n3.3.1 Additional functions\n\n\nmapTaxonomy\n\nmergeFeatures/mergeSamples"
  },
  {
    "objectID": "pages/12_quality_control.html#abundance",
    "href": "pages/12_quality_control.html#abundance",
    "title": "4¬† Exploration and Quality Control",
    "section": "\n4.1 Abundance",
    "text": "4.1 Abundance\nAbundance visualization is an important data exploration approach. miaViz offers the function plotAbundanceDensity to plot the most abundant taxa with several options.\nNext, a few demonstrations are shown, using the (Lahti et al. 2014) dataset. A Jitter plot based on relative abundance data, similar to the one presented at (Salosensaari et al. 2021) supplementary figure 1, could be visualized as follows:\n\nLahti, L, JSaloj√§rvi, A Salonen, M Scheffer, and WM de Vos. 2014. ‚ÄúTipping Elements in the Human Intestinal Ecosystem.‚Äù Nature Communications 2014: 1‚Äì10. https://doi.org/https://doi.org/10.1038/ncomms5344.\n\nSalosensaari, Aaro, Ville Laitinen, Aki Havulinna, Guillaume M√©ric, Susan Cheng, Markus Perola, Liisa Valsta, et al. 2021. ‚ÄúTaxonomic Signatures of Cause-Specific Mortality Risk in Human Gut Microbiome.‚Äù Nature Communications 12: 1‚Äì8. https://www.nature.com/articles/s41467-021-22962-y.\n\n# Load example data\nlibrary(miaTime)\nlibrary(miaViz)\ndata(hitchip1006)\ntse &lt;- hitchip1006\n\n# Add relative abundances\ntse &lt;- transformAssay(tse, MARGIN = \"samples\", method = \"relabundance\")\n\n# Use argument names\n# assay.type / assay.type / assay.type\n# depending on the mia package version\nplotAbundanceDensity(tse, layout = \"jitter\", assay.type = \"relabundance\",\n                     n = 40, point_size=1, point_shape=19, point_alpha=0.1) + \n                     scale_x_log10(label=scales::percent)\n\n\n\n\n\n\n\nThe relative abundance values for the top-5 taxonomic features can be visualized as a density plot over a log scaled axis, with ‚Äúnationality‚Äù indicated by colors:\n\nplotAbundanceDensity(tse, layout = \"density\", assay.type = \"relabundance\",\n                     n = 5, colour_by=\"nationality\", point_alpha=1/10) +\n    scale_x_log10()"
  },
  {
    "objectID": "pages/12_quality_control.html#prevalence",
    "href": "pages/12_quality_control.html#prevalence",
    "title": "4¬† Exploration and Quality Control",
    "section": "\n4.2 Prevalence",
    "text": "4.2 Prevalence\nPrevalence quantifies the frequency of samples where certain microbes were detected (above a given detection threshold). The prevalence can be given as sample size (N) or percentage (unit interval).\nInvestigating prevalence allows you either to focus on changes which pertain to the majority of the samples, or identify rare microbes, which may be conditionally abundant in a small number of samples.\nThe population prevalence (frequency) at a 1% relative abundance threshold (detection = 1/100 and as_relative = TRUE), can look like this.\n\nhead(getPrevalence(tse, detection = 1/100, sort = TRUE, as_relative = TRUE))\n##  Faecalibacterium prausnitzii et rel.           Ruminococcus obeum et rel. \n##                                0.9522                               0.9140 \n##    Oscillospira guillermondii et rel.        Clostridium symbiosum et rel. \n##                                0.8801                               0.8714 \n##      Subdoligranulum variable at rel.     Clostridium orbiscindens et rel. \n##                                0.8358                               0.8315\n\nThe function arguments detection and as_relative can also be used to access, how many samples do pass a threshold for raw counts. Here, the population prevalence (frequency) at the absolute abundance threshold (as_relative = FALSE) at read count 1 (detection = 1) is accessed.\n\nhead(getPrevalence(tse, detection = 1, sort = TRUE, assay.type = \"counts\",\n                   as_relative = FALSE))\n##             Uncultured Mollicutes      Uncultured Clostridiales II \n##                                 1                                1 \n##        Uncultured Clostridiales I               Tannerella et rel. \n##                                 1                                1 \n##    Sutterella wadsworthia et rel. Subdoligranulum variable at rel. \n##                                 1                                1\n\nIf the output should be used for subsetting or storing the data in the rowData, set sort = FALSE.\n\n4.2.1 Prevalence analysis\nTo investigate microbiome prevalence at a selected taxonomic level, two approaches are available.\nFirst the data can be agglomerated to the taxonomic level and getPrevalence applied on the resulting object.\n\n# Agglomerate taxa abundances to Phylum level, and add the new table\n# to the altExp slot\naltExp(tse,\"Phylum\") &lt;- mergeFeaturesByRank(tse, \"Phylum\")\n# Check prevalence for the Phylum abundance table from the altExp slot\nhead(getPrevalence(altExp(tse,\"Phylum\"), detection = 1/100, sort = TRUE,\n                   assay.type = \"counts\", as_relative = TRUE))\n##       Firmicutes   Bacteroidetes  Actinobacteria  Proteobacteria \n##        1.0000000       0.9852302       0.4821894       0.2988705 \n##  Verrucomicrobia   Cyanobacteria \n##        0.1277150       0.0008688\n\nAlternatively, the rank argument could be set to perform the agglomeration on the fly.\n\nhead(getPrevalence(tse, rank = \"Phylum\", detection = 1/100, sort = TRUE,\n                   assay.type = \"counts\", as_relative = TRUE))\n##       Firmicutes   Bacteroidetes  Actinobacteria  Proteobacteria \n##        1.0000000       0.9852302       0.4821894       0.2988705 \n##  Verrucomicrobia   Cyanobacteria \n##        0.1277150       0.0008688\n\nNote that, by default, na.rm = TRUE is used for agglomeration in getPrevalence, whereas the default for mergeFeaturesByRank is FALSE to prevent accidental data loss.\nIf you only need the names of the prevalent taxa, getPrevalentFeatures is available. This returns the taxa that exceed the given prevalence and detection thresholds.\n\ngetPrevalentFeatures(tse, detection = 0, prevalence = 50/100)\nprev &lt;- getPrevalentFeatures(tse, detection = 0, prevalence = 50/100,\n                         rank = \"Phylum\", sort = TRUE)\nprev\n\nNote that the detection and prevalence thresholds are not the same, since detection can be applied to relative counts or absolute counts depending on whether as_relative is set TRUE or FALSE\nThe function ‚ÄògetPrevalentAbundance‚Äô can be used to check the total relative abundance of the prevalent taxa (between 0 and 1).\n\n4.2.2 Rare taxa\nRelated functions are available for the analysis of rare taxa (rareMembers; rareAbundance; lowAbundance, getRareFeatures, subsetByRareFeatures).\n\n4.2.3 Plotting prevalence\nTo plot the prevalence, add the prevalence of each taxon to rowData. Here, we are analysing the Phylum level abundances, which are stored in the altExp slot.\n\nrowData(altExp(tse,\"Phylum\"))$prevalence &lt;- \n    getPrevalence(altExp(tse,\"Phylum\"), detection = 1/100, sort = FALSE,\n                  assay.type = \"counts\", as_relative = TRUE)\n\nThe prevalences can then be plotted using the plotting functions from the scater package.\n\nlibrary(scater)\nplotRowData(altExp(tse,\"Phylum\"), \"prevalence\", colour_by = \"Phylum\")\n\n\n\n\n\n\n\nThe prevalence can also be visualized on the taxonomic tree with the miaViz package.\n\naltExps(tse) &lt;- splitByRanks(tse)\naltExps(tse) &lt;-\n   lapply(altExps(tse),\n          function(y){\n              rowData(y)$prevalence &lt;- \n                  getPrevalence(y, detection = 1/100, sort = FALSE,\n                                assay.type = \"counts\", as_relative = TRUE)\n              y\n          })\ntop_phyla &lt;- getTopFeatures(altExp(tse,\"Phylum\"),\n                        method=\"prevalence\",\n                        top=5L,\n                        assay.type=\"counts\")\ntop_phyla_mean &lt;- getTopFeatures(altExp(tse,\"Phylum\"),\n                             method=\"mean\",\n                             top=5L,\n                             assay.type=\"counts\")\nx &lt;- unsplitByRanks(tse, ranks = taxonomyRanks(tse)[1:6])\nx &lt;- addTaxonomyTree(x)\n\nAfter some preparation, the data is assembled and can be plotted with plotRowTree.\n\nlibrary(miaViz)\nplotRowTree(x[rowData(x)$Phylum %in% top_phyla,],\n            edge_colour_by = \"Phylum\",\n            tip_colour_by = \"prevalence\",\n            node_colour_by = \"prevalence\")\n\n\n\nPrevalence of top phyla as judged by prevalence\n\n\n\n\nplotRowTree(x[rowData(x)$Phylum %in% top_phyla_mean,],\n            edge_colour_by = \"Phylum\",\n            tip_colour_by = \"prevalence\",\n            node_colour_by = \"prevalence\")\n\n\n\nPrevalence of top phyla as judged by mean abundance"
  },
  {
    "objectID": "pages/12_quality_control.html#sec-qc",
    "href": "pages/12_quality_control.html#sec-qc",
    "title": "4¬† Exploration and Quality Control",
    "section": "\n4.3 Quality control",
    "text": "4.3 Quality control\nNext, let us load the GlobalPatterns dataset to illustrate standard microbiome data summaries.\n\nlibrary(mia)\ndata(\"GlobalPatterns\", package=\"mia\")\ntse &lt;- GlobalPatterns \n\n\n4.3.1 Top taxa\nThe getTopFeatures identifies top taxa in the data.\n\n# Pick the top taxa\ntop_features &lt;- getTopFeatures(tse, method=\"median\", top=10)\n\n# Check the information for these\nrowData(tse)[top_features, taxonomyRanks(tse)]\n##  DataFrame with 10 rows and 7 columns\n##             Kingdom         Phylum               Class             Order\n##         &lt;character&gt;    &lt;character&gt;         &lt;character&gt;       &lt;character&gt;\n##  549656    Bacteria  Cyanobacteria         Chloroplast     Stramenopiles\n##  331820    Bacteria  Bacteroidetes         Bacteroidia     Bacteroidales\n##  317182    Bacteria  Cyanobacteria         Chloroplast     Stramenopiles\n##  94166     Bacteria Proteobacteria Gammaproteobacteria    Pasteurellales\n##  279599    Bacteria  Cyanobacteria    Nostocophycideae        Nostocales\n##  158660    Bacteria  Bacteroidetes         Bacteroidia     Bacteroidales\n##  329744    Bacteria Actinobacteria      Actinobacteria   Actinomycetales\n##  326977    Bacteria Actinobacteria      Actinobacteria Bifidobacteriales\n##  248140    Bacteria  Bacteroidetes         Bacteroidia     Bacteroidales\n##  550960    Bacteria Proteobacteria Gammaproteobacteria Enterobacteriales\n##                     Family           Genus                Species\n##                &lt;character&gt;     &lt;character&gt;            &lt;character&gt;\n##  549656                 NA              NA                     NA\n##  331820     Bacteroidaceae     Bacteroides                     NA\n##  317182                 NA              NA                     NA\n##  94166     Pasteurellaceae     Haemophilus Haemophilusparainflu..\n##  279599        Nostocaceae  Dolichospermum                     NA\n##  158660     Bacteroidaceae     Bacteroides                     NA\n##  329744             ACK-M1              NA                     NA\n##  326977 Bifidobacteriaceae Bifidobacterium Bifidobacteriumadole..\n##  248140     Bacteroidaceae     Bacteroides      Bacteroidescaccae\n##  550960 Enterobacteriaceae     Providencia                     NA\n\n\n4.3.2 Library size / read count\nThe total counts/sample can be calculated using perCellQCMetrics/addPerCellQC from the scater package. The former one just calculates the values, whereas the latter one directly adds them to colData.\n\nlibrary(scater)\nperCellQCMetrics(tse)\n##  DataFrame with 26 rows and 3 columns\n##                sum  detected     total\n##          &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt;\n##  CL3        864077      6964    864077\n##  CC1       1135457      7679   1135457\n##  SV1        697509      5729    697509\n##  M31Fcsw   1543451      2667   1543451\n##  M11Fcsw   2076476      2574   2076476\n##  ...           ...       ...       ...\n##  TS28       937466      2679    937466\n##  TS29      1211071      2629   1211071\n##  Even1     1216137      4213   1216137\n##  Even2      971073      3130    971073\n##  Even3     1078241      2776   1078241\ntse &lt;- addPerCellQC(tse)\ncolData(tse)\n##  DataFrame with 26 rows and 10 columns\n##          X.SampleID   Primer Final_Barcode Barcode_truncated_plus_T\n##            &lt;factor&gt; &lt;factor&gt;      &lt;factor&gt;                 &lt;factor&gt;\n##  CL3        CL3      ILBC_01        AACGCA                   TGCGTT\n##  CC1        CC1      ILBC_02        AACTCG                   CGAGTT\n##  SV1        SV1      ILBC_03        AACTGT                   ACAGTT\n##  M31Fcsw    M31Fcsw  ILBC_04        AAGAGA                   TCTCTT\n##  M11Fcsw    M11Fcsw  ILBC_05        AAGCTG                   CAGCTT\n##  ...            ...      ...           ...                      ...\n##  TS28         TS28   ILBC_25        ACCAGA                   TCTGGT\n##  TS29         TS29   ILBC_26        ACCAGC                   GCTGGT\n##  Even1        Even1  ILBC_27        ACCGCA                   TGCGGT\n##  Even2        Even2  ILBC_28        ACCTCG                   CGAGGT\n##  Even3        Even3  ILBC_29        ACCTGT                   ACAGGT\n##          Barcode_full_length SampleType\n##                     &lt;factor&gt;   &lt;factor&gt;\n##  CL3             CTAGCGTGCGT      Soil \n##  CC1             CATCGACGAGT      Soil \n##  SV1             GTACGCACAGT      Soil \n##  M31Fcsw         TCGACATCTCT      Feces\n##  M11Fcsw         CGACTGCAGCT      Feces\n##  ...                     ...        ...\n##  TS28            GCATCGTCTGG      Feces\n##  TS29            CTAGTCGCTGG      Feces\n##  Even1           TGACTCTGCGG      Mock \n##  Even2           TCTGATCGAGG      Mock \n##  Even3           AGAGAGACAGG      Mock \n##                                         Description       sum  detected\n##                                            &lt;factor&gt; &lt;numeric&gt; &lt;numeric&gt;\n##  CL3     Calhoun South Carolina Pine soil, pH 4.9      864077      6964\n##  CC1     Cedar Creek Minnesota, grassland, pH 6.1     1135457      7679\n##  SV1     Sevilleta new Mexico, desert scrub, pH 8.3    697509      5729\n##  M31Fcsw M3, Day 1, fecal swab, whole body study      1543451      2667\n##  M11Fcsw M1, Day 1, fecal swab, whole body study      2076476      2574\n##  ...                                            ...       ...       ...\n##  TS28                                       Twin #1    937466      2679\n##  TS29                                       Twin #2   1211071      2629\n##  Even1                                      Even1     1216137      4213\n##  Even2                                      Even2      971073      3130\n##  Even3                                      Even3     1078241      2776\n##              total\n##          &lt;numeric&gt;\n##  CL3        864077\n##  CC1       1135457\n##  SV1        697509\n##  M31Fcsw   1543451\n##  M11Fcsw   2076476\n##  ...           ...\n##  TS28       937466\n##  TS29      1211071\n##  Even1     1216137\n##  Even2      971073\n##  Even3     1078241\n\nThe distribution of calculated library sizes can be visualized as a histogram (left), or by sorting the samples by library size (right).\n\nlibrary(ggplot2)\n\np1 &lt;- ggplot(as.data.frame(colData(tse))) +\n        geom_histogram(aes(x = sum), color = \"black\", fill = \"gray\", bins = 30) +\n        labs(x = \"Library size\", y = \"Frequency (n)\") + \n        # scale_x_log10(breaks = scales::trans_breaks(\"log10\", function(x) 10^x), \n        # labels = scales::trans_format(\"log10\", scales::math_format(10^.x))) +\n        theme_bw() +\n        theme(panel.grid.major = element_blank(), # Removes the grid\n          panel.grid.minor = element_blank(),\n          panel.border = element_blank(),\n          panel.background = element_blank(),\n          axis.line = element_line(colour = \"black\")) # Adds y-axis\n\nlibrary(dplyr)\ndf &lt;- as.data.frame(colData(tse)) %&gt;%\n        arrange(sum) %&gt;%\n        mutate(index = 1:n())\np2 &lt;- ggplot(df, aes(y = index, x = sum/1e6)) +\n        geom_point() +  \n        labs(x = \"Library size (million reads)\", y = \"Sample index\") +  \n        theme_bw() +\n        theme(panel.grid.major = element_blank(), # Removes the grid\n          panel.grid.minor = element_blank(),\n          panel.border = element_blank(),\n          panel.background = element_blank(),\n          axis.line = element_line(colour = \"black\")) # Adds y-axis\n\nlibrary(patchwork)\np1 + p2\n\n\n\nLibrary size distribution.\n\n\n\nLibrary sizes other variables from colData can be visualized by using specified function called plotColData.\n\nlibrary(ggplot2)\n# Sort samples by read count, order the factor levels, and store back to tse as DataFrame\n# TODO: plotColData could include an option for sorting samples based on colData variables\ncolData(tse) &lt;- as.data.frame(colData(tse)) %&gt;%\n                 arrange(X.SampleID) %&gt;%\n             mutate(X.SampleID = factor(X.SampleID, levels=X.SampleID)) %&gt;%\n         DataFrame\nplotColData(tse,\"sum\",\"X.SampleID\", colour_by = \"SampleType\") + \n    theme(axis.text.x = element_text(angle = 45, hjust=1)) +\n    labs(y = \"Library size (N)\", x = \"Sample ID\")       \n\n\n\nLibrary sizes per sample.\n\n\n\n\nplotColData(tse,\"sum\",\"SampleType\", colour_by = \"SampleType\") + \n    theme(axis.text.x = element_text(angle = 45, hjust=1))\n\n\n\nLibrary sizes per sample type.\n\n\n\nIn addition, data can be rarefied with subsampleCounts, which normalises the samples to an equal number of reads. However, this practice has been discouraged for the analysis of differentially abundant microorganisms (see (McMurdie and Holmes 2014)).\n\nMcMurdie, Paul J, and Susan Holmes. 2014. ‚ÄúWaste Not, Want Not: Why Rarefying Microbiome Data Is Inadmissible.‚Äù PLoS Computational Biology 10 (4): e1003531.\n\n4.3.3 Contaminant sequences\nSamples might be contaminated with exogenous sequences. The impact of each contaminant can be estimated based on their frequencies and concentrations across the samples.\nThe following decontam functions are based on the (Davis et al. 2018) and support such functionality:\n\nDavis, Nicole M, Diana M Proctor, Susan P Holmes, David A Relman, and Benjamin J Callahan. 2018. ‚ÄúSimple Statistical Identification and Removal of Contaminant Sequences in Marker-Gene and Metagenomics Data.‚Äù Microbiome 6 (1): 1‚Äì14.\n\n\nisContaminant, isNotContaminant\n\n\naddContaminantQC, addNotContaminantQC"
  },
  {
    "objectID": "pages/11_taxonomic_information.html#assigning-taxonomic-information.",
    "href": "pages/11_taxonomic_information.html#assigning-taxonomic-information.",
    "title": "5¬† Taxonomic Information",
    "section": "\n5.1 Assigning taxonomic information.",
    "text": "5.1 Assigning taxonomic information.\nThere are a number of methods to assign taxonomic information. We like to give a short introduction about the methods available without ranking one over the other. This has to be your choice based on the result for the individual dataset.\n\n5.1.1 dada2\nThe dada2 package (Callahan et al. 2016) implements the assignTaxonomy function, which takes as input the ASV sequences associated with each row of data and a training dataset. For more information visit the dada2 homepage.\n\nCallahan, Benjamin J, Paul J McMurdie, Michael J Rosen, Andrew W Han, Amy Jo A Johnson, and Susan P Holmes. 2016. ‚ÄúDADA2: High-Resolution Sample Inference from Illumina Amplicon Data.‚Äù Nature Methods 13: 581‚Äì83. https://doi.org/10.1038/nmeth.3869.\n\n5.1.2 DECIPHER\nThe DECIPHER package (Wright 2020) implements the IDTAXA algorithm to assign either taxonomic information or function information. For mia only the first option is of interest for now and more information can be found on the DECIPHER website.\n\nWright, Erik. 2020. DECIPHER: Tools for Curating, Analyzing, and Manipulating Biological Sequences."
  },
  {
    "objectID": "pages/11_taxonomic_information.html#functions-to-access-taxonomic-information",
    "href": "pages/11_taxonomic_information.html#functions-to-access-taxonomic-information",
    "title": "5¬† Taxonomic Information",
    "section": "\n5.2 Functions to access taxonomic information",
    "text": "5.2 Functions to access taxonomic information\ncheckTaxonomy checks whether the taxonomic information is usable for mia\n\ncheckTaxonomy(tse)\n##  [1] TRUE\n\nSince the rowData can contain other data, taxonomyRanks will return the columns mia assumes to contain the taxonomic information.\n\ntaxonomyRanks(tse)\n##  [1] \"Kingdom\" \"Phylum\"  \"Class\"   \"Order\"   \"Family\"  \"Genus\"   \"Species\"\n\nThis can then be used to subset the rowData to columns needed.\n\nrowData(tse)[, taxonomyRanks(tse)]\n##  DataFrame with 19216 rows and 7 columns\n##             Kingdom        Phylum        Class        Order        Family\n##         &lt;character&gt;   &lt;character&gt;  &lt;character&gt;  &lt;character&gt;   &lt;character&gt;\n##  549322     Archaea Crenarchaeota Thermoprotei           NA            NA\n##  522457     Archaea Crenarchaeota Thermoprotei           NA            NA\n##  951        Archaea Crenarchaeota Thermoprotei Sulfolobales Sulfolobaceae\n##  244423     Archaea Crenarchaeota        Sd-NA           NA            NA\n##  586076     Archaea Crenarchaeota        Sd-NA           NA            NA\n##  ...            ...           ...          ...          ...           ...\n##  278222    Bacteria           SR1           NA           NA            NA\n##  463590    Bacteria           SR1           NA           NA            NA\n##  535321    Bacteria           SR1           NA           NA            NA\n##  200359    Bacteria           SR1           NA           NA            NA\n##  271582    Bacteria           SR1           NA           NA            NA\n##               Genus                Species\n##         &lt;character&gt;            &lt;character&gt;\n##  549322          NA                     NA\n##  522457          NA                     NA\n##  951     Sulfolobus Sulfolobusacidocalda..\n##  244423          NA                     NA\n##  586076          NA                     NA\n##  ...            ...                    ...\n##  278222          NA                     NA\n##  463590          NA                     NA\n##  535321          NA                     NA\n##  200359          NA                     NA\n##  271582          NA                     NA\n\ntaxonomyRankEmpty checks for empty values in the given rank and returns a logical vector of length(x).\n\nall(!taxonomyRankEmpty(tse, rank = \"Kingdom\"))\n##  [1] TRUE\ntable(taxonomyRankEmpty(tse, rank = \"Genus\"))\n##  \n##  FALSE  TRUE \n##   8008 11208\ntable(taxonomyRankEmpty(tse, rank = \"Species\"))\n##  \n##  FALSE  TRUE \n##   1413 17803\n\ngetTaxonomyLabels is a multi-purpose function, which turns taxonomic information into a character vector of length(x)\n\nhead(getTaxonomyLabels(tse))\n##  [1] \"Class:Thermoprotei\"               \"Class:Thermoprotei_1\"            \n##  [3] \"Species:Sulfolobusacidocaldarius\" \"Class:Sd-NA\"                     \n##  [5] \"Class:Sd-NA_1\"                    \"Class:Sd-NA_2\"\n\nBy default, this will use the lowest non-empty information to construct a string with the following scheme level:value. If all levels are the same, this part is omitted, but can be added by setting with_rank = TRUE.\n\nphylum &lt;- !is.na(rowData(tse)$Phylum) &\n    vapply(data.frame(apply(rowData(tse)[, taxonomyRanks(tse)[3:7]], 1L, is.na)), all, logical(1))\nhead(getTaxonomyLabels(tse[phylum,]))\n##  [1] \"Crenarchaeota\"    \"Crenarchaeota_1\"  \"Crenarchaeota_2\" \n##  [4] \"Actinobacteria\"   \"Actinobacteria_1\" \"Spirochaetes\"\nhead(getTaxonomyLabels(tse[phylum,], with_rank = TRUE))\n##  [1] \"Phylum:Crenarchaeota\"    \"Phylum:Crenarchaeota_1\" \n##  [3] \"Phylum:Crenarchaeota_2\"  \"Phylum:Actinobacteria\"  \n##  [5] \"Phylum:Actinobacteria_1\" \"Phylum:Spirochaetes\"\n\nBy default the return value of getTaxonomyLabels contains only unique elements by passing it through make.unique. This step can be omitted by setting make_unique = FALSE.\n\nhead(getTaxonomyLabels(tse[phylum,], with_rank = TRUE, make_unique = FALSE))\n##  [1] \"Phylum:Crenarchaeota\"  \"Phylum:Crenarchaeota\"  \"Phylum:Crenarchaeota\" \n##  [4] \"Phylum:Actinobacteria\" \"Phylum:Actinobacteria\" \"Phylum:Spirochaetes\"\n\nTo apply the loop resolving function resolveLoop from the TreeSummarizedExperiment package (Huang 2020) within getTaxonomyLabels, set resolve_loops = TRUE.\nThe function getUniqueFeatures gives a list of unique taxa for the specified taxonomic rank.\n\nhead(getUniqueFeatures(tse, rank = \"Phylum\"))\n##  [1] \"Crenarchaeota\"  \"Euryarchaeota\"  \"Actinobacteria\" \"Spirochaetes\"  \n##  [5] \"MVP-15\"         \"Proteobacteria\"\n\n\n5.2.1 Generate a taxonomic tree on the fly\nTo create a taxonomic tree, taxonomyTree used the information and returns a phylo object. Duplicate information from the rowData is removed.\n\ntaxonomyTree(tse)\n##  \n##  Phylogenetic tree with 1645 tips and 1089 internal nodes.\n##  \n##  Tip labels:\n##    Species:Cenarchaeumsymbiosum, Species:pIVWA5, Species:CandidatusNitrososphaeragargensis, Species:SCA1145, Species:SCA1170, Species:Sulfolobusacidocaldarius, ...\n##  Node labels:\n##    root:ALL, Kingdom:Archaea, Phylum:Crenarchaeota, Class:C2, Class:Sd-NA, Class:Thaumarchaeota, ...\n##  \n##  Rooted; includes branch lengths.\n\n\ntse &lt;- addTaxonomyTree(tse)\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 19216 26 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(19216): Class:Thermoprotei Class:Thermoprotei ...\n##    Phylum:SR1 Phylum:SR1\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (19216 rows)\n##  rowTree: 1 phylo tree(s) (1645 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nThe implementation is based on the toTree function from the TreeSummarizedExperiment package (Huang 2020).\n\nHuang, Ruizhu. 2020. TreeSummarizedExperiment: A S4 Class for Data with Tree Structures."
  },
  {
    "objectID": "pages/11_taxonomic_information.html#sec-data-agglomeration",
    "href": "pages/11_taxonomic_information.html#sec-data-agglomeration",
    "title": "5¬† Taxonomic Information",
    "section": "\n5.3 Data agglomeration",
    "text": "5.3 Data agglomeration\nOne of the main applications of taxonomic information in regards to count data is to agglomerate count data on taxonomic levels and track the influence of changing conditions through these levels. For this mia contains the mergeFeaturesByRank function. The ideal location to store the agglomerated data is as an alternative experiment.\n\ntse &lt;- transformAssay(tse, assay.type = \"counts\", method = \"relabundance\")\naltExp(tse, \"Family\") &lt;- mergeFeaturesByRank(tse, rank = \"Family\",\n                                           agglomerateTree = TRUE)\naltExp(tse, \"Family\")\n##  class: TreeSummarizedExperiment \n##  dim: 603 26 \n##  metadata(1): agglomerated_by_rank\n##  assays(2): counts relabundance\n##  rownames(603): Class:Thermoprotei Family:Sulfolobaceae ...\n##    Family:Thermodesulfobiaceae Phylum:SR1\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (603 rows)\n##  rowTree: 1 phylo tree(s) (496 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nIf multiple assays (counts and relabundance) exist, both will be agglomerated.\n\nassayNames(tse)\n##  [1] \"counts\"       \"relabundance\"\nassayNames(altExp(tse, \"Family\"))\n##  [1] \"counts\"       \"relabundance\"\n\n\nassay(altExp(tse, \"Family\"), \"relabundance\")[1:5, 1:7]\n##                             CL3       CC1 SV1 M31Fcsw M11Fcsw M31Plmr\n##  Class:Thermoprotei   0.0000000 0.000e+00   0       0       0       0\n##  Family:Sulfolobaceae 0.0000000 0.000e+00   0       0       0       0\n##  Class:Sd-NA          0.0000000 0.000e+00   0       0       0       0\n##  Order:NRP-J          0.0001991 2.070e-04   0       0       0       0\n##  Family:SAGMA-X       0.0000000 6.165e-06   0       0       0       0\n##                         M11Plmr\n##  Class:Thermoprotei   0.000e+00\n##  Family:Sulfolobaceae 2.305e-06\n##  Class:Sd-NA          0.000e+00\n##  Order:NRP-J          6.914e-06\n##  Family:SAGMA-X       0.000e+00\n\n\nassay(altExp(tse, \"Family\"), \"counts\")[1:5, 1:7]\n##                       CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr\n##  Class:Thermoprotei     0   0   0       0       0       0       0\n##  Family:Sulfolobaceae   0   0   0       0       0       0       1\n##  Class:Sd-NA            0   0   0       0       0       0       0\n##  Order:NRP-J          172 235   0       0       0       0       3\n##  Family:SAGMA-X         0   7   0       0       0       0       0\n\naltExpNames now consists of Family level data. This can be extended to use any taxonomic level listed in mia::taxonomyRanks(tse).\nRare taxa can also be aggregated into a single group ‚ÄúOther‚Äù instead of filtering them out. A suitable function for this is mergeFeaturesByPrevalence. The number of rare taxa is higher on the species level, which causes the need for data agglomeration by prevalence.\n\naltExp(tse, \"Species_byPrevalence\") &lt;- mergeFeaturesByPrevalence(tse, \n                                                               rank = \"Species\", \n                                                               other_label = \"Other\", \n                                                               prevalence = 5 / 100, \n                                                               detection = 1 / 100, \n                                                               as_relative = T)\naltExp(tse, \"Species_byPrevalence\")\n##  class: TreeSummarizedExperiment \n##  dim: 92 26 \n##  metadata(2): agglomerated_by_rank agglomerated_by_rank\n##  assays(2): counts relabundance\n##  rownames(92): pIVWA5 SCA1145 ... Desulfitobacteriumhafniense Other\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n\nassay(altExp(tse, \"Species_byPrevalence\"), \"relabundance\")[88:92, 1:7]\n##                                    CL3       CC1       SV1   M31Fcsw\n##  Streptococcusthermophilus   5.787e-06 2.290e-05 1.290e-05 6.032e-04\n##  Mitsuokellamultacida        8.101e-06 7.046e-06 1.147e-05 6.479e-07\n##  Veillonellaparvula          1.736e-05 1.673e-05 1.720e-05 7.645e-05\n##  Desulfitobacteriumhafniense 1.620e-05 1.585e-05 8.602e-06 1.296e-06\n##  Other                       8.622e-03 6.787e-03 4.325e-02 2.763e-02\n##                                M11Fcsw   M31Plmr  M11Plmr\n##  Streptococcusthermophilus   1.122e-04 1.225e-02 0.002478\n##  Mitsuokellamultacida        9.632e-07 2.782e-06 0.000000\n##  Veillonellaparvula          1.589e-05 2.075e-02 0.001143\n##  Desulfitobacteriumhafniense 9.632e-07 0.000e+00 0.000000\n##  Other                       2.682e-03 7.077e-02 0.070752\n\n\n# Saving the tse for later\ntseGlobalPatterns &lt;- tse\n\n\n5.3.1 Taxa clustering\nAnother way to agglomerate the data is to cluster the taxa. To do so, we usually start by doing a compositionality aware transformation such as CLR, followed by the application of a standard clustering method.\nHere is an example that does a CLR transformation followed by the hierarchical clustering algorithm.\nFirst, we import the library bluster that simplifies the clustering.\n\nlibrary(bluster)\n\nThen we do the CLR transform followed by the clustering. We will cluster with two different distances: the euclidean distance and the kendall distance.\n\n# Get the data\ndata(\"peerj13075\", package = \"mia\")\ntse &lt;- peerj13075\n\n# The result of the CLR transform is stored in the assay clr\ntse &lt;- transformAssay(tse, method = \"clr\", pseudocount = 1)\n\ntse &lt;- transformAssay(tse, assay.type = \"clr\", method = \"z\", \n                      MARGIN = \"features\")\n\n# Cluster (with euclidean distance) on the features of the z assay\ntse &lt;- cluster(tse,\n               assay.type = \"z\",\n               clust.col = \"hclustEuclidean\",\n           MARGIN = \"features\",\n               HclustParam(dist.fun = stats::dist, method = \"ward.D2\"))\n\n# Declare the Kendall dissimilarity computation function\nkendall_dissimilarity &lt;- function(x) {\n    as.dist(1 - cor(t(x), method = \"kendall\"))\n}\n\n# Cluster (with Kendall dissimilarity) on the features of the z assay\ntse &lt;- cluster(tse,\n               assay.type = \"z\",\n               clust.col = \"hclustKendall\",\n               MARGIN = \"features\",            \n               HclustParam(dist.fun = kendall_dissimilarity, method = \"ward.D2\"))\n\nLet us store the resulting cluster indices in the rowData column specified with the clust.col parameter.\n\n# Checking the clusters\nclusters_euclidean &lt;- rowData(tse)$hclustEuclidean\nhead(clusters_euclidean, 10)\n##   OTU1  OTU2  OTU7  OTU9 OTU10 OTU12 OTU14 OTU15 OTU18 OTU19 \n##      1     2     1     1     1     1     3     4     3     2 \n##  Levels: 1 2 3 4 5\n\nclusters_kendall &lt;- rowData(tse)$hclustKendall\nhead(clusters_kendall, 10)\n##   OTU1  OTU2  OTU7  OTU9 OTU10 OTU12 OTU14 OTU15 OTU18 OTU19 \n##      1     2     1     3     3     1     3     1     1     3 \n##  Levels: 1 2 3 4\n\nTo better visualize the results and the distribution of the clusters, we can plot the histogram of the clusters.\n\nlibrary(ggplot2)\nlibrary(patchwork) # TO arrange several plots as a grid\nplot1 &lt;- ggplot(as.data.frame(rowData(tse)), aes(x = clusters_euclidean)) +\n    geom_bar() +\n    labs(title = \"CAG size distribution (Euclidean distance)\",\n         x = \"Clusters\", y = \"Feature count (n)\")\nplot2 &lt;- ggplot(as.data.frame(rowData(tse)), aes(x = clusters_kendall)) +\n    geom_bar() +\n    labs(title = \"CAG size distribution (1 - tau)\",\n         x = \"Clusters\", y = \"Feature count (n)\")\nplot1 + plot2 + plot_layout(ncol = 2)\n\n\n\n\n\n\n\nIt‚Äôs also possible to merge the rows by cluster.\n\n# Aggregate clusters as a sum of each cluster values\ntse_merged &lt;- mergeFeatures(tse, clusters_euclidean)\ntse_merged\n##  class: TreeSummarizedExperiment \n##  dim: 5 58 \n##  metadata(0):\n##  assays(3): counts clr z\n##  rownames(5): 1 2 3 4 5\n##  rowData names(8): kingdom phylum ... hclustEuclidean hclustKendall\n##  colnames(58): ID1 ID2 ... ID57 ID58\n##  colData names(5): Sample Geographical_location Gender Age Diet\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n\nWe can note that it worked as planned since there were 5 clusters and there are now 5 rows."
  },
  {
    "objectID": "pages/11_taxonomic_information.html#sec-assay-transform",
    "href": "pages/11_taxonomic_information.html#sec-assay-transform",
    "title": "5¬† Taxonomic Information",
    "section": "\n5.4 Data transformation",
    "text": "5.4 Data transformation\nData transformations are common in microbiome analysis. Examples include the logarithmic transformation, calculation of relative abundances (percentages), and compositionality-aware transformations such as the centered log-ratio transformation (clr).\nIn mia package, transformations are applied to abundance data. The transformed abundance table is stored back to ‚Äòassays‚Äô. mia includes transformation function (‚ÄòtransformAssay()‚Äô) which applies sample-wise or column-wise transformation when MARGIN = ‚Äòsamples‚Äô, feature-wise or row-wise transformation when MARGIN = ‚Äòfeatures‚Äô.\nFor a complete list of available transformations and parameters, see function help.\n\ntse &lt;- tseGlobalPatterns\ntse &lt;- transformAssay(tse, assay.type = \"counts\", method = \"relabundance\", pseudocount = 1)\ntse &lt;- transformAssay(x = tse, assay.type = \"relabundance\", method = \"clr\", \n                      pseudocount = 1, name = \"clr\")\n\nhead(assay(tse, \"clr\"))\n##                                          CL3        CC1        SV1    M31Fcsw\n##  Class:Thermoprotei               -5.078e-05 -5.105e-05 -5.055e-05 -4.975e-05\n##  Class:Thermoprotei               -5.078e-05 -5.105e-05 -5.055e-05 -4.975e-05\n##  Species:Sulfolobusacidocaldarius -5.078e-05 -5.105e-05 -5.055e-05 -4.975e-05\n##  Class:Sd-NA                      -5.078e-05 -5.105e-05 -5.055e-05 -4.975e-05\n##  Class:Sd-NA                      -5.078e-05 -5.105e-05 -5.055e-05 -4.975e-05\n##  Class:Sd-NA                      -5.078e-05 -5.105e-05 -5.055e-05 -4.975e-05\n##                                      M11Fcsw    M31Plmr    M11Plmr    F21Plmr\n##  Class:Thermoprotei               -4.947e-05 -4.931e-05 -4.879e-05 -4.671e-05\n##  Class:Thermoprotei               -4.947e-05 -4.931e-05 -4.879e-05 -4.671e-05\n##  Species:Sulfolobusacidocaldarius -4.947e-05 -4.931e-05 -4.658e-05 -4.671e-05\n##  Class:Sd-NA                      -4.947e-05 -4.931e-05 -4.879e-05 -4.671e-05\n##  Class:Sd-NA                      -4.947e-05 -4.931e-05 -4.879e-05 -4.671e-05\n##  Class:Sd-NA                      -4.947e-05 -4.931e-05 -4.879e-05 -4.671e-05\n##                                      M31Tong    M11Tong   LMEpi24M   SLEpi20M\n##  Class:Thermoprotei               -4.846e-05 -4.257e-05 -4.756e-05 -4.837e-05\n##  Class:Thermoprotei               -4.846e-05 -4.257e-05 -4.756e-05 -4.918e-05\n##  Species:Sulfolobusacidocaldarius -4.846e-05 -4.257e-05 -4.756e-05 -4.918e-05\n##  Class:Sd-NA                      -4.846e-05 -4.257e-05 -4.756e-05 -4.918e-05\n##  Class:Sd-NA                      -4.846e-05 -4.257e-05 -4.756e-05 -4.918e-05\n##  Class:Sd-NA                      -4.846e-05 -4.257e-05 -4.756e-05 -4.918e-05\n##                                       AQC1cm     AQC4cm     AQC7cm        NP2\n##  Class:Thermoprotei               -2.385e-05 -4.438e-06  2.787e-05 -4.731e-05\n##  Class:Thermoprotei               -4.660e-05 -4.568e-05 -4.428e-05 -4.915e-05\n##  Species:Sulfolobusacidocaldarius -4.660e-05 -4.652e-05 -4.777e-05 -4.915e-05\n##  Class:Sd-NA                      -4.660e-05 -3.726e-05 -3.090e-05 -4.915e-05\n##  Class:Sd-NA                      -4.660e-05 -4.568e-05 -4.719e-05 -4.915e-05\n##  Class:Sd-NA                      -4.660e-05 -4.610e-05 -4.603e-05 -4.915e-05\n##                                          NP3        NP5    TRRsed1    TRRsed2\n##  Class:Thermoprotei               -5.068e-05 -5.083e-05 -3.909e-05 -4.927e-05\n##  Class:Thermoprotei               -5.068e-05 -5.083e-05 -3.909e-05 -4.927e-05\n##  Species:Sulfolobusacidocaldarius -5.068e-05 -5.083e-05 -3.909e-05 -4.927e-05\n##  Class:Sd-NA                      -5.068e-05 -5.083e-05 -3.909e-05 -4.927e-05\n##  Class:Sd-NA                      -5.068e-05 -5.083e-05 -3.909e-05 -4.927e-05\n##  Class:Sd-NA                      -5.068e-05 -5.083e-05 -3.909e-05 -4.927e-05\n##                                      TRRsed3       TS28       TS29      Even1\n##  Class:Thermoprotei               -4.829e-05 -5.016e-05 -4.934e-05 -5.046e-05\n##  Class:Thermoprotei               -4.829e-05 -5.016e-05 -4.934e-05 -5.046e-05\n##  Species:Sulfolobusacidocaldarius -4.829e-05 -5.016e-05 -4.934e-05 -5.046e-05\n##  Class:Sd-NA                      -4.829e-05 -5.016e-05 -4.934e-05 -5.046e-05\n##  Class:Sd-NA                      -4.829e-05 -5.016e-05 -4.934e-05 -5.046e-05\n##  Class:Sd-NA                      -4.829e-05 -5.016e-05 -4.934e-05 -5.046e-05\n##                                        Even2      Even3\n##  Class:Thermoprotei               -5.017e-05 -5.034e-05\n##  Class:Thermoprotei               -5.017e-05 -5.034e-05\n##  Species:Sulfolobusacidocaldarius -5.017e-05 -5.034e-05\n##  Class:Sd-NA                      -5.017e-05 -5.034e-05\n##  Class:Sd-NA                      -5.017e-05 -5.034e-05\n##  Class:Sd-NA                      -5.017e-05 -5.034e-05\n\n\nIn ‚Äòpa‚Äô transformation, abundance table is converted to present/absent table.\n\n\ntse &lt;- transformAssay(tse, method = \"pa\")\n\nhead(assay(tse, \"pa\"))\n##                                   CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr\n##  Class:Thermoprotei                 0   0   0       0       0       0       0\n##  Class:Thermoprotei                 0   0   0       0       0       0       0\n##  Species:Sulfolobusacidocaldarius   0   0   0       0       0       0       1\n##  Class:Sd-NA                        0   0   0       0       0       0       0\n##  Class:Sd-NA                        0   0   0       0       0       0       0\n##  Class:Sd-NA                        0   0   0       0       0       0       0\n##                                   F21Plmr M31Tong M11Tong LMEpi24M SLEpi20M\n##  Class:Thermoprotei                     0       0       0        0        1\n##  Class:Thermoprotei                     0       0       0        0        0\n##  Species:Sulfolobusacidocaldarius       0       0       0        0        0\n##  Class:Sd-NA                            0       0       0        0        0\n##  Class:Sd-NA                            0       0       0        0        0\n##  Class:Sd-NA                            0       0       0        0        0\n##                                   AQC1cm AQC4cm AQC7cm NP2 NP3 NP5 TRRsed1\n##  Class:Thermoprotei                    1      1      1   1   0   0       0\n##  Class:Thermoprotei                    0      1      1   0   0   0       0\n##  Species:Sulfolobusacidocaldarius      0      0      0   0   0   0       0\n##  Class:Sd-NA                           0      1      1   0   0   0       0\n##  Class:Sd-NA                           0      1      1   0   0   0       0\n##  Class:Sd-NA                           0      1      1   0   0   0       0\n##                                   TRRsed2 TRRsed3 TS28 TS29 Even1 Even2 Even3\n##  Class:Thermoprotei                     0       0    0    0     0     0     0\n##  Class:Thermoprotei                     0       0    0    0     0     0     0\n##  Species:Sulfolobusacidocaldarius       0       0    0    0     0     0     0\n##  Class:Sd-NA                            0       0    0    0     0     0     0\n##  Class:Sd-NA                            0       0    0    0     0     0     0\n##  Class:Sd-NA                            0       0    0    0     0     0     0\n\n\n# list of abundance tables that assays slot contains\nassays(tse)\n##  List of length 4\n##  names(4): counts relabundance clr pa"
  },
  {
    "objectID": "pages/14_alpha_diversity.html#estimation",
    "href": "pages/14_alpha_diversity.html#estimation",
    "title": "6¬† Community Diversity",
    "section": "\n6.1 Estimation",
    "text": "6.1 Estimation\nAlpha diversity can be estimated with wrapper functions that interact with other packages implementing the calculation, such as vegan (Oksanen et al. 2020).\n\nOksanen, Jari, F. Guillaume Blanchet, Michael Friendly, Roeland Kindt, Pierre Legendre, Dan McGlinn, Peter R. Minchin, et al. 2020. Vegan: Community Ecology Package. https://CRAN.R-project.org/package=vegan.\n\n6.1.1 Richness\nRichness gives the number of features present within a community and can be calculated with estimateRichness. Each of the estimate diversity/richness/evenness/dominance functions adds the calculated measure(s) to the colData of the SummarizedExperiment under the given column name. Here, we calculate observed features as a measure of richness.\n\ntse &lt;- mia::estimateRichness(tse, \n                             assay.type = \"counts\", \n                             index = \"observed\", \n                             name=\"observed\")\n\nhead(tse$observed)\n##      CL3     CC1     SV1 M31Fcsw M11Fcsw M31Plmr \n##     6964    7679    5729    2667    2574    3214\n\nThis allows access to the values to be analyzed directly from the colData, for example by plotting them using plotColData from the scater package (McCarthy et al. 2020).\n\nMcCarthy, Davis, Kieran Campbell, Aaron Lun, and Quin Wills. 2020. Scater: Single-Cell Analysis Toolkit for Gene Expression Data in r. http://bioconductor.org/packages/scater/.\n\nlibrary(scater)\nplotColData(tse, \n            \"observed\", \n            \"SampleType\", \n            colour_by = \"Final_Barcode\") +\n    theme(axis.text.x = element_text(angle=45,hjust=1)) + \n  ylab(expression(Richness[Observed]))\n\n\n\nShannon diversity estimates plotted grouped by sample type with colour-labeled barcode.\n\n\n\n\n6.1.2 Diversity\nThe main function, estimateDiversity, calculates the selected diversity index based on the selected assay data.\n\ntse &lt;- mia::estimateDiversity(tse, \n                              assay.type = \"counts\",\n                              index = \"shannon\", \n                              name = \"shannon\")\nhead(tse$shannon)\n##      CL3     CC1     SV1 M31Fcsw M11Fcsw M31Plmr \n##    6.577   6.777   6.498   3.828   3.288   4.289\n\nAlpha diversities can be visualized with boxplot. Here, Shannon index is compared between different sample type groups. Individual data points are visualized by plotting them as points with geom_jitter.\ngeom_signif is used to test whether these differences are statistically significant. It adds p-values to plot.\n\nlibrary(ggsignif)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(ggsignif)\n\n# Subsets the data. Takes only those samples that are from feces, skin, or tongue,\n# and creates data frame from the collected data\ndf &lt;- as.data.frame(colData(tse)[tse$SampleType %in% \n                 c(\"Feces\", \"Skin\", \"Tongue\"), ])\n\n# Changes old levels with new levels\ndf$SampleType &lt;- factor(df$SampleType)\n\n# For significance testing, all different combinations are determined\ncomb &lt;- split(t(combn(levels(df$SampleType), 2)), \n           seq(nrow(t(combn(levels(df$SampleType), 2)))))\n\nggplot(df, aes(x = SampleType, y = shannon)) +\n  # Outliers are removed, because otherwise each data point would be plotted twice; \n  # as an outlier of boxplot and as a point of dotplot.\n  geom_boxplot(outlier.shape = NA) + \n  geom_jitter(width = 0.2) + \n  geom_signif(comparisons = comb, map_signif_level = FALSE) +\n  theme(text = element_text(size = 10))\n\n\n\n\n\n\n\n\n6.1.3 Faith phylogenetic diversity\nThe Faith index is returned by the function estimateFaith.\n\ntse &lt;- mia::estimateFaith(tse,\n                          assay.type = \"counts\")\nhead(tse$faith)\n##  [1] 250.5 262.3 208.5 117.9 119.8 135.8\n\nNote: because tse is a TreeSummarizedExperiment object, its phylogenetic tree is used by default. However, the optional argument tree must be provided if tse does not contain one.\nBelow a visual comparison between shannon and faith indices is shown with a violin plot.\n\nplots &lt;- lapply(c(\"shannon\", \"faith\"),\n                plotColData,\n                object = tse, colour_by = \"SampleType\")\nplots[[1]] + plots[[2]] +\n  plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\nAlternatively, the phylogenetic diversity can be calculated by mia::estimateDiversity. This is a faster re-implementation of\nthe widely used function in picante W et al. (2010).\n\nW, Kembel Steven, Cowan Peter D, Helmus Matthew R, Cornwell William K, Morlon Helene, Ackerly David D, Blomberg Simon P, and Webb Campbell O. 2010. ‚ÄúPicante: R tools for integrating phylogenies and ecology.‚Äù Bioinformatics 26 (11): 1463‚Äì64. https://doi.org/https://doi.org/10.1093/bioinformatics/btq166.\nLoad picante R package and get the phylo stored in rowTree.\n\ntse &lt;- mia::estimateDiversity(tse, \n                              assay.type = \"counts\",\n                              index = \"faith\", \n                              name = \"faith\")\n\n\n6.1.4 Evenness\nEvenness can be calculated with estimateEvenness.\n\ntse &lt;- estimateEvenness(tse, \n                        assay.type = \"counts\", \n                        index=\"simpson\")\nhead(tse$simpson)\n##       CL3      CC1      SV1  M31Fcsw  M11Fcsw  M31Plmr \n##  0.026871 0.027197 0.047049 0.005179 0.004304 0.005011\n\n\n6.1.5 Dominance\nDominance can be calculated with estimateDominance. Here, the Relative index is calculated which is the relative abundance of the most dominant species in the sample.\n\ntse &lt;- estimateDominance(tse, \n                         assay.type = \"counts\", \n                         index=\"relative\")\n\nhead(tse$relative)\n##      CL3     CC1     SV1 M31Fcsw M11Fcsw M31Plmr \n##  0.03910 0.03226 0.01690 0.22981 0.21778 0.22329\n\n\n6.1.6 Rarity\nmia package provides one rarity index called log-modulo skewness. It can be calculated with estimateDiversity.\n\ntse &lt;- mia::estimateDiversity(tse, \n                              assay.type = \"counts\",\n                              index = \"log_modulo_skewness\")\n\nhead(tse$log_modulo_skewness)\n##      1     2     3     4     5     6 \n##  2.061 2.061 2.061 2.061 2.061 2.061\n\n\n6.1.7 Divergence\nDivergence can be evaluated with estimateDivergence. Reference and algorithm for the calculation of divergence can be specified as reference and FUN, respectively.\n\ntse &lt;- mia::estimateDivergence(tse,\n                               assay.type = \"counts\",\n                               reference = \"median\",\n                               FUN = vegan::vegdist)"
  },
  {
    "objectID": "pages/14_alpha_diversity.html#visualization",
    "href": "pages/14_alpha_diversity.html#visualization",
    "title": "6¬† Community Diversity",
    "section": "\n6.2 Visualization",
    "text": "6.2 Visualization\nA plot comparing all the diversity measures calculated above and stored in colData can then be constructed directly.\n\nplots &lt;- lapply(c(\"observed\", \"shannon\", \"simpson\", \"relative\", \"faith\", \"log_modulo_skewness\"),\n                plotColData,\n                object = tse,\n                x = \"SampleType\",\n                colour_by = \"SampleType\")\n\nplots &lt;- lapply(plots, \"+\", \n                theme(axis.text.x = element_blank(),\n                      axis.title.x = element_blank(),\n                      axis.ticks.x = element_blank()))\n\n((plots[[1]] | plots[[2]] | plots[[3]]) / \n(plots[[4]] | plots[[5]] | plots[[6]])) +\n  plot_layout(guides = \"collect\")"
  },
  {
    "objectID": "pages/20_beta_diversity.html#sec-unsupervised-ordination",
    "href": "pages/20_beta_diversity.html#sec-unsupervised-ordination",
    "title": "7¬† Community Similarity",
    "section": "\n7.1 Unsupervised ordination",
    "text": "7.1 Unsupervised ordination\nUnsupervised ordination methods variation in the data without additional information on covariates or other supervision of the model. Among the different approaches, Multi-Dimensional Scaling (MDS) and non-metric MDS (NMDS) can be regarded as the standard. They are jointly referred to as PCoA. For this demonstration we will analyse beta diversity in GlobalPatterns, and observe the variation between stool samples and those with a different origin.\n\n# Load mia and import sample dataset\nlibrary(mia)\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\n# Beta diversity metrics like Bray-Curtis are often applied to relabundances\ntse &lt;- transformAssay(tse,\n                      assay.type = \"counts\",\n                      method = \"relabundance\")\n\n# Other metrics like Aitchison to clr-transformed data\ntse &lt;- transformAssay(tse,\n                      assay.type = \"relabundance\",\n                      method = \"clr\",\n                      pseudocount = TRUE)\n\n# Add group information Feces yes/no\ntse$Group &lt;- tse$SampleType == \"Feces\"\n\n\n7.1.1 Comparing communities by beta diversity analysis\nA typical comparison of community compositions starts with a visual representation of the groups by a 2D ordination. Then we estimate relative abundances and MDS ordination based on Bray-Curtis index between the groups, and visualize the results.\nIn the following examples dissimilarity is calculated with the function supplied to the FUN argument. Several metrics of beta diversity are defined by the vegdist function of the vegan package, which is often used in this context. However, such custom functions created by the user also work, as long as they return a dist object. In either case, this function is then applied to calculate reduced dimensions via an ordination method, the results of which can be stored in the reducedDim slot of the TreeSE. This entire process is contained by the runMDS and runNMDS functions.\n\n# Load package to plot reducedDim\nlibrary(scater)\n\n# Run PCoA on relabundance assay with Bray-Curtis distances\ntse &lt;- runMDS(tse,\n              FUN = vegan::vegdist,\n              method = \"bray\",\n              assay.type = \"relabundance\",\n              name = \"MDS_bray\")\n\nSample dissimilarity can be visualized on a lower-dimensional display (typically 2D) using the plotReducedDim function from the scater package. This also provides tools to incorporate additional information encoded by color, shape, size and other aesthetics. Can you find any difference between the groups?\n\n# Create ggplot object\np &lt;- plotReducedDim(tse, \"MDS_bray\",\n                    colour_by = \"Group\")\n\n# Calculate explained variance\ne &lt;- attr(reducedDim(tse, \"MDS_bray\"), \"eig\")\nrel_eig &lt;- e / sum(e[e &gt; 0])\n\n# Add explained variance for each axis\np &lt;- p + labs(x = paste(\"PCoA 1 (\", round(100 * rel_eig[[1]], 1), \"%\", \")\", sep = \"\"),\n              y = paste(\"PCoA 2 (\", round(100 * rel_eig[[2]], 1), \"%\", \")\", sep = \"\"))\n\np\n\n\n\nMDS plot based on the Bray-Curtis distances on the GlobalPattern dataset.\n\n\n\nA few combinations of beta diversity metrics and assay types are typically used. For instance, Bray-Curtis dissimilarity and Euclidean distance are often applied to the relative abundance and the clr assays, respectively. Besides beta diversity metric and assay type, the PCoA algorithm is also a variable that should be considered. Below, we show how the choice of these three factors can affect the resulting lower-dimensional data.\n\n# Run NMDS on relabundance assay with Bray-Curtis distances\ntse &lt;- runNMDS(tse,\n               FUN = vegan::vegdist,\n               method = \"bray\",\n               assay.type = \"relabundance\",\n               name = \"NMDS_bray\")\n\n# Run MDS on clr assay with Aitchison distances\ntse &lt;- runMDS(tse,\n              FUN = vegan::vegdist,\n              method = \"euclidean\",\n              assay.type = \"clr\",\n              name = \"MDS_aitchison\")\n\n# Run NMDS on clr assay with Euclidean distances\ntse &lt;- runNMDS(tse,\n               FUN = vegan::vegdist,\n               method = \"euclidean\",\n               assay.type = \"clr\",\n               name = \"NMDS_aitchison\")\n\nMultiple ordination plots are combined into a multi-panel plot with the patchwork package, so that different methods can be compared to find similarities between them or select the most suitable one to visualize beta diversity in the light of the research question.\n\n# Load package for multi-panel plotting\nlibrary(patchwork)\n\n# Generate plots for all 4 reducedDims\nplots &lt;- lapply(c(\"MDS_bray\", \"MDS_aitchison\",\n                  \"NMDS_bray\", \"NMDS_aitchison\"),\n                plotReducedDim,\n                object = tse,\n                colour_by = \"Group\")\n\n# Generate multi-panel plot\nwrap_plots(plots) +\n  plot_layout(guides = \"collect\")\n\n\n\nComparison of MDS and NMDS plots based on the Bray-Curtis or Aitchison distances on the GlobalPattern dataset.\n\n\n\nThe Unifrac method is a special case, as it requires data on the relationship of features in form on a phylo tree. calculateUnifrac performs the calculation to return a dist object, which can again be used within runMDS.\n\ntse &lt;- runMDS(tse,\n              FUN = mia::calculateUnifrac,\n              name = \"Unifrac\",\n              tree = rowTree(tse),\n              ntop = nrow(tse),\n              assay.type = \"counts\")\n\nplotReducedDim(tse, \"Unifrac\",\n               colour_by = \"Group\")\n\n\n\nUnifrac distances scaled by MDS of the GlobalPattern dataset.\n\n\n\n\n7.1.2 Other ordination methods\nOther dimension reduction methods, such as PCA and UMAP, are inherited from the scater package.\n\ntse &lt;- runPCA(tse,\n              name = \"PCA\",\n              assay.type = \"counts\",\n              ncomponents = 10)\n\nplotReducedDim(tse, \"PCA\",\n               colour_by = \"Group\")\n\n\n\nPCA plot on the GlobalPatterns data set containing sample from different sources.\n\n\n\nAs mentioned before, applicability of the different methods depends on your sample set and research question.\n\ntse &lt;- runUMAP(tse,\n               name = \"UMAP\",\n               assay.type = \"counts\",\n               ncomponents = 3)\n\nplotReducedDim(tse, \"UMAP\",\n               colour_by = \"Group\",\n               ncomponents = c(1:3))\n\n\n\nUMAP plot on the GlobalPatterns data set containing sample from different sources.\n\n\n\n\n7.1.3 Explained variance\nThe percentage of explained variance is typically shown for PCA ordination plots. This quantifies the proportion of overall variance in the data that is captured by the PCA axes, or how well the ordination axes reflect the original distances.\nSometimes a similar measure is shown for MDS/PCoA. The interpretation is generally different, however, and hence we do not recommend using it. PCA is a special case of PCoA with Euclidean distances. With non-Euclidean dissimilarities PCoA uses a trick where the pointwise dissimilarities are first cast into similarities in a Euclidean space (with some information loss i.e.¬†stress) and then projected to the maximal variance axes. In this case, the maximal variance axes do not directly reflect the correspondence of the projected distances and original distances, as they do for PCA.\nIn typical use cases, we would like to know how well the ordination reflects the original similarity structures; then the quantity of interest is the so-called ‚Äústress‚Äù function, which measures the difference in pairwise similarities between the data points in the original (high-dimensional) vs.¬†projected (low-dimensional) space.\nHence, we propose that for PCoA and other ordination methods, users would report relative stress, which varies in the unit interval and is better if smaller. This can be calculated as shown below.\n\n# Load vegan package\nlibrary(vegan)\n\n# Quantify dissimilarities in the original feature space\nx &lt;- assay(tse, \"relabundance\") # Pick relabunance assay separately\nd0 &lt;- as.matrix(vegdist(t(x), \"bray\"))\n\n# PCoA Ordination\npcoa &lt;- as.data.frame(cmdscale(d0, k = 2))\nnames(pcoa) &lt;- c(\"PCoA1\", \"PCoA2\")\n\n# Quantify dissimilarities in the ordination space\ndp &lt;- as.matrix(dist(pcoa))\n\n# Calculate stress i.e. relative difference in the original and\n# projected dissimilarities\nstress &lt;- sum((dp - d0)^2) / sum(d0^2)\n\nA Shepard plot visualizes the original versus the ordinated dissimilarity between the observations.\n\nord &lt;- order(as.vector(d0))\ndf &lt;- data.frame(d0 = as.vector(d0)[ord],\n                 dmds = as.vector(dp)[ord])\n\nggplot(df, aes(x = d0, y = dmds)) +\n  geom_smooth() +\n  geom_point() +    \n  labs(title = \"Shepard plot\",\n       x = \"Original distance\",\n       y = \"MDS distance\",   \n       subtitle = paste(\"Stress:\", round(stress, 2))) +\n  theme_bw()"
  },
  {
    "objectID": "pages/20_beta_diversity.html#supervised-ordination",
    "href": "pages/20_beta_diversity.html#supervised-ordination",
    "title": "7¬† Community Similarity",
    "section": "\n7.2 Supervised ordination",
    "text": "7.2 Supervised ordination\ndbRDA is a supervised counterpart of PCoA, that is, it takes into account the covariates specified by the user to maximize the variance with respect to the them. The result shows how much each covariate affects beta diversity. The table below illustrates the relation between supervised and unsupervised ordination methods.\n\n\n\n\n\n\n\n\nsupervised ordination\nunsupervised ordination\n\n\n\nEuclidean distance\nRDA\nPCA\n\n\nnon-Euclidean distance\ndbRDA\nPCoA/MDS, NMDS and UMAP\n\n\n\nWe demonstrate the usage of dbRDA with the enterotype dataset, where samples correspond to patients. The colData contains the clinical status of each patient and a few covariates such as their gender and age.\n\n# Load data\ndata(\"enterotype\", package = \"mia\")\ntse2 &lt;- enterotype\n\n# Apply relative transform\ntse2 &lt;- transformAssay(tse2,\n                       method = \"relabundance\")\n\ndbRDA can be perfomed with the runRDA function. In addition to the arguments previously defined for unsupervised ordination, this function takes a formula to control for variables and an action to treat missing values. Along with clinical status, which is the main outcome, we control for gender and age, and exclude observations where one of these variables is missing.\n\n# Perform RDA\ntse2 &lt;- runRDA(tse2,\n               assay.type = \"relabundance\",\n               formula = assay ~ ClinicalStatus + Gender + Age,\n               distance = \"bray\",\n               na.action = na.exclude)\n\n# Store results of PERMANOVA test\nrda_info &lt;- attr(reducedDim(tse2, \"RDA\"), \"significance\")\n\nThe importance of each variable on the similarity between samples can be assessed from the results of PERMANOVA, automatically provided by the runRDA function. We see that both clinical status and age explain more than 10% of the variance, but only age shows statistical significance.\n\nrda_info$permanova |&gt;\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nDf\nSumOfSqs\nF\nPr(&gt;F)\nTotal variance\nExplained variance\n\n\n\nModel\n6\n1.1157\n1.940\n0.030\n3.991\n0.2795\n\n\nClinicalStatus\n4\n0.5837\n1.522\n0.135\n3.991\n0.1463\n\n\nGender\n1\n0.1679\n1.751\n0.112\n3.991\n0.0421\n\n\nAge\n1\n0.5245\n5.471\n0.001\n3.991\n0.1314\n\n\nResidual\n30\n2.8757\nNA\nNA\n3.991\n0.7205\n\n\n\n\n\nTo ensure that the homogeneity assumption holds, we retrieve the corresponding information from the results of RDA. In this case, none of the p-values is lower than the significance threshold, and thus homogeneity is observed.\n\nrda_info$homogeneity |&gt;\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF\nN.Perm\nPr(&gt;F)\nTotal variance\nExplained variance\n\n\n\nClinicalStatus\n4\n0.2511\n0.0628\n2.7440\n999\n0.109\n1.0288\n0.2440\n\n\nGender\n1\n0.0103\n0.0103\n0.4158\n999\n0.512\n0.9283\n0.0111\n\n\nAge\n29\n0.3272\n0.0113\n17.0255\n999\n0.439\n0.3319\n0.9860\n\n\n\n\n\nNext, we proceed to visualize the weight and significance of each variable on the similarity between samples with an RDA plot, which can be generated with the plotRDA function from the miaViz package.\n\n# Load packages for plotting function\nlibrary(miaViz)\n\n# Generate RDA plot coloured by clinical status\nplotRDA(tse2, \"RDA\", colour_by = \"ClinicalStatus\")\n\n\n\n\n\n\n\nFrom the plot above, we can see that only age significantly describes differences between the microbial profiles of different samples. Such visual approach complements the previous results of PERMANOVA."
  },
  {
    "objectID": "pages/20_beta_diversity.html#case-studies",
    "href": "pages/20_beta_diversity.html#case-studies",
    "title": "7¬† Community Similarity",
    "section": "\n7.3 Case studies",
    "text": "7.3 Case studies\n\n7.3.0.1 Visualizing the most dominant genus on PCoA\nIn this section, we visualize the most dominant genus on PCoA. A similar visualization was proposed by (2021). First, we agglomerate the data at the Genus level and get the dominant taxa per sample.\n\nSalosensaari, Aaro, Ville Laitinen, Aki Havulinna, Guillaume M√©ric, Susan Cheng, Markus Perola, Liisa Valsta, et al. 2021. ‚ÄúTaxonomic Signatures of Cause-Specific Mortality Risk in Human Gut Microbiome.‚Äù Nature Communications 12: 1‚Äì8. https://www.nature.com/articles/s41467-021-22962-y.\n\n# Agglomerate to genus level\ntse_genus &lt;- mergeFeaturesByRank(tse,\n                                 rank = \"Genus\")\n\n# Convert to relative abundances\ntse_genus &lt;- transformAssay(tse,\n                            method = \"relabundance\",\n                            assay.type = \"counts\")\n\n# Add info on dominant genus per sample\ntse_genus &lt;- addPerSampleDominantFeatures(tse_genus,\n                                          assay.type = \"relabundance\",\n                                          name = \"dominant_taxa\")\n# Overview\ncountDominantFeatures(tse_genus, rank = \"Genus\", digits = 3, name = \"dominant_taxa\")\n##  # A tibble: 17 √ó 3\n##    dominant_taxa                n rel_freq\n##    &lt;chr&gt;                    &lt;int&gt;    &lt;dbl&gt;\n##  1 Genus:Bacteroides            5    0.192\n##  2 Order:Stramenopiles          4    0.154\n##  3 Family:Desulfobulbaceae      2    0.077\n##  4 Genus:Streptococcus          2    0.077\n##  5 Class:Chloracidobacteria     1    0.038\n##  6 Family:ACK-M1                1    0.038\n##  # ‚Ñπ 11 more rows\n\nNext, we perform PCoA with Bray-Curtis dissimilarity.\n\ntse_genus &lt;- runMDS(tse_genus,\n                    FUN = vegan::vegdist,\n                    name = \"PCoA_BC\",\n                    assay.type = \"relabundance\")\n\nFinally, we get the top taxa and and visualize their abundances on PCoA. Note that A 3D interactive version of the plot below can be found in Appendix¬†A.\n\n# Getting the top taxa\ntop_taxa &lt;- getTopFeatures(tse_genus,\n                           top = 6,\n                           assay.type = \"relabundance\")\n\n# Naming all the rest of non top-taxa as \"Other\"\nmost_abundant &lt;- lapply(colData(tse_genus)$dominant_taxa,\n                        function(x) {if (x %in% top_taxa) {x} else {\"Other\"}})\n\n# Storing the previous results as a new column within colData\ncolData(tse_genus)$most_abundant &lt;- as.character(most_abundant)\n\n# Calculating percentage of the most abundant\nmost_abundant_freq &lt;- table(as.character(most_abundant))\nmost_abundant_percent &lt;- round(most_abundant_freq / sum(most_abundant_freq) * 100, 1)\n\n# Retrieving the explained variance\ne &lt;- attr(reducedDim(tse_genus, \"PCoA_BC\"), \"eig\")\nvar_explained &lt;- e / sum(e[e &gt; 0]) * 100\n\n# Define colors for visualization\nmy_colors &lt;- c(\"black\", \"blue\", \"lightblue\", \"darkgray\", \"magenta\", \"darkgreen\", \"red\")\n\n# Visualization\nplot &lt;-plotReducedDim(tse_genus, \"PCoA_BC\",\n                      colour_by = \"most_abundant\") +\n  scale_colour_manual(values = my_colors,\n                      labels = paste0(names(most_abundant_percent), \"(\", most_abundant_percent, \"%)\")) +\n  labs(x = paste(\"PC 1 (\", round(var_explained[1], 1), \"%)\"),\n       y = paste(\"PC 2 (\", round(var_explained[2], 1), \"%)\"),\n       color = \"\")\n\nplot\n\n\n\n\n\n\n\nSimilarly, we visualize and compare the sub-population.\n\n# Calculating the frequencies and percentages for both categories\nfreq_TRUE &lt;- table(as.character(most_abundant[colData(tse_genus)$Group == TRUE]))\nfreq_FALSE &lt;- table(as.character(most_abundant[colData(tse_genus)$Group == FALSE]))\npercent_TRUE &lt;- round(freq_TRUE / sum(freq_TRUE) * 100, 1)\npercent_FALSE &lt;- round(freq_FALSE / sum(freq_FALSE) * 100, 1)\n\n# Visualization\nplotReducedDim(tse_genus[ , colData(tse_genus)$Group == TRUE], \"PCoA_BC\",\n               colour_by = \"most_abundant\") +\n  scale_colour_manual(values = my_colors,\n                      labels = paste0(names(percent_TRUE), \"(\", percent_TRUE, \"%)\")) +\n  labs(x = paste(\"PC 1 (\", round(var_explained[1], 1), \"%)\"),\n       y = paste(\"PC 2 (\", round(var_explained[2], 1), \"%)\"),\n       title = \"Group = TRUE\", color = \"\")\n\n\n\n\n\n\n\nplotReducedDim(tse_genus[ , colData(tse_genus)$Group == FALSE], \"PCoA_BC\",\n               colour_by = \"most_abundant\") +\n  scale_colour_manual(values = my_colors,\n                      labels = paste0(names(percent_FALSE), \"(\", percent_FALSE, \"%)\")) +\n  labs(x = paste(\"PC 1 (\", round(var_explained[1], 1), \"%)\"),\n       y = paste(\"PC 2 (\", round(var_explained[2], 1), \"%)\"),\n       title = \"Group = FALSE\", color = \"\")\n\n\n\n\n\n\n\n\n7.3.1 Testing differences in community composition between sample groups\nPermutational Analysis of Variance (PERMANOVA; (2001)) is a widely used non-parametric multivariate method that aims to estimate the actual statistical significance of differences in the observed community composition between two groups of samples.\n\nAnderson, Marti J. 2001. ‚ÄúA New Method for Non-Parametric Multivariate Analysis of Variance.‚Äù Austral Ecology 26 (1): 32‚Äì46. https://doi.org/10.1111/j.1442-9993.2001.01070.pp.x.\nPERMANOVA tests the hypothesis that the centroids and dispersion of the community are equivalent between the compared groups. A p-value smaller than the significance threshold indicates that the groups have a different community composition. This method is implemented with the adonis2 function from the vegan package.\nBy default, the argument by is set to \"terms\", in which the order of variables in the formula matters. In this case, each variable is analyzed sequentially, and the result is different when more than 1 variable is introduced and their order differs. Therefore, it is recommended to set by = \"margin\", which specifies that the marginal effect of each variable is analyzed individually. You can view a comparison between the two designs in chapter Section¬†A.2.\nWe can perform PERMANOVA either with adonis2 function or by first performing dbRDA and then applying permutational test its results. An advantage of the latter approach is that by doing so we can get coefficients: how much each taxa affects the variation between communities.\n\n# Agglomerate data to Species level\ntse &lt;- mergeFeaturesByRank(tse,\n                           rank = \"Species\")\n\n# Set seed for reproducibility\nset.seed(1576)\n# We choose 99 random permutations. Consider applying more (999 or 9999) in your\n# analysis. \npermanova &lt;- adonis2(t(assay(tse, \"relabundance\")) ~ Group,\n                     by = \"margin\", # each term (here only 'Group') analyzed individually\n                     data = colData(tse),\n                     method = \"euclidean\",\n                     permutations = 99)\n\n# Set seed for reproducibility\nset.seed(1576)\n# Perform dbRDA\ndbrda &lt;- dbrda(t(assay(tse,\"relabundance\")) ~ Group, \n               data = colData(tse))\n# Perform permutational analysis\npermanova2 &lt;- anova.cca(dbrda,\n                        by = \"margin\", # each term (here only 'Group') analyzed individually\n                        method = \"euclidean\",\n                        permutations = 99)\n\n# Get p-values\np_values &lt;- c(permanova[\"Group\", \"Pr(&gt;F)\"], permanova2[\"Group\", \"Pr(&gt;F)\"])\np_values &lt;-as.data.frame(p_values)\nrownames(p_values) &lt;- c(\"adonis2\", \"dbRDA+anova.cca\")\np_values\n##                  p_values\n##  adonis2             0.02\n##  dbRDA+anova.cca     0.02\n\nAs we can see, the community composition is significantly different between the groups (p &lt; 0.05), and these two methods give equal p-values.\nLet us visualize the model coefficients for species that exhibit the largest differences between the groups. This gives some insights into how the groups tend to differ from each other in terms of community composition.\n\n# Add taxa info\nsppscores(dbrda) &lt;- t(assay(tse, \"relabundance\"))\n# Get coefficients\ncoef &lt;- dbrda$CCA$v\n# Get the taxa with biggest weights\ntop.coef &lt;- head(coef[rev(order(abs(coef))), , drop = FALSE], 20)\n# Sort weights in increasing order\ntop.coef &lt;- top.coef[order(top.coef), ]\n# Get top names\ntop_names &lt;- names(top.coef)[order(abs(top.coef), decreasing = TRUE)]\n\n\ndf &lt;- data.frame(x = top.coef,\n                 y = factor(names(top.coef), unique(names(top.coef))))\n\nggplot(df, aes(x = x, y = y)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"\", y= \"\", title = \"Top Taxa\") +\n  theme_bw()\n\n\n\n\n\n\n\nIn the example above, the largest differences between the two groups can be attributed to Genus:Bacteroides (elevated in the first group) and Family:Ruminococcaceae (elevated in the second group), and many other co-varying species.\n\n7.3.2 Checking the homogeneity condition\nIt is important to note that the application of PERMANOVA assumes homogeneous group dispersions (variances). This can be tested with the PERMDISP2 method (Anderson 2006) by using the same assay and distance method than in PERMANOVA.\n\n‚Äî‚Äî‚Äî. 2006. ‚ÄúDistance-Based Tests for Homogeneity of Multivariate Dispersions.‚Äù Biometrics 62: 245‚Äì53. https://doi.org/10.1111/j.1541-0420.2005.00440.x.\n\nanova(betadisper(vegdist(t(assay(tse, \"counts\"))), colData(tse)$Group))\n##  Analysis of Variance Table\n##  \n##  Response: Distances\n##            Df Sum Sq Mean Sq F value  Pr(&gt;F)    \n##  Groups     1 0.2385  0.2385     103 3.6e-10 ***\n##  Residuals 24 0.0554  0.0023                    \n##  ---\n##  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nIf the groups have similar dispersion, PERMANOVA can be seen as an appropriate choice for comparing community compositions."
  },
  {
    "objectID": "pages/20_beta_diversity.html#summary",
    "href": "pages/20_beta_diversity.html#summary",
    "title": "7¬† Community Similarity",
    "section": "\n7.4 Summary",
    "text": "7.4 Summary\nAs a final note, we provide a comprehensive list of functions for the evaluation of dissimilarity indices available in the mia and scater packages. The calculate methods return a reducedDim object as an output, whereas the run methods store the reducedDim object into the specified TreeSE.\n\nCanonical Correspondence Analysis (CCA): calculateCCA and runCCA\n\ndbRDA: calculateRDA and runRDA\n\nDouble Principal Coordinate Analysis (DPCoA): calculateDPCoA and runDPCoA\n\nJensen-Shannon Divergence (JSD): calculateJSD and runJSD\n\nMDS: calculateMDS and runMDS\n\nNMDS: calculateNMDS and runNMDS\n\nOverlap: calculateOverlap and runOverlap\n\nt-distributed Stochastic Neighbor Embedding (t-SNE): calculateTSNE and runTSNE\n\nUMAP: calculateUMAP and runUMAP\n\n\nFor more information on clustering samples by beta diversity, you can refer to:\n\n\nHow to extract information from clusters\n\nChapter Chapter¬†9 on community typing"
  },
  {
    "objectID": "pages/21_microbiome_community.html#sec-visual-composition",
    "href": "pages/21_microbiome_community.html#sec-visual-composition",
    "title": "8¬† Community Composition",
    "section": "\n8.1 Visualizing taxonomic composition",
    "text": "8.1 Visualizing taxonomic composition\n\n8.1.1 Composition barplot\nA typical way to visualize microbiome composition is by using composition barplot. In the following, relative abundance is calculated and top taxa are retrieved for the Phylum rank. Thereafter, the barplot is visualized ordering rank by abundance values and samples by ‚ÄúBacteroidetes‚Äù:\n\nlibrary(miaViz)\n# Computing relative abundance\ntse &lt;- transformAssay(tse, assay.type = \"counts\", method = \"relabundance\")\n\n# Getting top taxa on a Phylum level\ntse_phylum &lt;- mergeFeaturesByRank(tse, rank =\"Phylum\", onRankOnly=TRUE)\ntop_taxa &lt;- getTopFeatures(tse_phylum,top = 5, assay.type = \"relabundance\")\n\n# Renaming the \"Phylum\" rank to keep only top taxa and the rest to \"Other\"\nphylum_renamed &lt;- lapply(rowData(tse)$Phylum,\n                   function(x){if (x %in% top_taxa) {x} else {\"Other\"}})\nrowData(tse)$Phylum &lt;- as.character(phylum_renamed)\n\n# Visualizing the composition barplot, with samples order by \"Bacteroidetes\"\nplotAbundance(tse, assay.type=\"relabundance\", rank = \"Phylum\",\n              order_rank_by=\"abund\", \n              order_sample_by = \"Bacteroidetes\")\n\n\n\n\n\n\n\n\n8.1.2 Composition heatmap\nCommunity composition can be visualized with heatmap, where the horizontal axis represents samples and the vertical axis the taxa. Color of each intersection point represents abundance of a taxon in a specific sample.\nHere, abundances are first CLR (centered log-ratio) transformed to remove compositionality bias. Then Z transformation is applied to CLR-transformed data. This shifts all taxa to zero mean and unit variance, allowing visual comparison between taxa that have different absolute abundance levels. After these rough visual exploration techniques, we can visualize the abundances at Phylum level.\n\nlibrary(ggplot2)\n\n# Add clr-transformation on samples\ntse_phylum &lt;- transformAssay(tse_phylum, assay.type = \"counts\",\n                              method = \"relabundance\", pseudocount = 1)\n\ntse_phylum &lt;- transformAssay(tse_phylum, assay.type = \"relabundance\",\n                              method = \"clr\", pseudocount = 1)\n\n# Add z-transformation on features (taxa)\ntse_phylum &lt;- transformAssay(tse_phylum, assay.type = \"clr\", \n                              MARGIN = \"features\",\n                              method = \"z\", name = \"clr_z\")\n\nVisualize as heatmap.\n\n# Melt the assay for plotting purposes\ndf &lt;- meltAssay(tse_phylum, assay.type = \"clr_z\")\n\n# Determines the scaling of colours\nmaxval &lt;- round(max(abs(df$clr_z)))\nlimits &lt;- c(-maxval, maxval)\nbreaks &lt;- seq(from = min(limits), to = max(limits), by = 0.5)\ncolours &lt;- c(\"darkblue\", \"blue\", \"white\", \"red\", \"darkred\")\n\n# Creates a ggplot object\nggplot(df, aes(x = SampleID, y = FeatureID, fill = clr_z)) +\n  geom_tile() +\n  scale_fill_gradientn(name = \"CLR + Z transform\", \n                       breaks = breaks, limits = limits, colours = colours) + \n  theme(text = element_text(size=10),\n        axis.text.x = element_text(angle=45, hjust=1),\n        legend.key.size = unit(1, \"cm\")) +\n  labs(x = \"Samples\", y = \"Taxa\")\n\n\n\n\n\n\n\npheatmap is a package that provides methods to plot clustered heatmaps.\n\nlibrary(pheatmap)\n\n# Takes subset: only samples from feces, skin, or tongue\ntse_phylum_subset &lt;- tse_phylum[ , tse_phylum$SampleType %in% c(\"Feces\", \"Skin\", \"Tongue\") ]\n\n# Add clr-transformation\ntse_phylum_subset &lt;- transformAssay(tse_phylum_subset,\n                         method = \"clr\",\n                 pseudocount = 1)\n\ntse_phylum_subset &lt;- transformAssay(tse_phylum_subset, assay.type = \"clr\",\n                                     MARGIN = \"features\", \n                                     method = \"z\", name = \"clr_z\")\n\n# Get n most abundant taxa, and subsets the data by them\ntop_taxa &lt;- getTopFeatures(tse_phylum_subset, top = 20)\ntse_phylum_subset &lt;- tse_phylum_subset[top_taxa, ]\n\n# Gets the assay table\nmat &lt;- assay(tse_phylum_subset, \"clr_z\")\n\n# Creates the heatmap\npheatmap(mat)\n\n\n\n\n\n\n\nWe can create clusters by hierarchical clustering and add them to the plot.\n\nlibrary(ape)\n\n# Hierarchical clustering\ntaxa_hclust &lt;- hclust(dist(mat), method = \"complete\")\n\n# Creates a phylogenetic tree\ntaxa_tree &lt;- as.phylo(taxa_hclust)\n\n\nlibrary(ggtree)\n\n# Plot taxa tree\ntaxa_tree &lt;- ggtree(taxa_tree) + \n  theme(plot.margin=margin(0,0,0,0)) # removes margins\n\n# Get order of taxa in plot\ntaxa_ordered &lt;- get_taxa_name(taxa_tree)\n\ntaxa_tree\n\n\n\n\n\n\n\nBased on phylo tree, we decide to create three clusters.\n\n# Creates clusters\ntaxa_clusters &lt;- cutree(tree = taxa_hclust, k = 3)\n\n# Converts into data frame\ntaxa_clusters &lt;- data.frame(clusters = taxa_clusters)\ntaxa_clusters$clusters &lt;- factor(taxa_clusters$clusters)\n\n# Order data so that it's same as in phylo tree\ntaxa_clusters &lt;- taxa_clusters[taxa_ordered, , drop = FALSE] \n\n# Prints taxa and their clusters\ntaxa_clusters\n##                   clusters\n##  Chloroflexi             3\n##  Actinobacteria          3\n##  Crenarchaeota           3\n##  Planctomycetes          3\n##  Gemmatimonadetes        3\n##  Thermi                  3\n##  Acidobacteria           3\n##  Spirochaetes            2\n##  Fusobacteria            2\n##  SR1                     2\n##  Cyanobacteria           2\n##  Proteobacteria          2\n##  Synergistetes           2\n##  Lentisphaerae           1\n##  Bacteroidetes           1\n##  Verrucomicrobia         1\n##  Tenericutes             1\n##  Firmicutes              1\n##  Euryarchaeota           1\n##  SAR406                  1\n\n\n# Adds information to rowData\nrowData(tse_phylum_subset)$clusters &lt;- taxa_clusters[order(match(rownames(taxa_clusters), rownames(tse_phylum_subset))), ]\n\n# Prints taxa and their clusters\nrowData(tse_phylum_subset)$clusters\n##   [1] 1 1 2 3 2 2 1 1 1 1 3 2 3 3 3 2 2 3 3 1\n##  Levels: 1 2 3\n\n\n# Hierarchical clustering\nsample_hclust &lt;- hclust(dist(t(mat)), method = \"complete\")\n\n# Creates a phylogenetic tree\nsample_tree &lt;- as.phylo(sample_hclust)\n\n# Plot sample tree\nsample_tree &lt;- ggtree(sample_tree) + layout_dendrogram() + \n  theme(plot.margin=margin(0,0,0,0)) # removes margins\n\n# Get order of samples in plot\nsamples_ordered &lt;- rev(get_taxa_name(sample_tree))\n\nsample_tree\n\n\n\n\n\n\n\n\n# Creates clusters\nsample_clusters &lt;- factor(cutree(tree = sample_hclust, k = 3))\n\n# Converts into data frame\nsample_data &lt;- data.frame(clusters = sample_clusters)\n\n# Order data so that it's same as in phylo tree\nsample_data &lt;- sample_data[samples_ordered, , drop = FALSE] \n\n# Order data based on \ntse_phylum_subset &lt;- tse_phylum_subset[ , rownames(sample_data)]\n\n# Add sample type data\nsample_data$sample_types &lt;- unfactor(colData(tse_phylum_subset)$SampleType)\n\nsample_data\n##          clusters sample_types\n##  M11Plmr        2         Skin\n##  M31Plmr        2         Skin\n##  F21Plmr        2         Skin\n##  M31Fcsw        1        Feces\n##  M11Fcsw        1        Feces\n##  TS28           3        Feces\n##  TS29           3        Feces\n##  M31Tong        3       Tongue\n##  M11Tong        3       Tongue\n\nNow we can create heatmap with additional annotations.\n\n# Determines the scaling of colorss\n# Scale colors\nbreaks &lt;- seq(-ceiling(max(abs(mat))), ceiling(max(abs(mat))), \n              length.out = ifelse( max(abs(mat))&gt;5, 2*ceiling(max(abs(mat))), 10 ) )\ncolors &lt;- colorRampPalette(c(\"darkblue\", \"blue\", \"white\", \"red\", \"darkred\"))(length(breaks)-1)\n\npheatmap(mat, annotation_row = taxa_clusters, \n         annotation_col = sample_data,\n         breaks = breaks,\n         color = colors)\n\n\n\n\n\n\n\nIn addition, there are also other packages that provide functions for more complex heatmaps, such as iheatmapr and ComplexHeatmap (Gu 2022). sechm package provides wrapper for ComplexHeatmap and its usage is explained in chapter Chapter¬†15 along with the pheatmap package for clustered heatmaps.\n\n\n\nGu, Zuguang. 2022. ‚ÄúComplex Heatmap Visualization.‚Äù iMeta 1 (3): e43. https://doi.org/https://doi.org/10.1002/imt2.43."
  },
  {
    "objectID": "pages/24_clustering.html#custom-tools",
    "href": "pages/24_clustering.html#custom-tools",
    "title": "9¬† Community Typing (Clustering)",
    "section": "\n9.1 Custom tools",
    "text": "9.1 Custom tools\nbluster is a Bioconductor package providing tools for clustering data in in the SummarizedExperiment container. It offers multiple algorithms such as hierarchical clustering, DBSCAN, and K-means.\n\n# Load dependencies\nlibrary(bluster)\nlibrary(kableExtra)\n\nIn the first examples of microbiome community typing we use enterotype data.\n\nlibrary(mia)\ndata(\"enterotype\", package = \"mia\")\ntse &lt;- enterotype\n\n# Apply transformation\ntse &lt;- transformAssay(tse, method = \"relabundance\")\n\nThe main focus in this example is to show how to use mia‚Äôs cluster function to cluster enterotype data. cluster function allows to choose a clustering algorithm and offers multiple parameters to shape the result.\nIn this example, HclustParam() parameter is chosen for hierarchical clustering. HclustParam() parameter itself has parameters on its own HclustParam documentation. A parameter is MARGIN defines whether to cluster features or samples .\n\n# Simple use of the hierarchical clustering. Here, the default parameters\n# Set the cut height to half of the dendrogram height\n\n# Save as an alternative experiment that contains clustering information\naltExp(tse, \"hclust\") &lt;- cluster(tse, assay.type = \"relabundance\", \n               MARGIN = \"samples\", HclustParam())\n\n# The result can be found in 'clusters' column of colData\n\n# The number of samples included in each cluster\nsummary(colData(altExp(tse, \"hclust\"))$clusters)\n##   1  2  3  4  5  6  7  8  9 \n##  92 25 21  2 55 41 20 23  1\n\nOnce the clustering on the samples is done, we can also plot the clusters.\n\nlibrary(scater)\n\n# Add the MDS dimensions for plotting\naltExp(tse, \"hclust\") &lt;- runMDS(altExp(tse, \"hclust\"), assay.type = \"relabundance\", \n              FUN = vegan::vegdist, method = \"bray\")\n\n# Plot the clusters\nplotReducedDim(altExp(tse, \"hclust\"), \"MDS\", colour_by = \"clusters\")"
  },
  {
    "objectID": "pages/24_clustering.html#hierarchical-clustering",
    "href": "pages/24_clustering.html#hierarchical-clustering",
    "title": "9¬† Community Typing (Clustering)",
    "section": "\n9.2 Hierarchical clustering",
    "text": "9.2 Hierarchical clustering\nThe hierarchical clustering algorithm aims to find hierarchy between samples/features. There are to approaches: agglomerative (‚Äúbottom-up‚Äù) and divisive (‚Äútop-down‚Äù). In agglomerative approach, each observation is first in a unique cluster. The algorithm continues by agglomerating similar clusters. The divisive approach, instead, starts with one cluster that contains all observations. Clusters are split recursively into clusters that differ the most. The clustering ends when each cluster contains only one observation. In this algorithm, the similarity of two clusters is based on the distance between them.\nHierarchical clustering can be visualized with a dendrogram tree. In each splitting point, the tree is divided into two clusters leading to the hierarchy.\nHierarchical clustering requires two steps. 1. Computation of the dissimilarities with a given distance.\n2. Clustering based on dissimilarities.\nAdditionally, since sequencing data is compositional, we apply relative transformation (as seen in the previous example).\nIn this example, we want to add information on the clustering. To do so, we use the full parameter. We also compute the dissimilarities with the bray distance. Finally, the clust.col parameter allows us to choose the name of the column in the colData (default name is clusters).\n\nlibrary(vegan)\n\n# Save another alternative experiment that contains full clustering information\naltExp(tse, \"hclust_full\") &lt;- cluster(tse,\n               assay.type = \"relabundance\",\n               MARGIN = \"samples\",\n               HclustParam(method = \"complete\",\n                           dist.fun = vegdist,\n                           metric = \"bray\"),\n               full = TRUE,\n               clust.col = \"Hclust\")\n\nWe plot the dendrogram, which is possible since we got the additional information from the clustering.\n\nlibrary(dendextend)\n\n# Get hclust data from metadata\nhclust_data &lt;- metadata(altExp(tse, \"hclust_full\"))$clusters$hclust\n\n# Get the dendrogram object\ndendro &lt;- as.dendrogram(hclust_data)\n\n# Plot dendrogram\ndendro %&gt;% set(\"labels\", NULL) %&gt;% plot()\n\n\n\n\n\n\n\nIn our case, we cut the dendrogram in half by default. To know how many clusters we have, we can check the colData.\n\n# Get the clusters\nsummary(colData(altExp(tse, \"hclust_full\"))$Hclust)\n##   1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \n##   3 65 35 12  9  2 23 23 27 15  4 11  6 11  2  1  9  7  4  4  1  2  1  1  1 \n##  26 \n##   1\n\nWe can see that there are 26 clusters, but that probably is not optimal since the the number of clusters has been chosen arbitrarily. To determine the number of clusters, we can use the dendrogram. Usually the tree is split where the branch length is the largest. However, as we can see from the dendrogram, clusters are not clear. There are algorithms to identify the optimal number of clusters.\nThe NbClust library is useful to that end as it offers multiple methods to determine the optimal number of clusters. Here we will use the silhouette analysis to determine the optimal number of clusters. For each data point, this analysis measures the distance to other data points in the same cluster (cohesion), and the distance to the other clusters (separation), establishing a score. That score is then combined across the data points. NbClust does this for multiple number of clusters and the best score corresponds to the optimal number of clusters.\n\nlibrary(NbClust)\ndiss &lt;- metadata(altExp(tse, \"hclust_full\"))$clusters$dist\n\n# Apply the silhouette analysis on the distance matrix\nres &lt;- NbClust(diss = diss, distance = NULL, method = \"ward.D2\",\n               index = \"silhouette\")\n##  \n##   Only frey, mcclain, cindex, sihouette and dunn can be computed. To compute the other indices, data matrix is needed\n\nres$Best.nc\n##  Number_clusters     Value_Index \n##           2.0000          0.4783\n\nBased on the result, let‚Äôs divide observations into 2 clusters.\n\nlibrary(dendextend)\n\n# Get optimal number of clusters\nk &lt;- res$Best.nc[1]\n\n# Making colors for 2 clusters\ncol_val_map &lt;- randomcoloR::distinctColorPalette(k) %&gt;%\n    as.list() %&gt;% \n    setNames(paste0(\"clust_\", seq(k)))\n\ndend &lt;- color_branches(dendro, k = k, col = unlist(col_val_map))\nlabels(dend) &lt;- NULL\nplot(dend)"
  },
  {
    "objectID": "pages/24_clustering.html#dirichlet-multinomial-mixtures-dmm",
    "href": "pages/24_clustering.html#dirichlet-multinomial-mixtures-dmm",
    "title": "9¬† Community Typing (Clustering)",
    "section": "\n9.3 Dirichlet Multinomial Mixtures (DMM)",
    "text": "9.3 Dirichlet Multinomial Mixtures (DMM)\nThis section focus on Dirichlet-Multinomial Mixture Model analysis. It is a probabilistic technique that allows to search for sample patterns that reflect sample similarity in the data. DMM has a property of determining an optimal number of clusters (k) to obtain the best model. The minimum value of Laplace approximation to the negative log model evidence for DMM models as a function of k, determines an optimal k. The optimal k suggests to fit a model with k mixtures of Dirichlet distributions. For the best model, k probabilities for each sample to belong to each cluster are obtained.\nIn this example, we cluster the data with DMM clustering. Since the data set is large, the algorithm requires a lot of computational capacity. Therefore, we use only a subset of the data that is agglomerated by Phylum as a rank.\nIn the example of DMM we use GlobalPatterns data.\n\n# Get the data\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\n# Agglomerate by rank\ntse &lt;- mergeFeaturesByRank(tse, rank = \"Phylum\", agglomerateTree = TRUE)\n\nIn the example below, we calculate model fit using Laplace approximation. The cluster information is added in the metadata with an optional name.\n\n# Run the model and calculates the most likely number of clusters from 1 to 7\n\n# Save as an alternative experiment that contains clustering information\naltExp(tse, \"dmm\") &lt;- cluster(tse, name = \"DMM\", DmmParam(k = 1:7, type = \"laplace\"), \n                   MARGIN = \"samples\", full = TRUE)\n\n\n# The dmm information is stored in the metadata under the 'DMM' column that includes information about all seven models \naltExp(tse, \"dmm\")\n##  class: TreeSummarizedExperiment \n##  dim: 67 26 \n##  metadata(2): agglomerated_by_rank DMM\n##  assays(1): counts\n##  rownames(67): Phylum:Crenarchaeota Phylum:Euryarchaeota ...\n##    Phylum:Synergistetes Phylum:SR1\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(8): X.SampleID Primer ... Description clusters\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (67 rows)\n##  rowTree: 1 phylo tree(s) (66 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nThe plot below represents the Laplace approximation to the model evidence for each of the k models. We can see that the best number of clusters is two.\n\nlibrary(miaViz)\nplotDMNFit(altExp(tse, \"dmm\"), type = \"laplace\", name = \"DMM\")\n\n\n\n\n\n\n\nThe best model can be confirmed with the following operation.\n\n# Get the the best model\nbestFit &lt;- metadata(altExp(tse, \"dmm\"))$DMM$dmm[[metadata(altExp(tse, \"dmm\"))$DMM$best]]\nbestFit\n##  class: DMN \n##  k: 2 \n##  samples x taxa: 26 x 67 \n##  Laplace: 7673 BIC: 7927 AIC: 7842\n\nThe clusters for the best model are saved in the colData under ‚Äòcluster‚Äô column.\n\nhead(colData(altExp(tse, \"dmm\"))$clusters, 10)\n##      CL3     CC1     SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr F21Plmr M31Tong \n##        1       1       1       2       2       2       2       2       2 \n##  M11Tong \n##        2 \n##  Levels: 1 2\n\nMore detailed information about the clusters can be accessed in the metadata. The metadata contains samples-cluster assignment probabilities that tell us the likelihood for each sample to belong to each cluster.\n\nhead(metadata(altExp(tse, \"dmm\"))$DMM$prob, 10) \n##                  1         2\n##  CL3     1.000e+00 5.019e-17\n##  CC1     1.000e+00 3.864e-22\n##  SV1     1.000e+00 1.948e-12\n##  M31Fcsw 7.861e-26 1.000e+00\n##  M11Fcsw 1.130e-16 1.000e+00\n##  M31Plmr 1.122e-13 1.000e+00\n##  M11Plmr 3.340e-06 1.000e+00\n##  F21Plmr 4.228e-11 1.000e+00\n##  M31Tong 1.450e-08 1.000e+00\n##  M11Tong 2.227e-06 1.000e+00\n\nOnce the optimal model have been confirmed, we can find out which samples are grouped with each other. The table below shows one sample of each sample type clustered in either of the groups. We can notice that DMM can distinguish environmental samples into one group, and mock and human samples into another. For clarity, in this example, the probabilities for each sample to belong in each cluster have been rounded.\n\nlibrary(dplyr)\n\nclusters &lt;- round(metadata(altExp(tse, \"dmm\"))$DMM$prob, 1)\nclusters &lt;- as.data.frame(cbind(clusters, levels(altExp(tse, \"dmm\")$SampleType)[altExp(tse, \"dmm\")$SampleType])) # add sample type information\ncolnames(clusters) &lt;- c(\"Group1\", \"Group2\", \"SampleType\")\n\nclusters %&gt;%\n  group_by(SampleType) %&gt;%\n  arrange(Group1) %&gt;%\n  filter(row_number()==1)\n##  # A tibble: 9 √ó 3\n##  # Groups:   SampleType [9]\n##    Group1 Group2 SampleType\n##    &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;     \n##  1 0      1      Feces     \n##  2 0      1      Skin      \n##  3 0      1      Tongue    \n##  4 0      1      Mock      \n##  5 1      0      Soil      \n##  6 1      0      Freshwater\n##  # ‚Ñπ 3 more rows\n\nWe can also plot the driver Phyla in each group. In this case, it reflects the differences between environmental and human samples.\n\n# Get the estimates on how much each phyla contributes on each cluster\nbest_model &lt;- metadata(altExp(tse, \"dmm\"))$DMM$dmm[2]\ndrivers &lt;- as.data.frame(best_model[[1]]@fit$Estimate)\n\ndrivers$phyla &lt;- gsub(\"Phylum:\", \"\", rownames(drivers)) # Clean phylum names\n\nplots &lt;- c()\nfor (i in 1:2) {\n  drivers &lt;- drivers[order(drivers[[i]], decreasing = TRUE),]\n  p &lt;- ggplot(head(drivers, 10), aes(x = reorder(head(phyla, 10), + head(drivers[[i]], 10)), y = head(drivers[[i]], 10))) +\n          geom_bar(stat = \"identity\", fill = \"deeppink4\", alpha = 0.5) +\n          coord_flip() + labs(title = paste(\"Top phyla in group\", i)) +\n          theme_light(base_size = 15) + labs(x=\"\", y=\"\") + scale_y_continuous(limits=c(0,7))\n\n  print(p)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe use calculateDMNgroup function to have an overview of the best model. The function groups samples by SampleType column from colData and returns DMNGroup object that contains a summary.\n\ndmm_group &lt;- calculateDMNgroup(altExp(tse, \"dmm\"), variable = \"SampleType\", \n                               assay.type = \"counts\", k = 2, \n                               seed = .Machine$integer.max)\n\ndmm_group\n##  class: DMNGroup \n##  summary:\n##                     k samples taxa    NLE  LogDet Laplace    BIC  AIC\n##  Feces              2       4   67 1078.3 -106.26   901.1 1171.9 1213\n##  Freshwater         2       2   67  889.6  -97.20   716.9  936.4 1025\n##  Freshwater (creek) 2       3   67 1600.3  862.19  1907.3 1674.5 1735\n##  Mock               2       3   67 1008.4  -55.40   856.6 1082.5 1143\n##  Ocean              2       3   67 1096.7  -56.66   944.3 1170.9 1232\n##  Sediment (estuary) 2       3   67 1195.5   18.63  1080.8 1269.7 1331\n##  Skin               2       3   67  992.6  -85.05   826.1 1066.8 1128\n##  Soil               2       3   67 1380.3   11.20  1261.8 1454.5 1515\n##  Tongue             2       2   67  783.0 -107.79   605.0  829.8  918\n\nMixture weights can be used for having a rough approximation of the cluster size.\n\nDirichletMultinomial::mixturewt(bestFit)\n##        pi theta\n##  1 0.5385 20.58\n##  2 0.4615 15.28\n\n\n9.3.1 PCoA with DMM clusters\nIn this section we show how to calculate principal coordinates for clr transformed abundance data. To calculate PCoA, we use Aitchison distance as a distance metrics that calculates Euclidean distances for clr transformed compositions.\nIn the visualization section, we project the sample distances on two dimensional space of first two principal coordinates. We colour the samples based on their DMM clusters. The visualization demonstrates that the DMM clusters can be distinguished on a PCoA plot, although the clusters are not coherent. This means that two-dimensional representation of the data created by PCoA preserves similar information that drives the DMM cluster division.\n\n# add pseudocount, because data contains zeros\nassay(tse, \"pseudo\") &lt;- assay(tse, \"counts\") + 1\ntse &lt;- transformAssay(tse, assay.type = \"pseudo\", method = \"relabundance\")\n\n# clr transformation\ntse &lt;- transformAssay(tse, \"relabundance\", method = \"clr\")\n\n# principal coordinate analysis\ndf &lt;- calculateMDS(tse, assay.type = \"clr\", method = \"euclidean\")\n\n# Create a data frame from principal coordinates\neuclidean_pcoa_df &lt;- data.frame(pcoa1 = df[, 1], pcoa2 = df[, 2])\n\n\n# Create a data frame that contains principal coordinates and DMM information\neuclidean_dmm_pcoa_df &lt;- cbind(euclidean_pcoa_df,\n                               dmm_component = colData(altExp(tse, \"dmm\"))$clusters)\n\n# Create a plot\neuclidean_dmm_plot &lt;- ggplot(data = euclidean_dmm_pcoa_df,\n                             aes(x = pcoa1, y = pcoa2, color = dmm_component)) +\n    geom_point() +\n    labs(x = \"Coordinate 1\",y = \"Coordinate 2\", \n         title = \"PCoA with Aitchison distances\") +\n    theme(plot.title = element_text(size = 12, # makes titles smaller\n                                    hjust = 0.5)) \n\neuclidean_dmm_plot"
  },
  {
    "objectID": "pages/24_clustering.html#biclustering",
    "href": "pages/24_clustering.html#biclustering",
    "title": "9¬† Community Typing (Clustering)",
    "section": "\n9.4 Biclustering",
    "text": "9.4 Biclustering\nBiclustering methods cluster rows and columns simultaneously in order to find subsets of correlated features/samples.\nHere, we use following packages:\n\nbiclust\ncobiclust\n\ncobiclust is especially developed for microbiome data whereas biclust is more general method. In this section, we show two different cases and example solutions to apply biclustering to them.\n\nTaxa vs samples\nTaxa vs biomolecule/biomarker\n\nBiclusters can be visualized using heatmap or boxplot, for instance. For checking purposes, also scatter plot might be valid choice.\nCheck more ideas for heatmaps from chapters Chapter¬†15 and Chapter¬†8.\n\n9.4.1 Taxa vs samples\nWhen you have microbial abundance matrices, we suggest to use cobiclust which is designed for microbial data.\nLoad example data\n\nlibrary(cobiclust)\ndata(\"HintikkaXOData\")\nmae &lt;- HintikkaXOData\n\nOnly the most prevalent taxa are included in analysis.\n\n# Subset data in the first experiment\nmae[[1]] &lt;- subsetByPrevalentFeatures(mae[[1]], rank = \"Genus\", \n                                      prevalence = 0.2, \n                                      detection = 0.001)\n\n# rclr-transform in the first experiment\nmae[[1]] &lt;- transformAssay(mae[[1]], method = \"rclr\")\n\ncobiclust takes counts table as an input and gives cobiclust object as an output. It includes clusters for taxa and samples.\n\n# Do clustering using counts table\nclusters &lt;- cobiclust(assay(mae[[1]], \"counts\"))\n\n# Get clusters\nrow_clusters &lt;- clusters$classification$rowclass\ncol_clusters &lt;- clusters$classification$colclass\n\n# Add clusters to rowdata and coldata\nrowData(mae[[1]])$clusters &lt;- factor(row_clusters)\ncolData(mae[[1]])$clusters &lt;- factor(col_clusters)\n\n# Order data based on clusters\nmae[[1]] &lt;- mae[[1]][order(rowData(mae[[1]])$clusters),\n                     order(colData(mae[[1]])$clusters)]\n\n# Print clusters\nclusters$classification\n##  $rowclass\n##    [1] 1 1 1 1 1 1 1 1 1 2 2 1 2 1 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 2 2 1 1 2 1 1\n##   [37] 2 1 2 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1\n##   [73] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1 1 1 1 2 2 1\n##  [109] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n##  \n##  $colclass\n##   C1  C2  C3  C4  C5  C6  C7  C8  C9 C10 C11 C12 C13 C14 C15 C16 C17 C18 C19 \n##    1   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2 \n##  C20 C21 C22 C23 C24 C25 C26 C27 C28 C29 C30 C31 C32 C33 C34 C35 C36 C37 C38 \n##    2   2   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3 \n##  C39 C40 \n##    3   1\n\nNext we can plot clusters. Annotated heatmap is a common choice.\n\nlibrary(pheatmap)\n# z-transform for heatmap\nmae[[1]] &lt;- transformAssay(mae[[1]], assay.type = \"rclr\",\n                            MARGIN = \"features\", method = \"z\", name = \"rclr_z\")\n\n# Create annotations. When column names are equal, they should share levels.\n# Here samples include 3 clusters, and taxa 2. That is why we have to make\n# column names unique.\nannotation_col &lt;- data.frame(colData(mae[[1]])[, \"clusters\", drop = F])\ncolnames(annotation_col) &lt;- \"col_clusters\"\n\nannotation_row &lt;- data.frame(rowData(mae[[1]])[, \"clusters\", drop = F])\ncolnames(annotation_row) &lt;- \"row_clusters\"\n\nPlot the heatmap.\n\npheatmap(assay(mae[[1]], \"rclr_z\"), cluster_rows = F, cluster_cols = F,\n         annotation_col = annotation_col, annotation_row = annotation_row)\n\n\n\n\n\n\n\nBoxplot is commonly used to summarize the results:\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# ggplot requires data in melted format\nmelt_assay &lt;- meltAssay(mae[[1]], assay.type = \"rclr\", \n                        add_col_data = T, add_row_data = T)\n\n# patchwork two plots side-by-side\np1 &lt;- ggplot(melt_assay) +\n    geom_boxplot(aes(x = clusters.x, y = rclr)) +\n    labs(x = \"Taxa clusters\")\n\np2 &lt;- ggplot(melt_assay) +\n    geom_boxplot(aes(x = clusters.y, y = rclr)) +\n    labs(x = \"Sample clusters\")\n\np1 + p2\n\n\n\n\n\n\n\n\n9.4.2 Taxa vs biomolecules\nHere, we analyze cross-correlation between taxa and metabolites. This is a case, where we use biclust method which is suitable for numeric matrices in general. First we pre-process the data.\n\n# Samples must be in equal order\n# (Only 1st experiment was ordered in cobiclust step leading to unequal order)\nmae[[1]] &lt;- mae[[1]][, colnames(mae[[2]])]\n\n# Make rownames unique since it is required by other steps\nrownames(mae[[1]]) &lt;- make.unique(rownames(mae[[1]]))\n\n# Transform the metabolites to be in log basis\nmae[[2]] &lt;- transformAssay(mae[[2]], assay.type = \"nmr\", method = \"log10\")\n\n# Add missing data to the metabolites\nreplace_na &lt;- function(row) {\n    na_indices &lt;- which(is.na(row))\n    non_na_values &lt;- row[!is.na(row)]\n    row[na_indices] &lt;- sample(non_na_values, length(na_indices), replace = TRUE)\n    row\n}\nassay(mae[[2]], \"log10\") &lt;- t(apply(assay(mae[[2]], \"log10\"), 1, replace_na))\n\nNext, we compute the spearman correlation matrix.\n\n# Calculate correlations\ncorr &lt;- getExperimentCrossCorrelation(mae, 1, 2, assay.type1 = \"rclr\",\n                                      assay.type2 = \"log10\", mode = \"matrix\",\n                                      correlation = \"spearman\")\n\nbiclust takes a matrix as an input and returns a biclust object.\n\nlibrary(biclust)\n# Set seed for reproducibility\nset.seed(3973)\n\n# Find biclusters\nbc &lt;- biclust(corr, method = BCPlaid(), verbose = FALSE)\n\nbc\n##  \n##  An object of class Biclust \n##  \n##  call:\n##      biclust(x = corr, method = BCPlaid(), verbose = FALSE)\n##  \n##  Number of Clusters found:  3 \n##  \n##  First  3  Cluster sizes:\n##                     BC 1 BC 2 BC 3\n##  Number of Rows:      17   15   17\n##  Number of Columns:   13   14    9\n\nThe object includes cluster information. However compared to cobiclust, biclust object includes only information about clusters that were found, not general cluster.\nMeaning that if one cluster size of 5 features was found out of 20 features, those 15 features do not belong to any cluster. That is why we have to create an additional cluster for features/samples that are not assigned into any cluster.\n\n# Functions for obtaining biclust information\n\n# Get clusters for rows and columns\n.get_biclusters_from_biclust &lt;- function(bc, assay) {\n    # Get cluster information for columns and rows\n    bc_columns &lt;- t(bc@NumberxCol)\n    bc_columns &lt;- data.frame(bc_columns)\n    bc_rows &lt;- bc@RowxNumber\n    bc_rows &lt;- data.frame(bc_rows)\n\n    # Get data into right format\n    bc_columns &lt;- .manipulate_bc_data(bc_columns, assay, \"col\")\n    bc_rows &lt;- .manipulate_bc_data(bc_rows, assay, \"row\")\n    \n    return(list(bc_columns = bc_columns, bc_rows = bc_rows))\n}\n\n# Input clusters, and how many observations there should be, i.e.,\n# the number of samples or features\n.manipulate_bc_data &lt;- function(bc_clusters, assay, row_col) {\n    # Get right dimension\n    dim &lt;- ifelse(row_col == \"col\", ncol(assay), nrow(assay))\n    # Get column/row names\n    if (row_col == \"col\") {\n        names &lt;- colnames(assay)\n    } else {\n        names &lt;- rownames(assay)\n    }\n\n    # If no clusters were found, create one. Otherwise create additional\n    # cluster which\n    # contain those samples that are not included in clusters that were found.\n    if (nrow(bc_clusters) != dim) {\n        bc_clusters &lt;- data.frame(cluster = rep(TRUE, dim))\n    } else {\n        # Create additional cluster that includes those samples/features that\n        # are not included in other clusters.\n        vec &lt;- ifelse(rowSums(bc_clusters) &gt; 0, FALSE, TRUE)\n\n        # If additional cluster contains samples, then add it\n        if (any(vec)) {\n            bc_clusters &lt;- cbind(bc_clusters, vec)\n        }\n    }\n    \n    # Adjust row and column names\n    rownames(bc_clusters) &lt;- names\n    colnames(bc_clusters) &lt;- paste0(\"cluster_\", 1:ncol(bc_clusters))\n    return(bc_clusters)\n}\n\n\n# Get biclusters\nbcs &lt;- .get_biclusters_from_biclust(bc, corr)\n\nbicluster_rows &lt;- bcs$bc_rows\nbicluster_columns &lt;- bcs$bc_columns\n\n# Print biclusters for rows\nhead(bicluster_rows)\n##                            cluster_1 cluster_2 cluster_3 cluster_4\n##  D_5__Staphylococcus           FALSE     FALSE     FALSE      TRUE\n##  D_5__Klebsiella               FALSE     FALSE     FALSE      TRUE\n##  D_5__Streptococcus            FALSE     FALSE     FALSE      TRUE\n##  D_5__Escherichia-Shigella     FALSE     FALSE     FALSE      TRUE\n##  D_5__Ruminiclostridium 5       TRUE     FALSE      TRUE     FALSE\n##  D_5__Pseudomonas              FALSE     FALSE     FALSE      TRUE\n\nLet‚Äôs collect information for the scatter plot.\n\n# Function for obtaining sample-wise sum, mean, median, and mean variance\n# for each cluster\n\n.sum_mean_median_var &lt;- function(tse1, tse2, assay.type1, assay.type2, clusters1, clusters2) {\n    list &lt;- list()\n    # Create a data frame that includes all the information\n    for (i in 1:ncol(clusters1)) {\n        # Subset data based on cluster\n        tse_subset1 &lt;- tse1[clusters1[, i], ]\n        tse_subset2 &lt;- tse2[clusters2[, i], ]\n        # Get assay\n        assay1 &lt;- assay(tse_subset1, assay.type1)\n        assay2 &lt;- assay(tse_subset2, assay.type2)\n        # Calculate sum, mean, median, and mean variance\n        sum1 &lt;- colSums2(assay1, na.rm = T)\n        mean1 &lt;- colMeans2(assay1, na.rm = T)\n        median1 &lt;- colMedians(assay1, na.rm = T)\n        var1 &lt;- colVars(assay1, na.rm = T)\n        \n        sum2 &lt;- colSums2(assay2, na.rm = T)\n        mean2 &lt;- colMeans2(assay2, na.rm = T)\n        median2 &lt;- colMedians(assay2, na.rm = T)\n        var2 &lt;- colVars(assay2, na.rm = T)\n        \n        list[[i]] &lt;- data.frame(sample = colnames(tse1), sum1, sum2, mean1, \n                                 mean2, median1, median2, var1, var2)\n    }\n    return(list)\n}\n\n# Calculate info\ndf &lt;- .sum_mean_median_var(mae[[1]], mae[[2]], \"rclr\", \"log10\", bicluster_rows, bicluster_columns)\n\nNow we can create a scatter plot. X-axis includes median clr abundance of microbiome and y-axis median absolute concentration of each metabolite. Each data point represents a single sample.\nFrom the plots, we can see that there is low negative correlation in both cluster 1 and 3. This means that when abundance of bacteria belonging to cluster 1 or 3 is higher, the concentration of metabolites of cluster 1 or 3 is lower, and vice versa.\n\npics &lt;- list()\nfor (i in seq_along(df)) {\n    pics[[i]] &lt;- ggplot(df[[i]]) +\n        geom_point(aes(x = median1, y = median2)) +\n        labs(title = paste0(\"Cluster \", i), x = \"Taxa (rclr median)\",\n             y = \"Metabolites (abs. median)\")\n    print(pics[[i]])\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npics[[1]] + pics[[2]] + pics[[3]]\n\n\n\n\n\n\n\npheatmap does not allow boolean values, so they must be converted into factors.\n\nbicluster_columns &lt;- data.frame(apply(bicluster_columns, 2, as.factor))\nbicluster_rows &lt;- data.frame(apply(bicluster_rows, 2, as.factor))\n\nAgain, we can plot clusters with heatmap.\n\n# Adjust colors for all clusters\nif (ncol(bicluster_rows) &gt; ncol(bicluster_columns)) {\n    cluster_names &lt;- colnames(bicluster_rows)\n} else {\n    cluster_names &lt;- colnames(bicluster_columns)\n}\nannotation_colors &lt;- list()\nfor (name in cluster_names) {\n    annotation_colors[[name]] &lt;- c(\"TRUE\" = \"red\", \"FALSE\" = \"white\")\n}\n\n# Create a heatmap\npheatmap(corr, cluster_cols = F, cluster_rows = F,\n         annotation_col = bicluster_columns, annotation_row = bicluster_rows,\n         annotation_colors = annotation_colors)"
  },
  {
    "objectID": "pages/24_clustering.html#additional-community-typing",
    "href": "pages/24_clustering.html#additional-community-typing",
    "title": "9¬† Community Typing (Clustering)",
    "section": "\n9.5 Additional Community Typing",
    "text": "9.5 Additional Community Typing\nFor more community typing techniques applied to the ‚ÄòSprockettTHData‚Äô data set, see the attached .Rmd file.\nLink:\n\nRmd"
  },
  {
    "objectID": "pages/30_differential_abundance.html#statistical-challenges-of-microbiome-data",
    "href": "pages/30_differential_abundance.html#statistical-challenges-of-microbiome-data",
    "title": "10¬† Differential Abundance",
    "section": "\n10.1 Statistical challenges of microbiome data",
    "text": "10.1 Statistical challenges of microbiome data\nMicrobiome data display unique properties that are exclusively addressed by DAA tools developed for microbiome analysis. Specifically, microbiome data are characterized by high variability, zero-inflation and compositionality. High variability expresses that abundance of taxa often varies by several orders of magnitude from sample to sample. Zero-inflation means that typically more than 70% of the values are zeros, which could be due to either physical absence (structural zeros) or insufficient sampling effort (sampling zeros). Compositionality implies that a change in the absolute abundance of one taxon will lead to apparent variations in the relative abundances of other taxa in the same sample. If neglected, such properties may cause significant bias in the results of DAA. Therefore, several approaches have been developed to address the unique properties of microbiome data and provide statistically useful results.\nThe first approach to target zero-inflated data consists of specialized models, such as over-dispersed count models and zero-inflated mixture models. DESeq2, edgeR and corncorb are based on over-dispersed count models, whereas metagenomeSeq, RAIDA, ZIBB and Omnibus implement zero-inflated mixture models to address zero-inflation. Typically, these models assume a negative binomial, beta-binomial or normal/log-normal distribution. Alternatively, zero imputation also represents a valid approach to deal with zero-inflated data. ALDEx2 and eBay apply a Bayesian model to impute the zeros when working with proportion data, accounting for sampling variability and sequencing depth variation. Other methods, such as MaAsLin2 and ANCOMBC impute the zeros with a pseudo-count strategy.\nRegarding the compositionality of microbiome data, several approaches have been developed to perform robust normalization with methods specifically designed to reduce the bias found in compositional data. Some examples include trimmed mean of M-values (TMM) normalization used by edgeR, relative log expression (RLE) normalization used by DESeq2, cumulative sum scaling (CSS) normalization used by metagenomeSeq, centered log-ratio transformation (CLR) normalization used by ALDEx2 and geometric mean of pairwise ratios (GMPR) normalization used by Omnibus and Wrench normalization (Kumar et al. 2018), which corrects the compositional bias by an empirical Bayes approach. Other methods to deal with compositional data entail reference taxa approach used by DACOMP and RAIDA, analyzing the pattern of pairwise log ratios as done by ANCOM and bias-correction applied by ANCOMBC.\n\nKumar, M. Senthil, V. Eric Slud, Kwame Okrah, C. Stephanie Hicks, Sridhar Hannenhalli, and Corrada H√©ctor Bravo. 2018. ‚ÄúAnalysis and Correction of Compositional Bias in Sparse Sequencing Count Data.‚Äù BMC Genomics 19 (November). https://doi.org/10.1186/s12864-018-5160-5.\n\nCalgaro, Matteo, Chiara Romualdi, Levi Waldron, Davide Risso, and Nicola Vitulo. 2020. ‚ÄúAssessment of Statistical Methods from Single Cell, Bulk RNA-Seq, and Metagenomics Applied to Microbiome Data.‚Äù Genome Biology 21 (1): 191. https://doi.org/10.1186/s13059-020-02104-1.\n\nCalgaro, Matteo, Chiara Romualdi, Davide Risso, and Nicola Vitulo. 2022. ‚ÄúBenchdamic: Benchmarking of Differential Abundance Methods for Microbiome Data.‚Äù Bioinformatics 39 (1). https://doi.org/10.1093/bioinformatics/btac778.\nWe recommend to have a look at Nearing et al. (2022). In this study, multiple DAA methods were applied to 38 different datasets and their results were compared to one another. Because each method follows a slightly different approach in terms of assumptions and normalization techniques, it was shown that results on the same dataset may differ substantially depending on the method. Recently, Yang and Chen (2022) comprehensively evaluated DAA methods via a semi-parametric framework and 106 real datasets. This study also concluded that different methods can produce contradictory results, creating the risk of cherry-picking the most favorable options for one‚Äôs own hypothesis. Therefore, it is highly recommended to perform DAA with multiple methods to determine whether the findings can be reproduced by different approaches. Built on the findings of Calgaro et al. (2020), the benchdamic (Calgaro et al. 2022) package could offer a valuable support in this regard. Through a comprehensive evaluation process it serves both practitioners by comparing DA methods from existing literature, and method developers by providing an impartial tool to evaluate their new approaches in comparison to what is already available. For details, check its extensive vignette."
  },
  {
    "objectID": "pages/30_differential_abundance.html#using-the-tools",
    "href": "pages/30_differential_abundance.html#using-the-tools",
    "title": "10¬† Differential Abundance",
    "section": "\n10.2 Using the tools",
    "text": "10.2 Using the tools\nIn this section we demonstrate the use of four methods that can be recommended based on recent literature (ANCOM-BC (Lin and Peddada 2020), ALDEx2 (Gloor, Macklaim, and Fernandes 2016), Maaslin2 (Mallick, Rahnavard, and McIver 2020), LinDA (H. Zhou et al. 2022) and ZicoSeq (Yang and Chen 2022)).\nThe purpose of this section is to show how to perform DAA in R, not how to correctly do causal inference. Depending on your experimental setup and your theory, you must determine how to specify any model exactly. E.g., there might be confounding factors that might drive (the absence of) differences between the shown groups that we ignore here for simplicity. Or your dataset is repeated sampling design, matched-pair design or the general longitudianl design. We will demonstrate how to include covariates in those models. We picked a dataset that merely has microbial abundances in a TSE object as well as a grouping variable in the sample data. We simplify the examples by only including two of the three groups.\n\nlibrary(mia)\nlibrary(tidyverse)\n\n# Import dataset\ndata(\"Tengeler2020\", package = \"mia\")\ntse &lt;- Tengeler2020\n\n# Show patient status by cohort\ntable(tse$patient_status, tse$cohort) %&gt;%\n  knitr::kable()\n\n\n\n\nCohort_1\nCohort_2\nCohort_3\n\n\n\nADHD\n4\n5\n4\n\n\nControl\n6\n5\n3\n\n\n\n\n\n\n10.2.1 Preparing the data for DAA\nBefore starting the analysis, it is recommended to reduce the size and complexity of the data to make the results more reproducible. For this purpose, we agglomerate the features by genus and filter them by a prevalence threshold of 10%.\n\n# Agglomerate by genus and subset by prevalence\ntse &lt;- subsetByPrevalentFeatures(tse,\n                             rank = \"Genus\",\n                             prevalence = 10 / 100)\n\n# Transform count assay to relative abundances\ntse &lt;- transformAssay(tse,\n                      assay.type = \"counts\",\n                      method = \"relabundance\")\n\nWhile some DAA tools provide optional arguments for prevalence filtering, here we filtered the tse object directly. This way, we ensure that the input data remains the same when multiple tools are used.\n\n10.2.2 ALDEx2\nIn this section, we will show how to perform DAA with ALDEx2, which can be regarded as the method of choice for its consistency, as it normally identifies features that are also found by complementary methods (Nearing et al. 2022). A more extensive introduction to its functionality is available in the ALDEx2 vignette.\nALDEx2 estimates technical variation within each sample per taxon by utilizing the Dirichlet distribution. It furthermore applies the CLR transformation (or closely related log-ratio transforms). Depending on the experimental setup, it will perform a two sample Welch‚Äôs t-test and Wilcoxon test or a one-way ANOVA and Kruskal-Wallis test. For more complex study designs, there is a possibility to utilize the glm functionality within ALDEx2. The Benjamini-Hochberg procedure is applied by default to correct for multiple testing.\n\n# Load package\nlibrary(ALDEx2)\n\n# Generate Monte Carlo samples of the Dirichlet distribution for each sample.\n# Convert each instance using the centered log-ratio transform.\n# This is the input for all further analyses.\nset.seed(123)\nx &lt;- aldex.clr(assay(tse), tse$patient_status)     \n\nThe t-test:\n\n# calculates expected values of the Welch's t-test and Wilcoxon rank\n# test on the data returned by aldex.clr\nx_tt &lt;- aldex.ttest(x, paired.test = FALSE, verbose = FALSE)\n\nEffect sizes:\n\n# Determines the median clr abundance of the feature in all samples and in\n# groups, the median difference between the two groups, the median variation\n# within each group and the effect size, which is the median of the ratio\n# of the between group difference and the larger of the variance within groups\nx_effect &lt;- aldex.effect(x, CI = TRUE, verbose = FALSE)\n\n# combine all outputs \naldex_out &lt;- data.frame(x_tt, x_effect)\n\nNow, we can create a so called Bland-Altman or MA plot (left). It shows the association between the relative abundance and the magnitude of the difference per sample. Next to that, we can also create a plot that shows the dispersion on the x-axis instead of log-ratio abundance. Red dots represent genera that are differentially abundant (\\(q \\leq 0.1\\)) between the 2 groups. Black points are rare taxa and grey ones are abundant taxa. The dashed line represent an effect size of 1. Gloor, Macklaim, and Fernandes (2016) provides more information on these plots.\n\npar(mfrow = c(1, 2))\n\naldex.plot(aldex_out,\n           type = \"MA\",\n           test = \"welch\",\n           xlab = \"Log-ratio abundance\",\n           ylab = \"Difference\",\n           cutoff = 0.05)\n\naldex.plot(aldex_out,\n           type = \"MW\",\n           test = \"welch\",\n           xlab = \"Dispersion\",\n           ylab = \"Difference\",\n           cutoff = 0.05)\n\n\n\n\n\n\n\nThe evaluation as differential abundant in above plots is based on the corrected p-value. According to the ALDEx2 developers, the safest approach is to identify those features where the 95% CI of the effect size does not cross 0. As we can see in below table, this is not the case for any of the identified genera (see overlap column, which indicates the proportion of overlap). Also, the authors recommend to focus on effect sizes and CIs rather than interpreting the p-value. To keep the comparison simple, we will here use the p-value as decision criterion. But please be aware that the effect size together with the CI is a better answer to the question we are typically interested in.\n\naldex_out %&gt;%\n  rownames_to_column(var = \"Genus\") %&gt;%\n  # here we choose the wilcoxon output rather than t-test output\n  filter(wi.eBH &lt;= 0.05)  %&gt;%\n  dplyr::select(Genus, we.eBH, wi.eBH, effect, overlap) %&gt;%\n  knitr::kable()\n\n\n\nGenus\nwe.eBH\nwi.eBH\neffect\noverlap\n\n\n[Ruminococcus]_gauvreauii_group\n0.1087\n0.0355\n0.8184\n0.1142\n\n\n\n\n\n10.2.3 ANCOM-BC\nThe analysis of composition of microbiomes with bias correction (ANCOM-BC) (Lin and Peddada 2020) is a recently developed method for differential abundance testing. It is based on an earlier published approach (Mandal et al. 2015). The previous version of ANCOM was among the methods that produced the most consistent results and is probably a conservative approach (Nearing et al. 2022). However, the new ANCOM-BC method operates quite differently compared to the former ANCOM method.\n\nNearing, Jacob T., Gavin M. Douglas, Molly G. Hayes, Jocelyn MacDonald, Dhwani K. Desai, Nicole Allward, Casey M. A. Jones, et al. 2022. ‚ÄúMicrobiome Differential Abundance Methods Produce Different Results Across 38 Datasets.‚Äù Nature Communications 13 (1): 342. https://doi.org/10.1038/s41467-022-28034-z.\nAs the only method, ANCOM-BC incorporates the so called sampling fraction into the model. The latter term could be empirically estimated by the ratio of the library size to the microbial load. According to the authors, ignoring variations in this sampling fraction would bias DAA results. Furthermore, this method provides p-values and confidence intervals for each taxon. It also controls the FDR and it is computationally simple to implement.\nNote that the original method was implemented in the ancombc() function (see extended tutorial). The method has since then been updated and new features have been added to enable multi-group comparisons and repeated measurements among other improvements. We do not cover the more advanced features of ANCOMBC in this tutorial as these features are documented in detail in this tutorial.\nWe now proceed with a simple example. First, we specify a formula. In this formula, other covariates could potentially be included to adjust for confounding. We show this further below. Again, please make sure to check the function documentation as well as the linked tutorials to learn about the additional arguments that we specify.\n\n# Load package\nlibrary(ANCOMBC)\n\n# Run ANCOM-BC at the genus level and only including the prevalent genera\nancombc2_out &lt;- ancombc2(data = tse,\n                         assay.type = \"counts\",\n                         fix_formula = \"patient_status\",\n                         p_adj_method = \"fdr\",\n                         prv_cut = 0,\n                         group = \"patient_status\",\n                         struc_zero = TRUE,\n                         neg_lb = TRUE,\n                         # multi group comparison is deactivated automatically\n                         global = TRUE)\n\nThe object out contains all model output. Again, see the documentation of the function under Value for details. Our question whether taxa are differentially abundant can be answered by looking at the res object, which contains dataframes with the coefficients, standard errors, p-values and q-values. Below we show the first entries of this dataframe.\n\n# store the FDR adjusted results \nancombc2_out$res %&gt;%\n  dplyr::select(taxon, lfc_patient_statusControl, q_patient_statusControl) %&gt;%\n  filter(q_patient_statusControl &lt; 0.05) %&gt;%\n  arrange(q_patient_statusControl) %&gt;%\n  head() %&gt;%\n  knitr::kable()\n\n\n\n\n\n\n\n\ntaxon\nlfc_patient_statusControl\nq_patient_statusControl\n\n\n\nSubdoligranulum\n1.909\n0.0010\n\n\nRuminococcus_1\n2.915\n0.0010\n\n\n[Ruminococcus]_gauvreauii_group\n1.520\n0.0014\n\n\n[Eubacterium]_rectale_group\n1.361\n0.0050\n\n\n[Clostridium]_innocuum_group\n1.455\n0.0052\n\n\nDielma\n1.166\n0.0052\n\n\n\n\n\n\n10.2.4 MaAsLin2\nLet us next illustrate MaAsLin2 (Mallick, Rahnavard, and McIver 2020). This method is based on generalized linear models and flexible for different study designs and covariate structures. For details, check their Biobakery tutorial.\n\n# Load package\nlibrary(Maaslin2)\n\n# maaslin expects features as columns and samples as rows \n# for both the abundance table as well as metadata \n\n# We can specify different GLMs/normalizations/transforms.\n# specifying a ref is especially important if you have more than 2 levels\nmaaslin2_out &lt;- Maaslin2(input_data = as.data.frame(t(assay(tse))),\n                         input_metadata = as.data.frame(colData(tse)),\n                         output = \"DAA example\",\n                         transform = \"AST\",\n                         fixed_effects = \"patient_status\",\n                         # you can also fit MLM by specifying random effects\n                         # random_effects = c(...),\n                         reference = \"patient_status,Control\",\n                         normalization = \"TSS\",\n                         standardize = FALSE,\n                         # filtering was previously performed\n                         min_prevalence = 0)\n\nWhich genera are identified as differentially abundant? (leave out ‚Äúhead‚Äù to see all).\n\nmaaslin2_out$results %&gt;%\n  filter(qval &lt; 0.05) %&gt;%\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfeature\nmetadata\nvalue\ncoef\nstderr\npval\nname\nqval\nN\nN.not.zero\n\n\n\nX.Ruminococcus._gauvreauii_group\npatient_status\nADHD\n-0.0674\n0.0133\n0.0000\npatient_statusADHD\n0.0015\n27\n21\n\n\nFaecalibacterium\npatient_status\nADHD\n0.1223\n0.0372\n0.0030\npatient_statusADHD\n0.0448\n27\n11\n\n\nX.Clostridium._innocuum_group\npatient_status\nADHD\n-0.0692\n0.0213\n0.0033\npatient_statusADHD\n0.0448\n27\n25\n\n\nCatabacter\npatient_status\nADHD\n0.0295\n0.0092\n0.0037\npatient_statusADHD\n0.0448\n27\n9\n\n\n\n\n\nThis will create a folder that is called like in the output specified above. It contains also figures to visualize difference between significant taxa.\n\n10.2.5 LinDA\nLastly, we cover linear models for differential abundance analysis of microbiome compositional data (H. Zhou et al. (2022)). This is very similar to ANCOMBC with few differences: 1) LinDA corrects for the compositional bias differently using the mode of all regression coefficients. 2) it is faster (100x-1000x than ANCOMBC and according to the authors); 3) it supports hierarchical models. The latest ANCOMBC versions are also supporting hierarchical models. Nevertheless, LinDA seems a promising tool that achieves a very good power/fdr trade-off together with ANCOMBC according to the review. The speed improvements might make it critical especially for datasets that have higher sample or feature set sizes.\n\n# Load package\nlibrary(MicrobiomeStat)\n\n# Run LinDA\nlinda_out &lt;- linda(feature.dat = as.data.frame(assay(tse)),\n                   meta.dat = as.data.frame(colData(tse)),\n                   formula = \"~ patient_status\",\n                   alpha = 0.05,\n                   prev.filter = 0,\n                   mean.abund.filter = 0)\n##  0  features are filtered!\n##  The filtered data has  27  samples and  49  features will be tested!\n##  Pseudo-count approach is used.\n##  Fit linear models ...\n##  Completed.\n\n\n# List genera for which H0 could be rejected:\nlinda_out$output$patient_statusControl %&gt;%\n  filter(reject) %&gt;%\n  dplyr::select(stat, padj) %&gt;%\n  rownames_to_column(var = \"feature\") %&gt;%\n  knitr::kable()\n\n\n\nfeature\nstat\npadj\n\n\n\nFaecalibacterium\n-4.250\n0.0092\n\n\n[Ruminococcus]_gauvreauii_group\n4.110\n0.0092\n\n\nCatabacter\n-3.379\n0.0390\n\n\n\n\n\n\n10.2.6 ZicoSeq\nSubsequently, we demonstrate DAA with ZicoSeq, a method based on linear models and permutation. Further details can be found in this tutorial. This approach has been assessed to exhibit high power and a low false discovery rate, which has the following components:\n\nWinsorization to decrease the influence of outliers;\nPosterior sampling based on a beta mixture prior to address sampling variability and zero inflation;\nReference-based multiple-stage normalization to address compositional effects;\n\n\n# Load package\nlibrary(GUniFrac)\n\nset.seed(123)\nzicoseq_out &lt;- ZicoSeq(feature.dat = as.matrix(assay(tse)),\n                       meta.dat = as.data.frame(colData(tse)),\n                       grp.name = \"patient_status\",\n                       feature.dat.type = \"count\",\n                       return.feature.dat = TRUE,\n                       prev.filter = 0,\n                       mean.abund.filter = 0,\n                       max.abund.filter = 0,\n                       perm.no = 999)\n##  For sample size less than 40, posterior sampling will not be used!\n##  0  features are filtered!\n##  The data has  27  samples and  49  features will be tested!\n##  On average,  1  outlier counts will be replaced for each feature!\n##  Finding the references ...\n##  Permutation testing ...\n##  ...................................................................................................\n##  ...................................................................................................\n##  ...................................................................................................\n##  ...................................................................................................\n##  ...................................................................................................\n##  ...................................................................................................\n##  Completed!\n\n\nzicoseq_res &lt;- cbind.data.frame(p.raw = zicoseq_out$p.raw,\n                                p.adj.fdr = zicoseq_out$p.adj.fdr)\n\nzicoseq_res %&gt;%\n  filter(p.adj.fdr &lt; 0.05) %&gt;%\n  arrange(p.adj.fdr) %&gt;%\n  knitr::kable()\n\n\n\n\np.raw\np.adj.fdr\n\n\n\n[Ruminococcus]_gauvreauii_group\n0.001\n0.005\n\n\nFaecalibacterium\n0.001\n0.024\n\n\n[Clostridium]_innocuum_group\n0.003\n0.024\n\n\nCatabacter\n0.006\n0.043\n\n\n\n\n\n\n## x-axis is the effect size: R2 * direction of coefficient\nZicoSeq.plot(ZicoSeq.obj = zicoseq_out,\n             pvalue.type = 'p.adj.fdr')\n\n\n\n\n\n\n\n\n10.2.7 PhILR\nPhILR is a tree-based method that tests group-wise associations based on balances. A detailed introduction to this method is available in this Bioconductor tutorial.\n\n10.2.8 Comparison of methods\nAlthough the methods described above yield unidentical results, they are expected to agree on a few differentially abundant taxa. To draw more informed conclusions, it is good practice to compare the outcomes of different methods in terms of found features, their effect sizes and significances, as well as other method-specific aspects. Such comparative approach is outlined in this exercise."
  },
  {
    "objectID": "pages/30_differential_abundance.html#daa-with-confounding",
    "href": "pages/30_differential_abundance.html#daa-with-confounding",
    "title": "10¬† Differential Abundance",
    "section": "\n10.3 DAA with confounding",
    "text": "10.3 DAA with confounding\nConfounders can be defined as variables that are related to and affect the apparent dynamics between the response and the main independent variable. They are common in experimental studies. Generally, they can be classified into 3 groups:\n\nBiological confounders, such as age and sex\nTechnical confounders produced during sample collection, processing and analysis\nConfounders resulting from experimental models, such as batch effects and sample history\n\nControlling for confounders is an important practice to reach an unbiased conclusion. To perform causal inference, it is crucial that the method is able to include confounders in the model. This is not possible with statistical tests of general use, such as the Wilcoxon test. In contrast, methods that target DAA, such as those described in this chapter, allow controlling for confounders. In the following examples, we will perform DAA with a main independent variable and a few confounders.\n\n10.3.1 Selecting confounders\nIn addition to patient status, we will now control for two confounders: cohort and library size. The former is a categorical variable with three factors, whereas the latter is a discrete numerical variable. Remarkably, most DAA methods accept these two and several other data types.\nFor demonstration, library size is treated as a confounder and included in the formulas of the DAA methods. Although this is a satisfactory approach to control for uneven sequencing efforts across samples, rarefaction generally represents a better solution (Schloss 2023). With that said, library size can be readily computed and added to the colData.\n\nSchloss, Patrick D. 2023. ‚ÄúRarefaction Is Currently the Best Approach to Control for Uneven Sequencing Effort in Amplicon Sequence Analyses.‚Äù bioRxiv, 2023‚Äì06. https://doi.org/10.1101/2023.06.23.546313.\n\n# Compute and store library size in colData\ncolData(tse)$library_size &lt;- colSums(assay(tse, \"counts\"))\n\n\n10.3.2 ANCOM-BC\nHere, confounders can be added to the formula along with patient status, the main outcome variable. This way, the model evaluates whether differentially abundant taxa are associated with one of the variables when the other two are kept constant.\n\n# perform the analysis \nancombc2_out &lt;- ancombc2(tse,\n                         assay.type = \"counts\",\n                         fix_formula = \"patient_status + cohort + library_size\",\n                         p_adj_method = \"fdr\",\n                         lib_cut = 0,\n                         group = \"patient_status\", \n                         struc_zero = TRUE, \n                         neg_lb = TRUE,\n                         alpha = 0.05,\n                         # multi-group comparison is deactivated automatically\n                         global = TRUE)\n\nIn the output, each taxon is assigned with several effect sizes (lfc, which stands for log-fold change) and adjusted p-values (q). For categorical variables such as patient status and cohort, the statistics indicate whether the abundance of a given taxon is significantly different between the specified group (column name) and the reference group (the group that does not appear in the column names), whereas for numerical variables such as library size, they indicate whether the abundance of a given taxon varies with that variable.\n\nancombc2_out$res %&gt;%\n  dplyr::select(starts_with(c(\"taxon\", \"lfc\", \"q\"))) %&gt;%\n  arrange(q_patient_statusControl) %&gt;%\n  head() %&gt;%\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntaxon\nlfc_(Intercept)\nlfc_patient_statusControl\nlfc_cohortCohort_2\nlfc_cohortCohort_3\nlfc_library_size\nq_(Intercept)\nq_patient_statusControl\nq_cohortCohort_2\nq_cohortCohort_3\nq_library_size\n\n\n\nAkkermansia\n-0.8599\n0.2309\n0.2876\n0.4635\n0\n0\n0\n0\n0\n0.9147\n\n\nHungatella\n-0.0695\n-0.3270\n-0.1397\n-0.1151\n0\n0\n0\n0\n0\n0.0593\n\n\nRuminococcaceae_UCG-013\n-0.9344\n-0.3371\n0.6599\n-0.0231\n0\n0\n0\n0\n0\n0.0050\n\n\nBacteroides\n-0.3081\n-0.7575\n0.1482\n0.7615\n0\n0\n0\n0\n0\n0.9650\n\n\nEscherichia-Shigella\n-1.1600\n-0.5157\n1.3093\n0.2340\n0\n0\n0\n0\n0\n0.0397\n\n\n[Clostridium]_innocuum_group\n-0.7590\n0.7781\n-0.1629\n0.1688\n0\n0\n0\n0\n0\n0.0593\n\n\n\n\n\n\n10.3.3 LinDA\nAs in the previous method, confounders can be included in the formula with the main outcome variable.\n\nlinda_out &lt;- linda(as.data.frame(assay(tse, \"counts\")),\n                   as.data.frame(colData(tse)),\n                   formula = \"~ patient_status + cohort + library_size\",\n                   alpha = 0.05,\n                   prev.filter = 0,\n                   mean.abund.filter = 0)\n##  0  features are filtered!\n##  The filtered data has  27  samples and  49  features will be tested!\n##  Imputation approach is used.\n##  Fit linear models ...\n##  Completed.\n\nThe model returns an output for every variable included in the formula. Normally, only the results on the main outcome variable are relevant and can be retrieved as shown below. However, the statistics on the confounders can be similarly obtained by accessing the corresponding items from the output object.\n\n# Select results for the patient status\nlinda_res &lt;- linda_out$output$patient_statusControl\n\nlinda_res %&gt;%\n  filter(reject) %&gt;%\n  dplyr::select(log2FoldChange, stat, padj) %&gt;%\n  rownames_to_column(var = \"feature\") %&gt;%\n  head() %&gt;%\n  knitr::kable()\n\n\n\nfeature\nlog2FoldChange\nstat\npadj\n\n\n\nFaecalibacterium\n-5.921\n-4.521\n0.0041\n\n\nErysipelatoclostridium\n3.743\n3.010\n0.0451\n\n\n[Ruminococcus]_gauvreauii_group\n4.240\n4.534\n0.0041\n\n\nBarnesiella\n-3.878\n-3.116\n0.0411\n\n\nRuminococcaceae_UCG-014\n-3.062\n-3.637\n0.0193\n\n\nButyricicoccus\n-2.357\n-3.127\n0.0411\n\n\n\n\n\nThe output shows effect sizes in terms of log-fold changes and a derived statistic (stat) as well as the corresponding adjusted p-values for differences in abundance of each taxon between the control and treated group.\n\n10.3.4 ZicoSeq\nFor this method, confounders can be added as a list to the adj.name argument.\n\nset.seed(123)\nzicoseq_out &lt;- ZicoSeq(feature.dat = as.matrix(assay(tse)),\n                       meta.dat = as.data.frame(colData(tse)),\n                       grp.name = \"patient_status\",\n                       adj.name = c(\"cohort\", \"library_size\"), \n                       feature.dat.type = \"count\",\n                       return.feature.dat = TRUE,\n                       prev.filter = 0,\n                       mean.abund.filter = 0,\n                       max.abund.filter = 0,\n                       perm.no = 999)\n##  For sample size less than 40, posterior sampling will not be used!\n##  0  features are filtered!\n##  The data has  27  samples and  49  features will be tested!\n##  On average,  1  outlier counts will be replaced for each feature!\n##  Finding the references ...\n##  Permutation testing ...\n##  ...................................................................................................\n##  ...................................................................................................\n##  ...................................................................................................\n##  ...................................................................................................\n##  ...................................................................................................\n##  ...................................................................................................\n##  Completed!\n\nThe output shows the raw and adjusted p-values for clinical status.\n\nzicoseq_res &lt;- cbind.data.frame(p.raw = zicoseq_out$p.raw,\n                                p.adj.fdr = zicoseq_out$p.adj.fdr)\n\nzicoseq_res %&gt;%\n  filter(p.adj.fdr &lt; 0.05) %&gt;%\n  head() %&gt;%\n  knitr::kable()\n\n\n\n\np.raw\np.adj.fdr\n\n\n\nFaecalibacterium\n0.002\n0.0224\n\n\n[Clostridium]_innocuum_group\n0.003\n0.0238\n\n\n[Ruminococcus]_gauvreauii_group\n0.001\n0.0005\n\n\nRuminococcus_2\n0.002\n0.0300\n\n\nRuminococcaceae_UCG-014\n0.004\n0.0369\n\n\nCatabacter\n0.003\n0.0224"
  },
  {
    "objectID": "pages/30_differential_abundance.html#additional-resources",
    "href": "pages/30_differential_abundance.html#additional-resources",
    "title": "10¬† Differential Abundance",
    "section": "\n10.4 Additional resources",
    "text": "10.4 Additional resources\nDAA can be performed by several means. Although most of them provide similar functionality, some may be more suitable than others given a certain study design or data type. Commonly used DAA tools include:\n\nALDEx2 (Gloor, Macklaim, and Fernandes 2016)\n\nANCOM (Mandal et al. 2015)\n\nANCOMBC (Lin and Peddada 2020)\n\ncorncob (Martin, Witten, and Willis 2021)\n\nDACOMP (Brill, Amnon, and Ruth 2022)\n\nDESeq2 (Love, Huber, and Anders 2014)\n\neBay (Liu, Zhao, and Wang 2020)\n\nedgeR (Y. Chen, Lun, and Smyth 2016)\n\nfastANCOM (C. Zhou et al. 2022)\n\nLDM (Hu and Satten 2020)\n\nlefser (Khleborodova 2021)\n\nlimma (Ritchie et al. 2015)\n\nLinDA (H. Zhou et al. 2022)\n\nMaAsLin2 (Mallick, Rahnavard, and McIver 2020)\n\nmetagenomeSeq (Paulson, Talukder, and Bravo 2017)\n\nOmnibus (J. Chen et al. 2018)\n\nRAIDA (Sohn, Du, and An 2015)\n\nt-test\nWilcoxon test\nZicoSeq (Yang and Chen 2022)\n\nZINQ (Ling et al. 2021)\n\n\n\n\n\nGloor, Gregory B., Jean M. Macklaim, and Andrew D. Fernandes. 2016. ‚ÄúDisplaying Variation in Large Datasets: Plotting a Visual Summary of Effect Sizes.‚Äù Journal of Computational and Graphical Statistics 25 (3): 971‚Äì79. https://doi.org/10.1080/10618600.2015.1131161.\n\nMandal, Siddhartha, Will Van Treuren, Richard A. White, Merete Eggesb√∏, Rob Knight, and Shyamal D. Peddada. 2015. ‚ÄúAnalysis of Composition of Microbiomes: A Novel Method for Studying Microbial Composition.‚Äù Microbial Ecology in Health & Disease 26 (0). https://doi.org/10.3402/mehd.v26.27663.\n\nLin, Huang, and Shyamal Das Peddada. 2020. ‚ÄúAnalysis of Compositions of Microbiomes with Bias Correction.‚Äù Nature Communications 11 (1): 1‚Äì11. https://doi.org/https://doi.org/10.1038/s41467-020-17041-7.\n\nMartin, Bryan D, Daniela Witten, and Amy D Willis. 2021. Corncob: Count Regression for Correlated Observations with the Beta-Binomial. https://CRAN.R-project.org/package=corncob.\n\nBrill, Barak, Amir Amnon, and Heller Ruth. 2022. ‚ÄúTesting for Differential Abundance in Compositional Counts Data, with Application to Microbiome Studies.‚Äù The Annals of Applied Statistics 16 (December).\n\nLove, Michael I., Wolfgang Huber, and Simon Anders. 2014. ‚ÄúModerated Estimation of Fold Change and Dispersion for RNA-Seq Data with DESeq2.‚Äù Genome Biology 15: 550. https://doi.org/10.1186/s13059-014-0550-8.\n\nLiu, Tiantian, Hongyu Zhao, and Tao Wang. 2020. ‚ÄúAn Empirical Bayes Approach to Normalization and Differential Abundance Testing for Microbiome Data.‚Äù BMC Bioinformatics 21 (June). https://doi.org/10.1186/s12859-020-03552-z.\n\nChen, Yunshun, Aaron TL Lun, and Gordon K Smyth. 2016. ‚ÄúFrom Reads to Genes to Pathways: Differential Expression Analysis of RNA-Seq Experiments Using Rsubread and the edgeR Quasi-Likelihood Pipeline.‚Äù F1000Research 5: 1438. https://doi.org/10.12688/f1000research.8987.2.\n\nZhou, Chao, Huimin Wang, Hongyu Zhao, and Tao Wang. 2022. ‚ÄúfastANCOM: A Fast Method for Analysis of Compositions of Microbiomes.‚Äù Bioinformatics 38 (March): 2039‚Äì41.\n\nHu, Yijuan, and Glen A Satten. 2020. ‚ÄúTesting Hypotheses about the Microbiome Using the Linear Decomposition Model (LDM).‚Äù Bioinformatics 36 (July): 4106--4115.\n\nKhleborodova, Asya. 2021. Lefser: R Implementation of the LEfSE Method for Microbiome Biomarker Discovery. https://github.com/waldronlab/lefser.\n\nRitchie, Matthew E, Belinda Phipson, Di Wu, Yifang Hu, Charity W Law, Wei Shi, and Gordon K Smyth. 2015. ‚Äúlimma Powers Differential Expression Analyses for RNA-Sequencing and Microarray Studies.‚Äù Nucleic Acids Research 43 (7): e47. https://doi.org/10.1093/nar/gkv007.\n\nZhou, Huijuan, Kejun He, Jun Chen, and Xianyang Zhang. 2022. ‚ÄúLinDA: Linear Models for Differential Abundance Analysis of Microbiome Compositional Data.‚Äù Genome Biology 23 (1): 95. https://doi.org/10.1186/s13059-022-02655-5.\n\nMallick, Himel, Ali Rahnavard, and Lauren J. McIver. 2020. MaAsLin 2: Multivariable Association in Population-Scale Meta-Omics Studies. http://huttenhower.sph.harvard.edu/maaslin2.\n\nPaulson, JN, H Talukder, and HC Bravo. 2017. ‚ÄúLongitudinal Differential Abundance Analysis of Marker-Gene Surveys Using Smoothing Splines.‚Äù Biorxiv. https://doi.org/10.1101/099457.\n\nChen, Jun, Emily King, Rebecca Deek, Zhi Wei, Yue Yu, Diane Grill, and Karla Ballman. 2018. ‚ÄúAn Omnibus Test for Differential Distribution Analysis of Microbiome Sequencing Data.‚Äù Bioinformatics 34 (February).\n\nSohn, Michael B., Ruofei Du, and Lingling An. 2015. ‚ÄúA Robust Approach for Identifying Differentially Abundant Features in Metagenomic Samples.‚Äù Bioinformatics 31 (July). https://doi.org/10.1093/bioinformatics/btv165.\n\nYang, Lu, and Jun Chen. 2022. ‚ÄúA Comprehensive Evaluation of Microbial Differential Abundance Analysis Methods: Current Status and Potential Solutions.‚Äù Microbiome 10 (130): 2049‚Äì2618. https://doi.org/10.1186/s40168-022-01320-0.\n\nLing, Wodan, Zhao Ni, M. Plantinga Anna, J. Launer Lenore, A. Fodor Anthony, A. Meyer Katie, and C. Wu Michael. 2021. ‚ÄúPowerful and Robust Non-Parametric Association Testing for Microbiome Data via a Zero-Inflated Quantile Approach (ZINQ).‚Äù Microbiome 181 (September). https://doi.org/10.1186/s40168-021-01129-3."
  },
  {
    "objectID": "pages/60_network_learning.html#network-learning",
    "href": "pages/60_network_learning.html#network-learning",
    "title": "11¬† Network learning and analysis",
    "section": "\n11.1 Network learning",
    "text": "11.1 Network learning\n\n11.1.1 Typical workflow\nFigure Figure¬†11.1 shows the workflow for learning/constructing a microbial association network as proposed by Peschel et al. (2021). The respective steps are explained below.\n\n\n\n\nFigure¬†11.1: The typical input is a \\(p\\) x \\(n\\) dimensional count matrix coming from a sequencing process, where \\(n\\) is the number of samples and \\(p\\) the number of features / ASVs / OTUs. Steps 1 through 6 are explained below. Each matrix resulting from steps 4, 5, and 6 plays a specific role in the final network: The adjacency matrix is used for edge colors, dissimilarity for layout, and similarity for edge weights. In weighted networks, the similarity matrix equals the adjacency matrix.\n\n\n\n\nZero replacement: Since the following steps usually require non-zero entries in the read count matrix, zero counts must be replaced. A simple solution is to add a pseudo count to the data. Other possible approaches are implemented in the R package zCompositions\nNormalization: To avoid compositional effects, the data are normalized using a compositionality aware transformation. A common approach is the centered log-ratio (clr) transformation, which moves the data from a \\(p\\)-dimensional simplex to Euclidean space so that standard statistical analysis methods are valid. A variance stabilizing transformation (vst) is also a suitable approach for normalizing microbial count data (Badri et al. 2020).\n\nAssociation estimation: This is the crucial step in network learning to obtain statistical relations between the taxa. Common association measures include correlation, conditional dependence (which we will equate to partial correlation), and proportionality. Further information on these three types of association and their application can be found in Section Section¬†11.6. The following list gives a selection of compositionality aware approaches:\n\n\nCompositionality aware correlation estimation methods:\n\nPearson‚Äôs correlation coefficient (+ normalization)\nSpearman‚Äôs rank correlation coefficient (+ normalization)\nCovariance shrinkage (corpcor package) (+ normalization)\nSparCC (implemented in SpiecEasi); applied in Section @ref(sparcc-correlation)\nCCREPE (ccrepe package)\nCCLasso (R code on GitHub)\n\n\n\nCompositionality aware measures of conditional dependence / partial correlation:\n\n\nSpiecEasi with Meinshausen and B√ºhlmann (MB) neighborhood selection; applied in Section @ref(spieceasi-mb)\n\nSpiecEasi with the graphical lasso (glasso)\ngCoda (R code on GitHub)\n\nSPRING; applied in Section @ref(netcomi-spring)\n\n\n\nProportionality measures (proportionality aware by definition):\n\npropr\n\nShrinkage proportionality estimator; applied in Section @ref(shrinkage-prop)\n\n\n\n\nSparsification: Transforming the estimated associations directly into adjacencies would lead to a dense network where all nodes are connected and only weighted network measures are meaningful. Therefore, the association matrix is usually sparsified to select edges of interest. A common sparsification approach for correlations is thresholding, where correlations with a magnitude below the threshold are set to zero. Another possibility is a statistical test (Student‚Äôs t-test or permutation test) with the null hypothesis that the correlation is equal to zero. SpiecEasi uses the StARS stability selection approach (Liu, Roeder, and Wasserman 2010) to decide on an appropriate sparsification level of the inferred conditional dependence graph.\n\nTransformation into dissimilarity: A common next step is to simply use the absolute values of the sparsified associations as edge weights. In this way, correlations of high magnitude (both positive and negative) will have a high edge weight. From a biological point of view, it would also make sense to assign a low edge weight to taxa that are strongly negatively associated, which would correspond to a high dissimilarity value. Here we follow Dongen and Enright (2012) to directly transform the sparse associations \\(r_{ij}^*\\) into dissimilarities, which can later be used for shortest path network measures. Depending on the desired handling of negative associations, one of the two proposed transformations should be chosen:\n5a: ‚Äúsigned‚Äù: \\(d_{ij} = \\sqrt{0.5(1-r^*_{ij})}\\), where strongly negatively associated taxa have the largest distance and are placed further apart in the network.\n5b: ‚Äúunsigned‚Äù: \\(d_{ij} = \\sqrt{1-{r_{ij}^*}^2}\\), resulting in a small distance between strongly associated taxa (regardless of the sign).\n\nTransformation into similarity / edge weight: Finally, the dissimilarities are transformed into similarities by \\(s_{ij} = 1 - d_{ij}\\), which are used as edge weights. Thus, the similarity matrix is equal to the adjacency matrix in a weighted network.\n\nThe main association measure used in this chapter is the SPRING (‚ÄúSemi-Parametric Rank-based approach for INference in Graphical model‚Äù) method proposed by Yoon, Gaynanova, and M√ºller (2019). SPRING learns conditional dependency graphs for compositional data and follows the neighborhood selection method introduced by Meinshausen and B√ºhlmann (2006) (‚ÄúMB‚Äù). We will show how to apply the method directly, as well as how to use it in conjunction with the R package NetCoMi, which is specifically designed for the construction and analysis of networks for microbiome data.\nSee Section Section¬†11.6 for a comparison of all three association types (correlation, partial correlation, and proportionality) with more information on each measure and applications.\nWe demonstrate the workflow using the the PeerJ data set (Potbhare et al. 2022). It contains skin microbial profiles of 58 subjects.\n\nPotbhare, Renuka, Ameeta RaviKumar, Eveliina Munukka, Leo Lahti, and Richa Ashma. 2022. ‚ÄúSkin Microbiota Diversity Among Genetically Unrelated Individuals of Indian Origin.‚Äù PeerJ 10: e13075. https://doi.org/10.7717/peerj.13075.\n\nlibrary(mia)\n\n\ndata(\"peerj13075\", package = \"mia\")\ntse0 &lt;- peerj13075\ndim(tse0)\n##  [1] 674  58\n\n\n11.1.2 Install packages\nThree packages used in this chapter are available on GitHub only: SpiecEasi, SPRING, and NetCoMi. We recommend that you install these packages before proceeding.\n\nif(!require(SpiecEasi)){\n  devtools::install_github(\"zdk123/SpiecEasi\")\n}\n##  VGAM   (NA -&gt; 1.1-9 ) [CRAN]\n##  pulsar (NA -&gt; 0.3.11) [CRAN]\n##  huge   (NA -&gt; 1.3.5 ) [CRAN]\n##  ‚îÄ‚îÄ R CMD build ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n##  * checking for file ‚Äò/tmp/RtmpoiwOlL/remotes407526cb96c/zdk123-SpiecEasi-5f396da/DESCRIPTION‚Äô ... OK\n##  * preparing ‚ÄòSpiecEasi‚Äô:\n##  * checking DESCRIPTION meta-information ... OK\n##  * cleaning src\n##  * checking for LF line-endings in source and make files and shell scripts\n##  * checking for empty or unneeded directories\n##  Removed empty directory ‚ÄòSpiecEasi/inst‚Äô\n##  * looking to see if a ‚Äòdata/datalist‚Äô file should be added\n##  * building ‚ÄòSpiecEasi_1.1.3.tar.gz‚Äô\n\nif(!require(SPRING)){\n  devtools::install_github(\"GraceYoon/SPRING\")\n}\n##  mixedCCA     (NA -&gt; 4c2b63f75...) [GitHub]\n##  egg          (NA -&gt; 0.4.5       ) [CRAN]\n##  assertthat   (NA -&gt; 0.2.1       ) [CRAN]\n##  linprog      (NA -&gt; 0.9-4       ) [CRAN]\n##  lpSolve      (NA -&gt; 5.6.20      ) [CRAN]\n##  magic        (NA -&gt; 1.6-1       ) [CRAN]\n##  sn           (NA -&gt; 2.1.1       ) [CRAN]\n##  cubature     (NA -&gt; 2.1.0       ) [CRAN]\n##  microbenc... (NA -&gt; 1.4.10      ) [CRAN]\n##  doFuture     (NA -&gt; 1.0.0       ) [CRAN]\n##  geometry     (NA -&gt; 0.4.7       ) [CRAN]\n##  heatmaply    (NA -&gt; 1.5.0       ) [CRAN]\n##  mnormt       (NA -&gt; 2.1.1       ) [CRAN]\n##  fMultivar    (NA -&gt; 4031.84     ) [CRAN]\n##  latentcor    (NA -&gt; 2.0.1       ) [CRAN]\n##  linprog      (NA -&gt; 0.9-4  ) [CRAN]\n##  lpSolve      (NA -&gt; 5.6.20 ) [CRAN]\n##  magic        (NA -&gt; 1.6-1  ) [CRAN]\n##  egg          (NA -&gt; 0.4.5  ) [CRAN]\n##  assertthat   (NA -&gt; 0.2.1  ) [CRAN]\n##  mnormt       (NA -&gt; 2.1.1  ) [CRAN]\n##  sn           (NA -&gt; 2.1.1  ) [CRAN]\n##  cubature     (NA -&gt; 2.1.0  ) [CRAN]\n##  microbenc... (NA -&gt; 1.4.10 ) [CRAN]\n##  doFuture     (NA -&gt; 1.0.0  ) [CRAN]\n##  geometry     (NA -&gt; 0.4.7  ) [CRAN]\n##  heatmaply    (NA -&gt; 1.5.0  ) [CRAN]\n##  fMultivar    (NA -&gt; 4031.84) [CRAN]\n##  latentcor    (NA -&gt; 2.0.1  ) [CRAN]\n##  ‚îÄ‚îÄ R CMD build ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n##  * checking for file ‚Äò/tmp/RtmpoiwOlL/remotes40715149e1d/irinagain-mixedCCA-4c2b63f/DESCRIPTION‚Äô ... OK\n##  * preparing ‚ÄòmixedCCA‚Äô:\n##  * checking DESCRIPTION meta-information ... OK\n##  * cleaning src\n##  * checking for LF line-endings in source and make files and shell scripts\n##  * checking for empty or unneeded directories\n##  Omitted ‚ÄòLazyData‚Äô from DESCRIPTION\n##  * building ‚ÄòmixedCCA_1.6.2.tar.gz‚Äô\n##  \n##  ‚îÄ‚îÄ R CMD build ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n##  * checking for file ‚Äò/tmp/RtmpoiwOlL/remotes40770fc192a/GraceYoon-SPRING-3d641a4/DESCRIPTION‚Äô ... OK\n##  * preparing ‚ÄòSPRING‚Äô:\n##  * checking DESCRIPTION meta-information ... OK\n##  * checking for LF line-endings in source and make files and shell scripts\n##  * checking for empty or unneeded directories\n##  * building ‚ÄòSPRING_1.0.4.tar.gz‚Äô\n\nif(!require(NetCoMi)){\n  devtools::install_github(\"stefpeschel/NetCoMi\", force = TRUE, ref = \"TSE\",\n                           dependencies = c(\"Depends\", \"Imports\", \"LinkingTo\"),\n                           repos = c(\"https://cloud.r-project.org/\",\n                                     BiocManager::repositories()))\n}\n##  Biobase      (2.63.0 -&gt; 8201fbbe5...) [Bioc]\n##  phyloseq     (1.47.0 -&gt; 73201334b...) [Bioc]\n##  pbivnorm     (NA     -&gt; 0.6.0       ) [CRAN]\n##  GO.db        (NA     -&gt; 3.18.0      ) [CRAN]\n##  impute       (NA     -&gt; 1.77.0      ) [CRAN]\n##  fastcluster  (NA     -&gt; 1.2.3       ) [CRAN]\n##  dynamicTr... (NA     -&gt; 1.63-1      ) [CRAN]\n##  fdrtool      (NA     -&gt; 1.2.17      ) [CRAN]\n##  glasso       (NA     -&gt; 1.11        ) [CRAN]\n##  lavaan       (NA     -&gt; 0.6-16      ) [CRAN]\n##  psych        (NA     -&gt; 2.3.9       ) [CRAN]\n##  WGCNA        (NA     -&gt; 1.72-5      ) [CRAN]\n##  qgraph       (NA     -&gt; 1.9.8       ) [CRAN]\n##  orca         (NA     -&gt; 1.1-1       ) [CRAN]\n##  filematrix   (NA     -&gt; 1.3         ) [CRAN]\n##  doSNOW       (NA     -&gt; 1.0.20      ) [CRAN]\n##  \n##  ‚îÄ‚îÄ R CMD build ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n##  * checking for file ‚Äò/tmp/RtmpoiwOlL/file4076e859743/DESCRIPTION‚Äô ... OK\n##  * preparing ‚ÄòBiobase‚Äô:\n##  * checking DESCRIPTION meta-information ... OK\n##  * cleaning src\n##  * checking for LF line-endings in source and make files and shell scripts\n##  * checking for empty or unneeded directories\n##  * looking to see if a ‚Äòdata/datalist‚Äô file should be added\n##  * building ‚ÄòBiobase_2.62.0.tar.gz‚Äô\n##  \n##  \n##  ‚îÄ‚îÄ R CMD build ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n##  * checking for file ‚Äò/tmp/RtmpoiwOlL/file4075b32adff/DESCRIPTION‚Äô ... OK\n##  * preparing ‚Äòphyloseq‚Äô:\n##  * checking DESCRIPTION meta-information ... OK\n##  * checking for LF line-endings in source and make files and shell scripts\n##  * checking for empty or unneeded directories\n##  * looking to see if a ‚Äòdata/datalist‚Äô file should be added\n##  * building ‚Äòphyloseq_1.46.0.tar.gz‚Äô\n##  \n##  ‚îÄ‚îÄ R CMD build ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n##  * checking for file ‚Äò/tmp/RtmpoiwOlL/remotes40737603dd7/stefpeschel-NetCoMi-03abaf1/DESCRIPTION‚Äô ... OK\n##  * preparing ‚ÄòNetCoMi‚Äô:\n##  * checking DESCRIPTION meta-information ... OK\n##  * installing the package to process help pages\n##  Loading required namespace: NetCoMi\n##  \n##  * saving partial Rd database\n##  * checking for LF line-endings in source and make files and shell scripts\n##  * checking for empty or unneeded directories\n##  * building ‚ÄòNetCoMi_1.1.0.9000.tar.gz‚Äô\n\n\n11.1.3 Data preparation\nBefore applying the network learning methods, we perform some data preparation steps:\n\nAggregation to genus level\nAdd relative abundance assay\nPrevalence filtering (keep genera with prevalence &gt; 20%)\nAdd assay with log10 transformed abundances\nAdd assay with clr transformed abundances\n\n\n# Agglomerate to genus level\ntse &lt;- agglomerateByRank(tse0, rank = \"genus\") \n\n# Add relative abundances\ntse &lt;- transformAssay(tse, \n                      assay.type = \"counts\", \n                      method = \"relabundance\",\n                      MARGIN = \"samples\") \n\n# Filter by prevalence\ntse &lt;- subsetByPrevalentFeatures(tse,\n                                 prevalence = 0.2,\n                                 detection = 0,\n                                 assay.type = \"relabundance\")\n\n# Add log10-transformed abundances\ntse &lt;- transformAssay(tse, method = \"log10\", pseudocount = 1)\n\n# Add clr-transformed abundances\ntse &lt;- transformAssay(tse, method = \"clr\", pseudocount = 1)\n\ndim(tse)\n##  [1] 147  58\n\n\n11.1.4 SPRING network\nAs explained in Section Section¬†11.1.1, we use SPRING (‚ÄúSemi-Parametric Rank-based approach for INference in Graphical model‚Äù) as association measure. We first use the SPRING function directly to construct a conditional dependency graph.\nNeither zero replacement nor normalization (steps 1 and 2 in our workflow) are required because SPRING uses a modified clr (mclr) transformation that can handle zero counts, and the correlation estimation method itself can also deal with zeros in the data. mclr is similar to the clr transformation except that mclr considers only the non-zero values. More precisely, the geometric mean is derived from positive values only, and zero counts remain zero after the transformation. This approach is similar to the ‚Äúrobust clr‚Äù (rclr) transformation included in the vegan package, except that mclr applies a positive shift to all non-zero values to make them strictly positive. See (Yoon, Gaynanova, and M√ºller 2019) for details.\n\nYoon, Grace, Christian L M√ºller, and Irina Gaynanova. 2021. ‚ÄúFast Computation of Latent Correlations.‚Äù Journal of Computational and Graphical Statistics 30 (4): 1249‚Äì56.\nThe Rmethod argument is set to ‚Äúapprox‚Äù to estimate the correlations using a hybrid multi-linear interpolation approach proposed by Yoon, M√ºller, and Gaynanova (2021). This method considerably reduces the runtime while controlling the approximation error.\nSPRING uses the StARS (‚ÄúStability Approach to Regularization Selection‚Äù) method (Liu, Roeder, and Wasserman 2010) to obtain a sparse association matrix. Thus, also step 4 of our workflow is already included. We set the StARS threshold to 0.05 to get a sparser graph.\n\nlibrary(SPRING)\n\n\nset.seed(13075)\nspring_est &lt;- SPRING(t(assay(tse, \"counts\")), \n                     Rmethod = \"approx\", \n                     thresh = 0.05,\n                     lambdaseq = \"data-specific\")\n\n\n# Get index of the optimal lambda selected by StARS\nopt.K &lt;- spring_est$output$stars$opt.index\n\n# Store partial correlation matrix belonging to the optimal lambda as matrix\nspring_cor &lt;- SpiecEasi::symBeta(as.matrix(spring_est$output$est$beta[[opt.K]]))\nspring_cor &lt;- as.matrix(spring_cor)\nrownames(spring_cor) &lt;- colnames(spring_cor) &lt;- rownames(tse)\ndiag(spring_cor) &lt;- 1\n\nAs explained in Section Section¬†11.1.1, the estimated associations are sparsified, transformed into dissimilarities, and finally transformed into similarities, which are the adjacency values. We write a function for these steps, which will be reused later.\nSince SPRING already includes a sparsification approach, the thresh argument is not needed here, but will be needed in Section Section¬†11.6 for other association measures.\nTo be consistent with the workflow, we provide two dissimilarity transformations: ‚Äúsigned‚Äù and ‚Äúunsigned‚Äù (see Section Section¬†11.1.1 for an explanation). These transformations were introduced by Dongen and Enright (2012). We use the ‚Äúsigned‚Äù transformation in our examples so that strongly negatively associated genera have low edge weights.\n\nDongen, Stijn van, and Anton J. Enright. 2012. ‚ÄúMetric distances derived from cosine similarity and Pearson and Spearman correlations.‚Äù arXiv Preprint 2: 2‚Äì6. http://arxiv.org/abs/1208.3145.\nThe output of the function is an igraph object, which can be plotted and analyzed using functions from the igraph package.\n\n# Arguments:\n# - assoMat: association matrix\n# - threshold: associations below the threshold are set to zero\n# - dissTrans: dissimilarity transformation (\"signed\" or \"unsigned\")\n\ntransform_asso &lt;- function(assoMat, thresh = NULL, dissTrans = \"signed\") {\n  # Sparsification\n  if (!is.null(thresh)) {\n    assoMat[abs(assoMat) &lt; thresh] &lt;- 0\n  }\n  \n  # Compute dissimilarity matrix\n  if (dissTrans == \"signed\") {\n    dissMat &lt;- sqrt(0.5 * (1 - assoMat))\n  } else {\n    dissMat &lt;- sqrt(1 - assoMat^2)\n  }\n  \n  # Dissimilarity between nodes with zero correlation is set to 1\n  # (these nodes are unconnected and thus should have maximum dissimilarity)\n  dissMat[assoMat == 0] &lt;- 1\n  \n  # Compute similarity matrix\n  simMat &lt;- 1 - dissMat\n  \n  # Turn into igraph object\n  graphObj &lt;- SpiecEasi::adj2igraph(simMat)\n  \n  return(list(graph = graphObj, adja = simMat, asso = assoMat, diss = dissMat))\n}\n\n\n# Create graph object\nspring_graph &lt;- transform_asso(spring_cor)$graph\n\n\n11.1.5 NetCoMi network\nThe NetCoMi (Peschel et al. 2021) package is specifically designed to construct, analyze, and compare networks for microbiome data and implements the complete workflow described in Section Section¬†11.1.1. Instead of using several functions for each of the steps, NetCoMi provides a single function for network construction (netConstruct()), so the package streamlines the workflow considerably. The user can choose from a variety of methods for data preprocessing, association estimation, sparsification, and transformation. The returned microNet object can then be passed to netAnalyze() (the network analysis function) so that all necessary information is available for the network analysis workflow.\n\nPeschel, Stefanie, Christian L M√ºller, Erika von Mutius, Anne-Laure Boulesteix, and Martin Depner. 2021. ‚ÄúNetCoMi: network construction and comparison for microbiome data in R.‚Äù Briefings in Bioinformatics 22 (4): bbaa290. https://doi.org/10.1093/bib/bbaa290.\n\nlibrary(NetCoMi)\n\nWe again use SPRING as one of the association measures available in NetCoMi to construct a conditional dependency graph.\nTo demonstrate how taxa are filtered with netConstruct(), we will use the unfiltered tse object this time. The filtering is the same as before: Taxa occurring in less than 20% of the samples are removed.\n\nnetcomi_net &lt;- netConstruct(tse,\n                            taxRank = \"genus\",\n                            filtTax = \"numbSamp\",\n                            filtTaxPar = list(numbSamp = 0.2),\n                            measure = \"spring\",\n                            measurePar = list(thresh = 0.05,\n                                              Rmethod = \"approx\"),\n                            sparsMethod = \"none\", \n                            dissFunc = \"signed\",\n                            seed = 13075)\n\nnetConstruct() returns an object of the class microNet, which contains all matrices generated during network construction.\nThe object also contains an edge list, giving each edge‚Äôs estimated association, dissimilarity, and adjacency. Let‚Äôs take a quick look at the edges with the highest and lowest edge weights:\n\nedgelist &lt;- netcomi_net$edgelist1[order(netcomi_net$edgelist1$adja, \n                                        decreasing = TRUE), ]\nhead(edgelist)\n##                  v1                    v2   asso   diss   adja\n##  73     Citrobacter           Escherichia 0.3682 0.5621 0.4379\n##  63    Buttiauxella              Serratia 0.2426 0.6154 0.3846\n##  69   Chitinivibrio Pseudogracilibacillus 0.2203 0.6244 0.3756\n##  19        Algicola           Siccibacter 0.2193 0.6248 0.3752\n##  111     Haliangium          Marinobacter 0.2148 0.6266 0.3734\n##  143 Planomicrobium         Virgibacillus 0.2006 0.6322 0.3678\ntail(edgelist)\n##                 v1             v2       asso   diss   adja\n##  132 Mycobacterium Salinibacillus  0.0017483 0.7065 0.2935\n##  24      Amphritea    Providencia  0.0014085 0.7066 0.2934\n##  102       Erwinia    Siccibacter  0.0013114 0.7066 0.2934\n##  116     Holophaga   Methylarcula  0.0007828 0.7068 0.2932\n##  17       Algicola     Lysobacter  0.0005191 0.7069 0.2931\n##  95   Enterobacter     Janibacter -0.0013921 0.7076 0.2924\n\nAs before, the adjacency matrix is converted into an igraph object. Further steps like sparsification and transformation are not necessary because they are done internally by netConstruct().\n\nnetcomi_graph &lt;- SpiecEasi::adj2igraph(abs(netcomi_net$adjaMat1))"
  },
  {
    "objectID": "pages/60_network_learning.html#sec-network-analysis",
    "href": "pages/60_network_learning.html#sec-network-analysis",
    "title": "11¬† Network learning and analysis",
    "section": "\n11.2 Network analysis with igraph",
    "text": "11.2 Network analysis with igraph\nThe computed network is now analyzed using appropriate methods. We will first use the igraph package to analyze the SPRING network. NetCoMi‚Äôs netAnalyze() function will be used later to analyze the constructed microNet object.\n\n11.2.1 Network plot\nTo get an overview of the network structure, a first common analysis method is to plot the network. We here use the igraph package, which is a state-of-the-art package for network analysis and visualization. Other packages that could be used for network plotting are the qgraph package or the ggnet2 package. Since we will use igraph for network analysis later on, we are using its plotting function here as well.\nWe use the Fruchterman-Reingold layout (a force-directed layout) for node placement. By placing strongly connected nodes close together and those with low edge weight far apart, this layout results in an easy-to-read network plot.\nThe node sizes are proportional to a taxon‚Äôs log10-transformed abundance, which we previously added to the tse object, averaged across all samples. The values are rescaled to be visually distinguishable.\nSince we created two graph objects, one with SPRING and one with NetCoMi, we plot them side by side. The two plots should be identical.\n\nlibrary(igraph)\n\n\n# Node sizes\nvsize &lt;- (colMeans(t(assay(tse, \"log10\"))) + 1) * 3\n\n# Fruchterman-Reingold layout from igraph package\nset.seed(13075)\nlay_fr &lt;- layout_with_fr(spring_graph)\n\npar(mfrow = c(1,2))\nplot(spring_graph, layout = lay_fr, vertex.size = vsize, \n     vertex.label = NA, main = \"SPRING network\")\nplot(netcomi_graph, layout = lay_fr, vertex.size = vsize, \n     vertex.label = NA, main = \"NetCoMi network\\n(with SPRING associations)\")\n\n\n\n\n\n\n\n\n11.2.2 Centrality measures\nCentrality measures express the importance of nodes within the network. Common measures are the degree, betweenness, closeness, and eigenvector centrality. The igraph package provides functions to compute these measures. We wrap a function around the code to reuse it later.\n\nget_centr &lt;- function(graph_obj) {\n  # We access igraph directly with \"::\" because there are more packages loaded in \n  # this chapter that contain a degree() function.\n  df &lt;- data.frame(Degree = igraph::degree(graph_obj))\n  df$Betweenness &lt;- betweenness(graph_obj)\n  df$Closeness &lt;- closeness(graph_obj, normalized = TRUE)\n  df$Eigenvector &lt;- eigen_centrality(graph_obj)$vector\n  return(df)\n}\n\ncentr_df &lt;- get_centr(spring_graph)\nrownames(centr_df) &lt;- rownames(spring_cor)\nhead(centr_df, 15)\n##                   Degree Betweenness Closeness Eigenvector\n##  Abyssicoccus          0           0       NaN   9.278e-18\n##  Acidaminococcus       2           0    0.6464   1.862e-01\n##  Acinetobacter         3           5    0.5544   1.257e-01\n##  Actinomyces           0           0       NaN   9.278e-18\n##  Actinoplanes          2          99    0.5104   1.099e-02\n##  Aerococcus            0           0       NaN   9.278e-18\n##  Aeromonas             4         351    0.7477   2.023e-01\n##  Agromyces             6         435    0.7733   5.293e-01\n##  Algicola              4         264    0.7206   1.500e-01\n##  Alicyclobacillus      0           0       NaN   9.278e-18\n##  Alteribacillus        0           0       NaN   9.278e-18\n##  Ammoniibacillus       1           0    0.5064   5.419e-02\n##  Amphritea             5         382    0.6256   1.335e-02\n##  Amycolatopsis         1           0    0.6117   1.338e-01\n##  Anaerococcus          2         392    0.4064   1.288e-03\n\nThe closeness centrality is ‚ÄúNaN‚Äù for some genera. These are unconnected nodes, as can be seen by the zero degree and betweenness centrality.\n\n11.2.3 Scale node sizes by degree\nCentrality measures can be visualized in the network plot by scaling the node sizes according to one of these measures. We plot the Spring graph using the same layout as before and with the node sizes scaled according to all four centrality measures.\nOf the four centrality measures, only the degree has a range suitable to be used as node size. The other centrality measures must be rescaled because their range is either too small or too large. The following scaling is a suggestion that works for this example. The values might be adapted for other data sets.\n\nget_vsizes &lt;- function(centr_df) {\n  df &lt;- as.matrix(centr_df)\n  df[, \"Betweenness\"] &lt;- log(df[, \"Betweenness\"])\n  df[, \"Closeness\"] &lt;- df[, \"Closeness\"] * 10\n  df[, \"Eigenvector\"] &lt;- df[, \"Eigenvector\"] * 10\n  df[is.infinite(df) | is.na(df)] &lt;- 0\n  return(df)\n}\n\nvsize_df &lt;- get_vsizes(centr_df )\nhead(vsize_df)\n##                  Degree Betweenness Closeness Eigenvector\n##  Abyssicoccus         0       0.000     0.000   9.278e-17\n##  Acidaminococcus      2       0.000     6.464   1.862e+00\n##  Acinetobacter        3       1.609     5.544   1.257e+00\n##  Actinomyces          0       0.000     0.000   9.278e-17\n##  Actinoplanes         2       4.595     5.104   1.099e-01\n##  Aerococcus           0       0.000     0.000   9.278e-17\n\n\npar(mfrow = c(2,2))\nfor (i in seq_along(centr_df)) {\n  plot(spring_graph, layout = lay_fr, vertex.size = vsize_df[, i], \n     vertex.label = NA, main = colnames(centr_df)[i])\n}\n\n\n\n\n\n\n\nWe observe that the two-node component at the bottom has a much higher closeness centrality than the nodes belonging to the main component of the network. Obviously, closeness centrality as commonly defined is misleading when the network consists of disconnected components. Nodes belonging to smaller components are seen as closer to others than in larger components. To overcome this problem, centrality values, and especially closeness centrality, are often calculated only for the largest connected component (LCC), which we will do below.\n\n# Extract the LCC\ndg_net &lt;- igraph::decompose.graph(spring_graph)\nidx_lcc &lt;- which.max(unlist(lapply(dg_net, function(x) length(igraph::V(x)))))\nlcc &lt;- dg_net[[idx_lcc]]\n\n# Compute centrality values for the LCC\ncentr_df_lcc &lt;- get_centr(lcc)\n\n# Replace centrality values by those for LCC and set all others to zero\nlcc_nodes &lt;- as.numeric(rownames(centr_df_lcc))\ncentr_df[lcc_nodes, ] &lt;- centr_df_lcc\ncentr_df[-lcc_nodes, ] &lt;- 0\n\n# Node/vertex sizes\nvsize_df &lt;- get_vsizes(centr_df)\n\n\npar(mfrow = c(2,2))\nfor (i in seq_along(centr_df)) {\n  plot(spring_graph, layout = lay_fr, vertex.size = vsize_df[, i], \n     vertex.label = NA, main = colnames(centr_df)[i])\n}\n\n\n\n\n\n\n\nNote that NetCoMi follows a different approach to overcome this problem. NetCoMi uses the definition of closeness centrality proposed by Tore Opsahl, which is well defined even for disconnected networks and assigns higher closeness centrality values to nodes in larger components. This is more intuitive because nodes in a larger component are connected to a larger number of other nodes than in small components.\n\n11.2.4 Degree distribution\nThe degree distribution is another popular measure that expresses the probability distribution of degrees over the entire network. It thus provides insight into the overall network structure. We plot the degree distribution for all four association estimation methods to compare the network structure.\n\nlibrary(ggplot2)\n\n\n# Compute degree distribution\nddist&lt;- igraph::degree.distribution(spring_graph)\n\n# Data frame needed for ggplot2\ndf &lt;- data.frame(Degree = as.factor((seq_along(ddist)) - 1),\n                 Fraction = ddist)\n\nggplot(data = df, aes(x = Degree, y = Fraction, group = 1)) +\n  geom_line() +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n\nThe network has a large number of singletons and sparsely connected nodes, and only a small number of nodes with a higher degree of 7 or more.\n\n11.2.5 Clustered heatmaps\nUsing the ComplexHeatmap package, we plot a heatmap of the association matrix estimated with SPRING. Rows and columns are sorted according to the clusters identified via hierarchical clustering.\n\nlibrary(ComplexHeatmap)\nlibrary(circlize)\n\nWe select the 50 nodes with the highest sum of edge weights to get a smaller heatmap.\n\nsel &lt;- names(sort(rowSums(spring_cor), decreasing = TRUE))[seq_len(50)]\nadja_sel &lt;- spring_cor[sel, sel]\n\n\n# Color vector\ncol &lt;- colorRamp2(c(-1, -0.5, 0, 0.5, 1), \n                  c(\"royalblue4\", \"lightblue\", \"white\", \"orange\", \"firebrick3\"))\n\nHeatmap(adja_sel, \n        col = col, \n        rect_gp = gpar(col = \"gray\", lwd = 1),\n        show_row_names = FALSE, \n        show_column_names = FALSE,\n        name = \"Association\")\n\n\n\n\n\n\n\nThe associations are generally quite low, and there are no prominent clusters detected by hierarchical clustering.\n\n11.2.6 Global network measures\nGlobal measures describe the overall network structure. We take a look at three common measures: density, transitivity, and average path length. The values are again computed with igraph functions.\n\n11.2.6.1 Density\nDefinition: Proportion of present edges from all possible edges.\n\nedge_density(spring_graph)\n##  [1] 0.01444\n\n\n11.2.6.2 Transitivity (clustering coefficient)\nHere, we consider only the global clustering coefficient, which is defined as the ratio of triangles to connected triples.\n\ntransitivity(spring_graph)\n##  [1] 0.1456\n\n\n11.2.6.3 Average path length\nDefinition: Mean of the shortest distance between each pair of nodes.\n\naverage.path.length(spring_graph)\n##  [1] 1.699"
  },
  {
    "objectID": "pages/60_network_learning.html#network-analysis-with-netcomi",
    "href": "pages/60_network_learning.html#network-analysis-with-netcomi",
    "title": "11¬† Network learning and analysis",
    "section": "\n11.3 Network analysis with NetCoMi",
    "text": "11.3 Network analysis with NetCoMi\nThe netcomi_net object of class microNet created before is now passed to netAnalyze() to perform network analysis with NetCoMi.\nThe function computes several common network characteristics such as centrality measures, cluster assignment, the graphlet correlation matrix, as well as global network measures.\nThe user has several options to choose from, such as a clustering method, how to define hubs, and whether or not to normalize centrality values. See the help page ?netAnalyze for a description of the arguments.\nBy default, a heatmap of the Graphlet Correlation Matrix (GCM) is returned (with graphlet correlations in the upper triangle and significance codes resulting from Student‚Äôs t-test in the lower triangle). See ?calcGCM and ?testGCM for details.\n\nnetcomi_netprops &lt;- netAnalyze(netcomi_net, \n                               clustMethod = \"cluster_fast_greedy\",\n                               hubPar = \"eigenvector\",\n                               normDeg = FALSE)\n\n\n\n\n\n\n\n\nsummary(netcomi_netprops, numbNodes = 5)\n##  \n##  Component sizes\n##  ```````````````              \n##  size: 103 2  1\n##     #:   1 1 42\n##  ______________________________\n##  Global network properties\n##  `````````````````````````\n##  Largest connected component (LCC):\n##                                   \n##  Relative LCC size         0.70068\n##  Clustering coefficient    0.21253\n##  Modularity                0.70495\n##  Positive edge percentage 99.35065\n##  Edge density              0.02932\n##  Natural connectivity      0.01173\n##  Vertex connectivity       1.00000\n##  Edge connectivity         1.00000\n##  Average dissimilarity*    0.99084\n##  Average path length**     3.81101\n##  \n##  Whole network:\n##                                   \n##  Number of components     44.00000\n##  Clustering coefficient    0.21253\n##  Modularity                0.70787\n##  Positive edge percentage 99.35484\n##  Edge density              0.01444\n##  Natural connectivity      0.00782\n##  -----\n##  *: Dissimilarity = 1 - edge weight\n##  **: Path length = Units with average dissimilarity\n##  \n##  ______________________________\n##  Clusters\n##  - In the whole network\n##  - Algorithm: cluster_fast_greedy\n##  ```````````````````````````````` \n##                                    \n##  name:  0  1  2  3  4 5  6 7 8 9 10\n##     #: 42 16 11 14 20 9 17 8 5 3  2\n##  \n##  ______________________________\n##  Hubs\n##  - In alphabetical/numerical order\n##  - Based on empirical quantiles of centralities\n##  ```````````````````````````````````````````````                      \n##   Agromyces            \n##   Aneurinibacillus     \n##   Anoxybacillus        \n##   Chitinivibrio        \n##   Erwinia              \n##   Geobacillus          \n##   Janibacter           \n##   Pseudogracilibacillus\n##  \n##  ______________________________\n##  Centrality measures\n##  - In decreasing order\n##  - Centrality of disconnected components is zero\n##  ````````````````````````````````````````````````\n##  Degree (unnormalized):\n##                         \n##  Anoxybacillus        10\n##  Erwinia              10\n##  Chitinivibrio         9\n##  Janibacter            8\n##  Escherichia/Shigella  7\n##  \n##  Betweenness centrality (normalized):\n##                      \n##  Janibacter    0.3941\n##  Chitinivibrio 0.3137\n##  Enterobacter  0.2780\n##  Buttiauxella  0.2454\n##  Erwinia       0.2095\n##  \n##  Closeness centrality (normalized):\n##                              \n##  Chitinivibrio         0.5247\n##  Janibacter            0.5067\n##  Anoxybacillus         0.4841\n##  Pseudogracilibacillus 0.4659\n##  Erwinia               0.4653\n##  \n##  Eigenvector centrality (normalized):\n##                              \n##  Anoxybacillus         1.0000\n##  Chitinivibrio         0.9831\n##  Pseudogracilibacillus 0.8657\n##  Janibacter            0.8361\n##  Aneurinibacillus      0.6890\n\nInterpretation of some findings:\n\nThe largest connected component (LCC) has 103 nodes and the network contains 42 singletons.\n10 clusters have been identified, containing 2 to 20 nodes.\nThere are 8 hub nodes detected, which by definition are the nodes with the highest eigenvector centrality.\nThe average path length in the LCC is 3.811. This means that on average it takes 3.811 steps (step length is the average dissimilarity) to get from one node to another. Note that the average path length in NetCoMi is defined differently than in the igraph package, which is why the values differ.\nLow values of edge density and the connectivity measures indicate that the network is rather sparse and not robust to perturbations (i.e., removal of nodes or edges)."
  },
  {
    "objectID": "pages/60_network_learning.html#network-visualization",
    "href": "pages/60_network_learning.html#network-visualization",
    "title": "11¬† Network learning and analysis",
    "section": "\n11.4 Network visualization",
    "text": "11.4 Network visualization\nFurther insight into the network structure can be gained by visualizing the network. We have already seen examples of how to plot a network using the igraph package. Here we will use NetCoMi‚Äôs plot function. It takes as input the microNetProps object returned by netAnalyze(), which contains all computed network properties. This has the advantage that the user can choose which properties to plot by simply changing some arguments. The plot function is based on qgraph, which is another state-of-the-art R package for network visualization. The help page can be accessed via ?plot.microNetProps.\n\n11.4.1 Highlight node properties\nIn the first plot, node colors represent the detected clusters and node sizes are scaled by eigenvector centrality. Hub nodes are highlighted by default. Singletons are not included in the plot. To improve the readability, NetCoMi‚Äôs ‚Äúintelligent‚Äù label shortening approach is used.\nNote that nodes are sometimes placed too close together so that the labels overlap. You may need to play around with the repulsion argument until you find a value where the labels are legible, but also the clusters are still well recognizable.\n\nplot(netcomi_netprops,\n     repulsion = 0.98,\n     rmSingles = TRUE,\n     shortenLabels = \"intelligent\",\n     labelScale = FALSE,\n     nodeSize = \"eigenvector\",\n     nodeSizeSpread = 3,\n     nodeColor = \"cluster\", \n     hubBorderCol = \"gray40\",\n     cexNodes = 1.8,\n     edgeTranspHigh = 20,\n     title1 = \"Network properties highlighted\", \n     showTitle = TRUE,\n     cexTitle = 2.3,\n     mar = c(1, 3, 4, 8))\n\nlegend(0.7, 1.1, cex = 1.7, title = \"estimated correlation:\",\n       legend = c(\"+\",\"-\"), lty = 1, lwd = 3, col = c(\"#009900\",\"red\"), \n       bty = \"n\", horiz = TRUE)\n\n\n\n\n\n\n\n\n11.4.2 Highlight data features\nWe now color nodes according to their phylum. The node sizes are proportional to a taxon‚Äôs sum of mclr-transformed abundances. As already mentioned in Section @ref(spring-network), this is the normalization method used by SPRING. A color palette from RColorBrewer is used here.\n\nlibrary(RColorBrewer)\n\n\n# Generate vector with phylum names for node coloring\nphyla &lt;- as.factor(rowData(tse)$phylum)\nnames(phyla) &lt;- rowData(tse)$genus\n\n# Create color vector\ncolvec &lt;- RColorBrewer::brewer.pal(length(levels(phyla)), \"Set3\")\n\nplot(netcomi_netprops,\n     repulsion = 0.98,\n     rmSingles = TRUE,\n     shortenLabels = \"intelligent\",\n     labelScale = FALSE,\n     nodeSize = \"mclr\",\n     nodeColor = \"feature\", \n     featVecCol = phyla, \n     colorVec =  colvec,\n     nodeTransp = 20,\n     highlightHubs = FALSE,\n     cexNodes = 1.8,\n     edgeTranspHigh = 20,\n     title1 = \"Data features highlighted\", \n     showTitle = TRUE,\n     cexTitle = 2.3,\n     mar = c(1, 10, 4, 6))\n\n# Add legends\nlegend(0.7, 1.1, cex = 1.7, title = \"estimated correlation:\",\n       legend = c(\"+\",\"-\"), lty = 1, lwd = 3, col = c(\"#009900\",\"red\"), \n       bty = \"n\", horiz = TRUE)\n\n# Colors used in the legend should be equally transparent as in the plot\ncol_transp &lt;- colToTransp(colvec, 20)\n\nlegend(-1.8, 1.1, cex = 1.7, pt.cex = 2.5, title = \"Phylum:\", \n       legend=levels(phyla), col = col_transp, bty = \"n\", pch = 16) \n\n\n\n\n\n\n\nA few things to observe:\n\nGenera belonging to the same phylum tend to cluster together, though not perfectly.\nGenera with a low total count play a rather unimportant role in the network, i.e., they have a low centrality.\nThere is only one negative edge in the network. This edge is between two clusters, as expected when using the ‚Äúsigned‚Äù transformation."
  },
  {
    "objectID": "pages/60_network_learning.html#which-methods-to-choose",
    "href": "pages/60_network_learning.html#which-methods-to-choose",
    "title": "11¬† Network learning and analysis",
    "section": "\n11.5 Which method(s) to choose?",
    "text": "11.5 Which method(s) to choose?\nThroughout all the steps from primary data to potentially significant network features, there is a variety of methods and parameters to choose from. However, there is no general consensus in the community on the ‚Äúright‚Äù way to estimate and analyze microbial networks. In the absence of a ‚Äúbest method‚Äù for inferring and analyzing microbial networks, researchers may be tempted to try different methods and report only the optimal results or those that fit some prior knowledge. This carries the risk of ‚Äúoverfitting‚Äù the analysis to the existing data so that the results are not replicable for new data (Ullmann et al. 2023).\n\nUllmann, Theresa, Stefanie Peschel, Philipp Finger, Christian L M√ºller, and Anne-Laure Boulesteix. 2023. ‚ÄúOver-Optimism in Unsupervised Microbiome Analysis: Insights from Network Learning and Clustering.‚Äù PLoS Computational Biology 19 (1): e1010820. https://doi.org/10.1371/journal.pcbi.1010820.\nTherefore, the selection of the workflow building blocks should be set up once and independently of any hypothesis about the data, thus avoiding the fallacy of starting to ‚Äúfish‚Äù for results that best fit a previously formulated hypothesis. For example, one should ask prior to the analysis whether correlation or conditional dependence as a measure of association better fits the research question and choose the method accordingly. Another example is the choice of transformation from estimated association to dissimilarity (i.e., ‚Äúsigned‚Äù or ‚Äúunsigned‚Äù), which completely changes the interpretation and characteristics of the network. This choice should be made based on the research question before starting the analysis."
  },
  {
    "objectID": "pages/60_network_learning.html#sec-more-about-association",
    "href": "pages/60_network_learning.html#sec-more-about-association",
    "title": "11¬† Network learning and analysis",
    "section": "\n11.6 More about association measures",
    "text": "11.6 More about association measures\nAs mentioned in the introduction of this chapter, there are three types of association measures that are commonly used to express relationships between taxa: correlation, conditional dependence, and proportionality. Below, we provide a brief explanation of each of these measures, along with lists of available compositionality-aware approaches.\n\n\nCorrelation: Two popular measures of ecological association are Pearson‚Äôs correlation coefficient and Spearman‚Äôs rank correlation coefficient, both of which can be inferred from empirical (sample) covariances. However, in the \\(p\\gg n\\) setting, which most microbiome datasets are in, sample covariances and correlations are unreliable because the parameters being estimated are typically underdetermined. One way to improve sample covariance estimates is to assume that the underlying covariance matrix is sparse and use a regularized covariance estimator to implement this structural assumption. The Sch√§fer-Strimmer shrinkage estimator (Sch√§fer and Strimmer 2005) is one possible method for estimating a sparse correlation matrix. Other popular methods, especially designed to estimate correlations for compositional data, are SparCC (‚ÄúSparse Correlations for Compositional data‚Äù) by J. Friedman and Alm (2012), CCREPE (‚ÄúCompositionality Corrected by REnormalization and PErmutation‚Äù) by Faust et al. (2012), and CCLasso (‚ÄúCorrelation inference for Compositional data through Lasso‚Äù) by Huaying Fang et al. (2015). The latter three methods already include a compositionality aware normalization, and SparCC also includes a zero replacement approach.\n\nConditional dependence: Since standard correlations include both direct and indirect dependencies, conditional dependence or partial correlation is often preferred for measuring association. Unlike (marginal) correlation, it expresses the relationship between two features conditioned on all other features in the data set. The approach and R package SpiecEasi (‚ÄúSparse InversE Covariance estimation for Ecological Association and Statistical Inference‚Äù) by Kurtz et al. (2015) is specifically designed for inferring ecological networks from microbiome data and includes two approaches for estimating conditional dependence structures between taxa: Neighborhood Selection; short ‚ÄúMB‚Äù (Meinshausen and B√ºhlmann 2006) and (inverse) covariance selection (Jerome Friedman, Hastie, and Tibshirani 2008), which is based on a penalized maximum likelihood approach and is also known as ‚Äúgraphical lasso‚Äù. Another approach and R package for inferring partial correlations from microbiome data is SPRING (‚ÄúSemi-Parametric Rank-based approach for INference in Graphical model‚Äù) by Yoon, Gaynanova, and M√ºller (2019). They also use the MB neighborhood selection method, but introduce a novel semi-parametric rank-based approach for sparse partial correlation estimation that can naturally handle the excess of zeros in the data. gCoda (H. Fang et al. 2017) is another conditional dependence measure based on penalized maximum likelihood estimation. All of the aforementioned conditional dependence measures address the high dimensionality of microbiome data.\n\nProportionality: Lovell et al. (2015) introduce proportionality as an alternative measure of pairwise association for compositional data. The idea is that if the relative abundances between two taxa \\(i\\) and \\(j\\) are proportional, then their corresponding absolute abundances are also proportional: \\(\\frac{\\omega_i}{m} \\propto \\frac{\\omega_j}{m} \\Rightarrow \\omega_i \\propto \\omega_j\\), where \\(m\\) is the sum of counts in the sample. It follows that proportionality is identical for the observed (relative) read counts and the true unobserved counts. The proportionality measure proposed by Lovell et al. (2015) is based on log-ratio variance \\(var(log \\frac{x_i}{x_j})\\), which is zero when \\(\\omega_i\\) and \\(\\omega_j\\) are perfectly proportional. Proportionality is implemented in the R package propr. Badri et al. (2020) extend the proportionality measure to a so-called ‚Äúshrinkage proportionality estimator‚Äù. It combines proportionality with the covariance shrinkage approach to obtain consistent association estimates even with small sample sizes.\n\nSch√§fer, Juliane, and Korbinian Strimmer. 2005. ‚ÄúA shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics.‚Äù Statistical Applications in Genetics and Molecular Biology 4 (1): 1‚Äì30. https://doi.org/10.2202/1544-6115.1175.\n\nFaust, Karoline, J. Fah Sathirapongsasuti, Jacques Izard, Nicola Segata, Dirk Gevers, Jeroen Raes, and Curtis Huttenhower. 2012. ‚ÄúMicrobial Co-occurrence Relationships in the Human Microbiome.‚Äù PLoS Computational Biology 8 (7): e1002606. https://doi.org/10.1371/journal.pcbi.1002606.\n\nFang, Huaying, Chengcheng Huang, Hongyu Zhao, and Minghua Deng. 2015. ‚ÄúCCLasso: Correlation inference for compositional data through Lasso.‚Äù Bioinformatics 31 (19): 3172‚Äì80. https://doi.org/10.1093/bioinformatics/btv349.\n\nFriedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2008. ‚ÄúSparse inverse covariance estimation with the graphical lasso.‚Äù Biostatistics (Oxford, England) 9 (3): 432‚Äì41. https://doi.org/10.1093/BIOSTATISTICS/KXM045.\n\nYoon, Grace, Irina Gaynanova, and Christian L M√ºller. 2019. ‚ÄúMicrobial networks in SPRING - Semi-parametric rank-based correlation and partial correlation estimation for quantitative microbiome data.‚Äù Frontiers in Genetics 10: 516. https://doi.org/10.3389/fgene.2019.00516.\n\nFang, H, C Huang, H Zhao, and M Deng. 2017. ‚ÄúgCoda: Conditional Dependence Network Inference for Compositional Data.‚Äù Journal of Computational Biology 24 (7): 699‚Äì708. https://doi.org/10.1089/cmb.2017.0054."
  },
  {
    "objectID": "pages/60_network_learning.html#comparison-of-association-measures",
    "href": "pages/60_network_learning.html#comparison-of-association-measures",
    "title": "11¬† Network learning and analysis",
    "section": "\n11.7 Comparison of association measures",
    "text": "11.7 Comparison of association measures\nIn this section, we provide three additional examples for constructing a network using each of the three types of association:\n\nCorrelation using SparCC\n\nPartial correlation using SpiecEasi\n\nProportionality using the shrinkage proportionality measure\n\n\n11.7.1 SparCC\nThe first association measure we look at is SparCC (‚ÄúSparse Correlations for Compositional data‚Äù), introduced by J. Friedman and Alm (2012). It estimates Pearson correlations while taking into account the compositional structure of the data. The SpiecEasi package provides an implementation of this method.\n\nFriedman, J, and EJ Alm. 2012. ‚ÄúInferring Correlation Networks from Genomic Survey Data.‚Äù PLoS Computational Biology 8 (9): e1002687. https://doi.org/10.1371/journal.pcbi.1002687.\n\n# Set seed for reproducibility\nset.seed(13075)\n# Compute correlation matrix\nsparcc_cor &lt;- SpiecEasi::sparcc(t(assay(tse, \"counts\")))$Cor\nrownames(sparcc_cor) &lt;- colnames(sparcc_cor) &lt;- rownames(tse)\n\nWe reuse the transform_asso() function created in Section @ref(spring-network), which sparsifies the association matrix, transforms it into a similarity matrix, and finally returns an igraph object.\nTwo threshold values are used to see the effect of sparsification later in the network plot.\n\nsparcc_trans03 &lt;- transform_asso(sparcc_cor, thresh = 0.3)\nsparcc_trans04 &lt;- transform_asso(sparcc_cor, thresh = 0.4)\n\nsparcc_graph03 &lt;- sparcc_trans03$graph\nsparcc_graph04 &lt;- sparcc_trans04$graph\n\n\n11.7.2 Shrinkage proportionality\nIn the second example, microbial associations are measured by proportionality, originally introduced by Lovell et al. (2015). We use the shrinkage proportionality estimator proposed by Badri et al. (2020), which gives consistent results even for small sample sizes. Since there is no R package implementing this estimator, we use the rho_shrink_est() function provided in the GitHub repository associated with the paper. The function is slightly modified to take normalized counts as input.\n\nLovell, David, Vera Pawlowsky-Glahn, Juan Jos√© Egozcue, Samuel Marguerat, and J√ºrg B√§hler. 2015. ‚ÄúProportionality: A Valid Alternative to Correlation for Relative Data.‚Äù PLoS Computational Biology 11 (3): 1‚Äì12. https://doi.org/10.1371/journal.pcbi.1004075.\n\nBadri, Michelle, Zachary D. Kurtz, Richard Bonneau, and Christian L. M√ºller. 2020. ‚ÄúShrinkage improves estimation of microbial associations under different normalization methods.‚Äù NAR Genomics and Bioinformatics 2 (4). https://doi.org/10.1093/NARGAB/LQAA100.\n\nlibrary(corpcor)\n\n\n# norm_counts: clr-transformed count matrix with samples in rows\nrho_shrink_est &lt;- function(norm_counts, ...) {\n  shrunk_cov &lt;- cov.shrink(norm_counts, ...)\n  p &lt;- ncol(norm_counts)\n  J &lt;- matrix(rep(diag(shrunk_cov), p), p)\n  rho &lt;- 2 * shrunk_cov / (J + t(J))\n  (rho + t(rho)) / 2\n}\n\n\n# Apply the shrinkage proportionality estimator to the clr-transformed counts\nprop_est &lt;- as(rho_shrink_est(t(assay(tse, \"clr\"))), \"matrix\")\n##  Estimating optimal shrinkage intensity lambda.var (variance vector): 0.0857 \n##  \n##  Estimating optimal shrinkage intensity lambda (correlation matrix): 0.3634\n\nAgain, we use our transformation function to convert the association matrix into a graph object.\n\nprop_trans &lt;- transform_asso(prop_est, thresh = 0.4)\nprop_graph &lt;- prop_trans$graph\n\n\n11.7.3 SpiecEasi - MB\nAs third example, we use the SpiecEasi (‚ÄúSparse InversE Covariance estimation for Ecological Association and Statistical Inference‚Äù) approach proposed by Kurtz et al. (2015) to estimate a sparse conditional dependency graph. The neighborhood selection method (‚ÄúMB‚Äù) introduced by Meinshausen and B√ºhlmann (2006) is used for network learning. The approach is implemented in the R package SpiecEasi.\n\nKurtz, ZD, CL M√ºller, ER Miraldi, DR Littman, MJ Blaser, and Bonneau RA. 2015. ‚ÄúSparse and Compositionally Robust Inference of Microbial Ecological Networks.‚Äù PLoS Computational Biology 11 (5): e1004226. https://doi.org/10.1371/journal.pcbi.1004226.\n\nMeinshausen, Nicolai, and Peter B√ºhlmann. 2006. ‚ÄúHigh-dimensional graphs and variable selection with the Lasso.‚Äù Annals of Statistics 34 (3): 1436‚Äì62. https://doi.org/10.1214/009053606000000281.\n\nlibrary(SpiecEasi)\n\n\nset.seed(13075)\nse_mb_est &lt;- spiec.easi(t(assay(tse, \"counts\")), \n                        method = 'mb', nlambda = 20, \n                        pulsar.params = list(rep.num = 20))\n\nSince SpiecEasi uses the StARS (‚ÄúStability Approach to Regularization Selection‚Äù) method (Liu, Roeder, and Wasserman 2010) to obtain a sparse association matrix, we don‚Äôt need to set a threshold here. We store the partial correlations corresponding to the StARS-optimal lambda and convert them into an igraph object.\n\nLiu, Han, Kathryn Roeder, and Larry Wasserman. 2010. ‚ÄúStability Approach to Regularization Selection (StARS) for High Dimensional Graphical Models.‚Äù Advances in Neural Information Processing Systems. https://doi.org/10.48550/arxiv.1006.3316.\n\n# Get optimal matrix with partial correlations\nse_mb_cor &lt;- as.matrix(getOptBeta(se_mb_est))\nse_mb_cor &lt;- as.matrix(symBeta(se_mb_cor))\nrownames(se_mb_cor) &lt;- colnames(se_mb_cor) &lt;- rownames(tse)\ndiag(se_mb_cor) &lt;- 1\n\n# Create graph object\nse_mb_graph &lt;- transform_asso(se_mb_cor)$graph\n\n\n11.7.4 Network plots\nThe graph objects can now be plotted using the igraph package. The same layout is used in all four plots so that the networks are comparable.\n\nlibrary(igraph)\n\n\n# Node sizes\nvsize &lt;- (colMeans(t(assay(tse, \"log10\"))) + 1) * 3\n\n# Use Fruchterman-Reingold (force-directed) layout\nset.seed(13075)\nlay_fr &lt;- layout_with_fr(se_mb_graph)\n\npar(mfrow = c(2,2))\nplot(sparcc_graph03, layout = lay_fr, vertex.size = vsize, \n     vertex.label = NA, main = \"SparCC (thresh 0.3)\")\nplot(sparcc_graph04, layout = lay_fr, vertex.size = vsize, \n     vertex.label = NA, main = \"SparCC (thresh 0.4)\")\nplot(prop_graph, layout = lay_fr, vertex.size = vsize, \n     vertex.label = NA, main = \"Shrinkage proportionality\\n(thresh 0.4)\")\nplot(se_mb_graph, layout = lay_fr, vertex.size = vsize, \n     vertex.label = NA, main = \"SpiecEasi (MB)\")\n\n\n\n\n\n\n\nA few observations:\nThe density of SparCC (threshold 0.4), proportionality and SpiecEasi is comparable, while the SparCC correlation network with threshold 0.3 is much denser. However, there are edges in the proportionality and SpiecEasi networks that are not present in the two SparCC networks. The SpiecEasi network has less highly connected nodes than the other three networks, but more nodes with one or two connections.\nWe will look at the degree distribution in the next section to quantify these observations.\n\n11.7.5 Network analysis\nHere we repeat some of the network analysis approaches explained in Section @ref(network-analysis). The analyses are performed simultaneously for the three association measures as well as the SPRING network constructed in Section @ref(spring-network). Therefore, we start by creating a list of all the graph objects we need for the analyses.\n\ngraphlist &lt;- list(SparCC = sparcc_graph04, \n                  Proportionality = prop_graph,\n                  SpiecEasi = se_mb_graph,\n                  SPRING = spring_graph)\n\n\n11.7.5.1 Degree distribution\nThe degree distribution is plotted for all four measures to compare the overall network structure.\n\nlibrary(ggplot2)\n\n\n# Compute degree distributions\nddlist &lt;- lapply(graphlist, igraph::degree.distribution)\n\n# Maximum degree\nmaxdeg &lt;- max(lengths(ddlist))\n\n# Make list elements the same length\nfor(i in seq_along(graphlist)) {\n  length(ddlist[[i]]) &lt;- maxdeg\n}\n\n# Data frame needed for ggplot2\ndf &lt;- data.frame(Degree = rep(seq_len(maxdeg), length(graphlist)), \n                 Fraction = unlist(ddlist), \n                 Method = rep(names(graphlist), each = maxdeg))\n\nggplot(df, aes(x = Degree, y = Fraction, group = Method)) +\n  geom_line(aes(color = Method)) +\n  geom_point(aes(color = Method)) +\n  theme_bw()\n\n\n\n\n\n\n\nThe SparCC and shrinkage proportionality networks have a considerably higher proportion of singletons (zero-degree nodes) than the two conditional dependency graphs, but a lower proportion of nodes with degrees between one and five. The SpiecEasi and SPRING graphs, on the other hand, have a higher proportion of low degree nodes, but no highly connected nodes with a degree greater than eleven.\n\n11.7.5.2 Clustered heatmaps\nUsing the ComplexHeatmap package, we plot heatmaps of the association matrices for the four considered association measures. Rows and columns are sorted according to the clusters identified via hierarchical clustering.\n\nlibrary(ComplexHeatmap)\nlibrary(circlize)\nlibrary(patchwork)\n\nFor each association measure, we select the 50 nodes with the highest sum of edge weights.\n\n# Function for selecting taxa with highest sum of edge weights\nselect_taxa &lt;- function(adja, ntaxa = 50) {\n  sel &lt;- names(sort(rowSums(adja), decreasing = TRUE))[seq_len(ntaxa)]\n  adja[sel, sel]\n}\n\nassolist &lt;- list()\nassolist$SparCC &lt;- select_taxa(sparcc_trans04$adja)\nassolist$Proportionality &lt;- select_taxa(prop_trans$adja)\nassolist$SpiecEasi &lt;- select_taxa(se_mb_cor)\nassolist$SPRING &lt;- select_taxa(spring_cor)\n\n\n# Color vector for the legend\ncol &lt;- colorRamp2(c(-1, -0.5, 0, 0.5, 1), \n                  c(\"royalblue4\", \"lightblue\", \"white\", \"orange\", \"firebrick3\"))\n\nhm_list &lt;- list()\n\nfor(i in seq_along(assolist)) {\n  if (i %in% c(2, 4)) {\n    showlegend &lt;- TRUE\n  } else {\n    showlegend &lt;- FALSE\n  }\n  \n  hm_list[[i]] &lt;- Heatmap(assolist[[i]], \n                          col = col, \n                          rect_gp = gpar(col = \"gray\", lwd = 1),\n                          show_row_names = FALSE, \n                          show_column_names = FALSE,\n                          column_title = names(assolist)[i], \n                          name = \"Association\",\n                          show_heatmap_legend = showlegend) %&gt;% \n    draw() %&gt;% \n    grid.grabExpr()\n}\n\n# Plot with wrap_plots() function from patchwork package\nwrap_plots(hm_list, ncol = 2, widths = c(8, 10, 8, 10))\n\n\n\n\n\n\n\nThe SparCC and the proportionality network show a block structure, where each block corresponds to a cluster. The clusters are less pronounced in the conditional dependence networks. The latter also generally have lower edge weights.\n\n11.7.5.3 Global network measures\nFor each association measure, the three global network measures density, transitivity, and average path length are computed and stored in a data frame for comparison.\n\n# Compute density and store in a data frame\nglob &lt;- data.frame(Density = unlist(lapply(graphlist, edge_density)))\n\n# Transitivity\nglob$Transitivity &lt;- unlist(lapply(graphlist, transitivity))\n\n# Average path length\nglob$Av.path &lt;- unlist(lapply(graphlist, average.path.length))\n\nglob\n##                  Density Transitivity Av.path\n##  SparCC          0.01510       0.5458  0.8932\n##  Proportionality 0.01295       0.5402  1.1847\n##  SpiecEasi       0.02162       0.2145  1.6322\n##  SPRING          0.01444       0.1456  1.6993"
  },
  {
    "objectID": "pages/61_network_comparison.html#data-preparation",
    "href": "pages/61_network_comparison.html#data-preparation",
    "title": "12¬† Network comparison",
    "section": "\n12.1 Data preparation",
    "text": "12.1 Data preparation\nWe perform the same data preprocessing steps as in chapter Chapter¬†11.\n\nlibrary(NetCoMi)\nlibrary(mia)\n\n\ndata(\"peerj13075\", package = \"mia\")\ntse0 &lt;- peerj13075\n\n\n# Agglomerate to genus level\ntse &lt;- agglomerateByRank(tse0, rank = \"genus\") \n\n# Add relative abundances\ntse &lt;- transformAssay(tse, \n                      assay.type = \"counts\", \n                      method = \"relabundance\",\n                      MARGIN = \"samples\") \n\n# Filter by prevalence\ntse &lt;- subsetByPrevalentFeatures(tse,\n                                 prevalence = 0.2,\n                                 detection = 0,\n                                 assay.type = \"relabundance\")\n\n# Add log10-transformed abundances\ntse &lt;- transformAssay(tse, method = \"log10\", pseudocount = 1)\n\n# Add clr-transformed abundances\ntse &lt;- transformAssay(tse, method = \"clr\", pseudocount = 1)\n\nBased on ‚ÄúDiet‚Äù, the tse object is then split into two groups: One with mixed diet subjects, and one with vegetarian subjects. Both subsets have nearly the same sample size and are therefore comparable.\n\ntable(tse$Diet)\n##  \n##  Mixed   Veg \n##     28    30\ntse_list &lt;- splitOn(tse, f = \"Diet\", use_names = TRUE, MARGIN = 2)"
  },
  {
    "objectID": "pages/61_network_comparison.html#network-learning-and-analysis",
    "href": "pages/61_network_comparison.html#network-learning-and-analysis",
    "title": "12¬† Network comparison",
    "section": "\n12.2 Network learning and analysis",
    "text": "12.2 Network learning and analysis\nThe approach starts again with network construction and analysis, but this time we pass the two data sets to netConstruct to perform a network comparison.\nThe rep.num argument is set to 10 to perform only 10 repetitions in the model selection approach. This speeds up the permutation tests performed later, and has a negligible effect for this data set.\n\nspring_net_diet &lt;- netConstruct(data = tse_list$Mixed,\n                                data2 = tse_list$Veg,\n                                taxRank = \"genus\",\n                                filtTax = \"highestFreq\",\n                                filtTaxPar = list(highestFreq  = 100),\n                                measure = \"spring\",\n                                measurePar = list(nlambda = 20, \n                                                  rep.num = 10,\n                                                  thresh = 0.05,\n                                                  Rmethod = \"approx\"),\n                                sparsMethod = \"none\", \n                                dissFunc = \"signed\",\n                                verbose = 3,\n                                seed = 13075)\n\nAll network measures are now computed for both networks. Also, both GCMs are plotted together with a third matrix containing the differences between the GCMs and significance codes that express if the differences are significantly different from zero.\n\nspring_netprops_diet &lt;- netAnalyze(spring_net_diet, \n                                   clustMethod = \"cluster_fast_greedy\",\n                                   hubPar = \"eigenvector\",\n                                   normDeg = FALSE)\n\n\n\n\n\n\n\nIn both of the networks, some graphlet correlations are significantly different from zero. However, none of the correlations are significantly different between the groups.\n\nsummary(spring_netprops_diet, groupNames = c(\"Mixed diet\", \"Vegetarian\"))\n##  \n##  Component sizes\n##  ```````````````\n##  Mixed diet:                   \n##  size: 18 8 4 3 2  1\n##     #:  1 1 1 1 3 43\n##  Vegetarian:                 \n##  size: 21 5 4 2  1\n##     #:  1 1 1 3 46\n##  ______________________________\n##  Global network properties\n##  `````````````````````````\n##  Largest connected component (LCC):\n##                           Mixed diet Vegetarian\n##  Relative LCC size           0.21951    0.25610\n##  Clustering coefficient      0.10393    0.22433\n##  Modularity                  0.51500    0.47707\n##  Positive edge percentage   80.00000  100.00000\n##  Edge density                0.13072    0.12381\n##  Natural connectivity        0.07312    0.06253\n##  Vertex connectivity         1.00000    1.00000\n##  Edge connectivity           1.00000    1.00000\n##  Average dissimilarity*      0.96009    0.96154\n##  Average path length**       2.22768    2.24622\n##  \n##  Whole network:\n##                           Mixed diet Vegetarian\n##  Number of components       50.00000   52.00000\n##  Clustering coefficient      0.07506    0.16530\n##  Modularity                  0.75184    0.66821\n##  Positive edge percentage   88.57143  100.00000\n##  Edge density                0.01054    0.01084\n##  Natural connectivity        0.01342    0.01347\n##  -----\n##  *: Dissimilarity = 1 - edge weight\n##  **: Path length = Units with average dissimilarity\n##  \n##  ______________________________\n##  Clusters\n##  - In the whole network\n##  - Algorithm: cluster_fast_greedy\n##  ```````````````````````````````` \n##  Mixed diet:                          \n##  name:  0 1 2 3 4 5 6 7 8 9\n##     #: 43 8 6 6 6 4 3 2 2 2\n##  \n##  Vegetarian:                        \n##  name:  0 1 2 3 4 5 6 7 8\n##     #: 46 9 8 4 5 4 2 2 2\n##  \n##  ______________________________\n##  Hubs\n##  - In alphabetical/numerical order\n##  - Based on empirical quantiles of centralities\n##  ```````````````````````````````````````````````\n##    Mixed diet           Vegetarian\n##   Citrobacter            Aeromonas\n##       Erwinia              Erwinia\n##   Escherichia Escherichia/Shigella\n##      Serratia           Salmonella\n##    Shewanella          Siccibacter\n##  \n##  ______________________________\n##  Centrality measures\n##  - In decreasing order\n##  - Centrality of disconnected components is zero\n##  ````````````````````````````````````````````````\n##  Degree (unnormalized):\n##                        Mixed diet Vegetarian\n##                Erwinia          6          6\n##            Citrobacter          4          0\n##               Serratia          4          3\n##          Streptococcus          3          0\n##                Pantoea          2          1\n##                            ______     ______\n##                Erwinia          6          6\n##              Aeromonas          1          5\n##   Escherichia/Shigella          2          5\n##            Siccibacter          0          5\n##             Salmonella          2          3\n##  \n##  Betweenness centrality (normalized):\n##                        Mixed diet Vegetarian\n##                Erwinia    0.60294    0.54737\n##               Serratia    0.41912        0.1\n##          Streptococcus    0.27941          0\n##           Enterobacter    0.24265          0\n##            Citrobacter    0.24265          0\n##                            ______     ______\n##                Erwinia    0.60294    0.54737\n##   Escherichia/Shigella    0.11765    0.53158\n##              Aeromonas          0    0.36842\n##            Siccibacter          0        0.3\n##          Thiolamprovum          0    0.20526\n##  \n##  Closeness centrality (normalized):\n##                        Mixed diet Vegetarian\n##                Erwinia    0.85251    0.80605\n##               Serratia    0.78452    0.56308\n##            Citrobacter    0.71265          0\n##           Enterobacter    0.64822    0.49217\n##          Streptococcus    0.61535          0\n##                            ______     ______\n##   Escherichia/Shigella    0.57246    0.80747\n##                Erwinia    0.85251    0.80605\n##              Aeromonas     0.4768    0.74282\n##            Siccibacter          0    0.72705\n##             Salmonella    0.57364    0.66777\n##  \n##  Eigenvector centrality (normalized):\n##                        Mixed diet Vegetarian\n##               Serratia          1    0.41577\n##                Erwinia    0.97703          1\n##            Citrobacter    0.80991          0\n##            Escherichia    0.60982          0\n##             Shewanella    0.41174     0.1238\n##                            ______     ______\n##                Erwinia    0.97703          1\n##   Escherichia/Shigella    0.38659    0.96856\n##            Siccibacter          0      0.888\n##              Aeromonas    0.26033    0.68516\n##             Salmonella     0.3153    0.64405\n\nFor each centrality measure, the five nodes with the highest centrality in each group are plotted by default.\nWe notice some differences in the network properties. The differential network analysis performed in the next section will show if the differences are significant."
  },
  {
    "objectID": "pages/61_network_comparison.html#differential-network-analysis",
    "href": "pages/61_network_comparison.html#differential-network-analysis",
    "title": "12¬† Network comparison",
    "section": "\n12.3 Differential network analysis",
    "text": "12.3 Differential network analysis\n\n12.3.1 Visual comparison\nWe start with a visual comparison of the two networks using NetCoMi‚Äôs plot function. The same configuration as in chapter Chapter¬†11 is used.\n\nplot(spring_netprops_diet,\n     repulsion = 0.97,\n     rmSingles = TRUE,\n     labelScale = FALSE,\n     nodeSize = \"eigenvector\",\n     nodeSizeSpread = 2,\n     nodeColor = \"cluster\", \n     sameColThresh = 2,\n     hubBorderCol = \"darkgray\",\n     cexNodes = 2,\n     edgeTranspHigh = 20,\n     title1 = \"Mixed diet\", \n     title2 = \"Vegetarian\",\n     showTitle = TRUE,\n     cexTitle = 2,\n     mar = c(1, 4, 4, 4))\n\n# Overlay a transparent plot on which the legend is plotted\npar(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 0, 0), new=TRUE)\nplot(0, 0, type='n', bty='n', xaxt='n', yaxt='n')\n\nlegend(-0.2, -0.9, cex = 1.5, title = \"estimated correlation:\",\n       legend = c(\"+\",\"-\"), lty = 1, lwd = 3, col = c(\"#009900\",\"red\"), \n       bty = \"n\", horiz = TRUE)\n\n\n\n\n\n\n\nThe layout is computed separately for each network, making it difficult to visually compare certain associations. It is therefore recommended to use the same layout for both groups (argument sameLayout). Instead of simply copying one layout to the other network, we set layoutGroup to ‚Äúunion‚Äù. This ensures that the nodes are placed as optimally as possible for both networks.\n\nplot(spring_netprops_diet,\n     sameLayout = TRUE,\n     repulsion = 0.95,\n     rmSingles = \"inboth\",\n     labelScale = FALSE,\n     nodeSize = \"eigenvector\",\n     nodeSizeSpread = 2,\n     nodeColor = \"cluster\", \n     sameColThresh = 2,\n     hubBorderCol = \"darkgray\",\n     cexNodes = 2,\n     edgeTranspHigh = 20,\n     title1 = \"Mixed diet\", \n     title2 = \"Vegetarian\",\n     showTitle = TRUE,\n     cexTitle = 2,\n     mar = c(1, 4, 4, 4))\n\n# Add legend\npar(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 0, 0), new=TRUE)\nplot(0, 0, type='n', bty='n', xaxt='n', yaxt='n')\nlegend(-0.2, -0.8, cex = 1.7, title = \"estimated correlation:\",\n       legend = c(\"+\",\"-\"), lty = 1, lwd = 3, col = c(\"#009900\",\"red\"), \n       bty = \"n\", horiz = TRUE)\n\n\n\n\n\n\n\nA few notes:\n\nDifferences in the edge weights can now be seen at first glance. For example, Serratia and Citrobacter are strongly associated in the mixed diet group, but not at all in the vegetarian group.\nClusters must share at least two nodes (sameColThresh argument) to be colored equally in both networks, which is why the color of some clusters differs between the groups.\nThe clustering generally differs markedly. In particular, the cluster assignment of many of the nodes in the largest connected component differs between the two groups.\n\nAs in Chapter Chapter¬†11, we also generate a network plot using phylum names to color the nodes and mclr-transformed abundances to scale node sizes.\n\nlibrary(RColorBrewer)\n\n\n# Generate vector with phylum names for node coloring\nphyla &lt;- as.factor(rowData(tse)$phylum)\nnames(phyla) &lt;- rowData(tse)$genus\n\n# Create color vector\ncolvec &lt;- RColorBrewer::brewer.pal(length(levels(phyla)), \"Set3\")\n\np_diet &lt;- plot(spring_netprops_diet,\n               sameLayout = TRUE,\n               repulsion = 0.95,\n               rmSingles = \"inboth\",\n               labelScale = FALSE,\n               nodeSize = \"clr\",\n               nodeColor = \"feature\", \n               featVecCol = phyla, \n               colorVec =  colvec,\n               nodeTransp = 20,\n               sameColThresh = 2,\n               highlightHubs = FALSE,\n               cexNodes = 2,\n               edgeTranspHigh = 20,\n               title1 = \"Mixed diet\", \n               title2 = \"Vegetarian\",\n               showTitle = TRUE,\n               cexTitle = 2,\n               mar = c(1, 4, 4, 4))\n\n# Add legends\n# Colors used in the legend should be equally transparent as in the plot\ncol_transp &lt;- colToTransp(colvec, 20)\n\npar(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 0, 0), new=TRUE)\nplot(0, 0, type='n', bty='n', xaxt='n', yaxt='n')\nlegend(-0.15, -0.8, cex = 1.7, title = \"estimated correlation:\",\n       legend = c(\"+\",\"-\"), lty = 1, lwd = 3, col = c(\"#009900\",\"red\"), \n       bty = \"n\", horiz = TRUE)\nlegend(-0.15, 1.3, cex = 1.7, pt.cex = 2.5, title = \"Phylum:\", \n       legend=levels(phyla), col = col_transp, bty = \"n\", pch = 16) \n\n\n\n\n\n\n\n\n12.3.2 Quantitative comparison\nnetCompare() enables a quantitative network comparison using comparative measures such as Jaccard‚Äôs Index, Adjusted Rand Index, and permutation tests.\nTo test for statistical significance of differences in network properties, we perform permutation tests with 1000 permutations. Multiple CPU cores are used to save run time. The association matrices estimated for all permutations are stored in an external file. We will reuse them later when performing differential association analysis. They could also be used to rerun netCompare() with different parameter settings.\nNote that unless running on a cluster with considerably more CPU cores, a network comparison with permutation tests may take several hours. You should test the code below with a small number of permutations to make sure it works before applying it to your data.\n\nspring_netcomp_diet &lt;- netCompare(spring_netprops_diet, \n                                  permTest = TRUE,\n                                  nPerm = 1000,\n                                  cores = 6,\n                                  seed = 13075,\n                                  storeAssoPerm = TRUE,\n                                  fileStoreAssoPerm = \"general/network_data/spring_assoPerm\",\n                                  verbose = TRUE)\n\n\nsummary(spring_netcomp_diet, \n        groupNames = c(\"Mixed diet\", \"Vegetarian\"),\n        numbNodes = 5)\n##  \n##  Comparison of Network Properties\n##  ----------------------------------\n##  CALL: \n##  netCompare(x = spring_netprops_diet, permTest = TRUE, verbose = TRUE, \n##      nPerm = 1000, cores = 19, libPathsClust = \"/dss/dsshome1/07/di93fen/R\", \n##      seed = 13075, storeAssoPerm = TRUE, fileStoreAssoPerm = \"general/network_data/spring_assoPerm\")\n##  \n##  ______________________________\n##  Global network properties\n##  `````````````````````````\n##  Largest connected component (LCC):\n##                           Mixed diet   Vegetarian    abs.diff.     p-value\n##  Relative LCC size             0.220        0.256        0.037    0.838162\n##  Clustering coefficient        0.104        0.224        0.120    0.450549\n##  Modularity                    0.515        0.477        0.038    0.801199\n##  Positive edge percentage     80.000      100.000       20.000    0.000999\n##  Edge density                  0.131        0.124        0.007    0.910090\n##  Natural connectivity          0.073        0.063        0.011    0.812188\n##  Vertex connectivity           1.000        1.000        0.000    1.000000\n##  Edge connectivity             1.000        1.000        0.000    1.000000\n##  Average dissimilarity*        0.960        0.962        0.001    0.945055\n##  Average path length**         2.228        2.246        0.019    0.984016\n##                              \n##  Relative LCC size           \n##  Clustering coefficient      \n##  Modularity                  \n##  Positive edge percentage ***\n##  Edge density                \n##  Natural connectivity        \n##  Vertex connectivity         \n##  Edge connectivity           \n##  Average dissimilarity*      \n##  Average path length**       \n##  \n##  Whole network:\n##                           Mixed diet   Vegetarian    abs.diff.     p-value\n##  Number of components         50.000       52.000        2.000     0.93706\n##  Clustering coefficient        0.075        0.165        0.090     0.46254\n##  Modularity                    0.752        0.668        0.084     0.24975\n##  Positive edge percentage     88.571      100.000       11.429     0.02398\n##  Edge density                  0.011        0.011        0.000     0.97303\n##  Natural connectivity          0.013        0.013        0.000     0.89011\n##                              \n##  Number of components        \n##  Clustering coefficient      \n##  Modularity                  \n##  Positive edge percentage *  \n##  Edge density                \n##  Natural connectivity        \n##  -----\n##  p-values: one-tailed test with null hypothesis diff=0\n##   *: Dissimilarity = 1 - edge weight\n##  **: Path length = Units with average dissimilarity\n##  \n##  ______________________________\n##  Jaccard index (similarity betw. sets of most central nodes)\n##  ```````````````````````````````````````````````````````````\n##                      Jacc   P(&lt;=Jacc)     P(&gt;=Jacc)    \n##  degree             0.560      0.9944       0.01637 *  \n##  betweenness centr. 0.294      0.4777       0.71860    \n##  closeness centr.   0.560      0.9944       0.01637 *  \n##  eigenvec. centr.   0.560      0.9944       0.01637 *  \n##  hub taxa           0.111      0.1431       0.97399    \n##  -----\n##  Jaccard index in [0,1] (1 indicates perfect agreement)\n##  \n##  ______________________________\n##  Adjusted Rand index (similarity betw. clusterings)\n##  ``````````````````````````````````````````````````\n##          wholeNet       LCC\n##  ARI        0.367     0.035\n##  p-value    0.000     0.563\n##  -----\n##  ARI in [-1,1] with ARI=1: perfect agreement betw. clusterings\n##                     ARI=0: expected for two random clusterings\n##  p-value: permutation test (n=1000) with null hypothesis ARI=0\n##  \n##  ______________________________\n##  Graphlet Correlation Distance\n##  `````````````````````````````\n##          wholeNet         LCC  \n##  GCD       1.5980      2.1770  \n##  p-value   0.4226      0.7143  \n##  -----\n##  GCD &gt;= 0 (GCD=0 indicates perfect agreement between GCMs)\n##  p-value: permutation test with null hypothesis GCD=0\n##  \n##  ______________________________\n##  Centrality measures\n##  - In decreasing order\n##  - Centrality of disconnected components is zero\n##  ````````````````````````````````````````````````\n##  Degree (unnormalized):\n##                       Mixed diet Vegetarian abs.diff. adj.p-value  \n##  Siccibacter                   0          5         5           1  \n##  Aeromonas                     1          5         4           1  \n##  Citrobacter                   4          0         4           1  \n##  Escherichia/Shigella          2          5         3           1  \n##  Streptococcus                 3          0         3           1  \n##  \n##  Betweenness centrality (normalized):\n##                       Mixed diet Vegetarian abs.diff. adj.p-value  \n##  Escherichia/Shigella      0.118      0.532     0.414           1  \n##  Aeromonas                 0.000      0.368     0.368           1  \n##  Serratia                  0.419      0.100     0.319           1  \n##  Siccibacter               0.000      0.300     0.300           1  \n##  Streptococcus             0.279      0.000     0.279           1  \n##  \n##  Closeness centrality (normalized):\n##                Mixed diet Vegetarian abs.diff. adj.p-value  \n##  Siccibacter        0.000      0.727     0.727      0.2676  \n##  Citrobacter        0.713      0.000     0.713      0.9799  \n##  Streptococcus      0.615      0.000     0.615      0.2676  \n##  Escherichia        0.587      0.000     0.587      0.9799  \n##  Xenorhabdus        0.000      0.527     0.527      0.2676  \n##  \n##  Eigenvector centrality (normalized):\n##                       Mixed diet Vegetarian abs.diff. adj.p-value  \n##  Siccibacter               0.000      0.888     0.888      0.6553  \n##  Citrobacter               0.810      0.000     0.810      1.0000  \n##  Escherichia               0.610      0.000     0.610      1.0000  \n##  Serratia                  1.000      0.416     0.584      1.0000  \n##  Escherichia/Shigella      0.387      0.969     0.582      1.0000  \n##  \n##  _________________________________________________________\n##  Significance codes: ***: 0.001, **: 0.01, *: 0.05, .: 0.1\n\nInterpreting some results:\n\nAlmost all global network properties are significantly different between the groups (for \\(\\alpha=0.1\\)), thus reflecting the different overall network structure we already have seen in the network plots.\nFor the Jaccard index of degree, closeness, and eigenvector centrality, the probability P(&gt;=Jacc) is significant, meaning that the sets of the most central nodes are quite similar for these three measures. The Jaccard index for the hub nodes, on the other hand, is low because the two networks share only one hub node (‚ÄúErwinia‚Äù).\nAs indicated by some similarities in the clusterings, the adjusted Rand index (ARI) of the whole network is significantly different from zero and thus from random clustering. The ARI of the largest connected component (LCC), however, is close to zero due to the different clusterings in the LCC.\nThe two GCD values are significantly different from zero, indicating substantial differences in the overall network structures.\nAll nodes are also tested for having significantly different centrality (only the five nodes with the highest absolute difference are shown in the summary). For \\(\\alpha=0.05\\), some nodes have a significantly different closeness centrality, and for \\(\\alpha=0.1\\) also a significantly different eigenvector centrality. Most of these nodes have a high centrality in the one group, but are not connected in the other group."
  },
  {
    "objectID": "pages/61_network_comparison.html#differential-association-analysis",
    "href": "pages/61_network_comparison.html#differential-association-analysis",
    "title": "12¬† Network comparison",
    "section": "\n12.4 Differential association analysis",
    "text": "12.4 Differential association analysis\nThe diffnet() function provides statistical tests to assess whether the associations themselves are significantly different between the two groups. NetCoMi also provides a plot function to generate a differential network, where two nodes are connected if they are differentially associated between the groups.\nSince we have already computed the permutation association matrices before, we can reuse them here (argument fileLoadAssoPerm).\nThe local false discovery rate is controlled at level 0.2 to account for multiplicity.\n\nspring_diffnet &lt;- diffnet(spring_net_diet,\n                          diffMethod = \"perm\",\n                          fileLoadAssoPerm = \"general/network_data/spring_assoPerm\",\n                          adjust = \"lfdr\")\n\n\nsum(spring_diffnet$pAdjustVec &lt; 0.05)\n##  [1] 0\nsum(spring_diffnet$pvalsVec &lt; 0.05)\n##  [1] 12\n\nSome of the unadjusted p-values are below the usual 5% significance level. However, none of the differences remain significant after adjusting for multiple testing so that the differential network would be empty.\nTo demonstrate the interpretation of a differential network, we set adjust to ‚Äúnone‚Äù, which is actually statistically incorrect.\n\nspring_diffnet_unadj &lt;- diffnet(spring_net_diet,\n                                pvalsVec = spring_diffnet$pvalsVec,\n                                diffMethod = \"perm\",\n                                alpha = 0.05,\n                                adjust = \"none\")\n\nThe diffnet object it now plotted using NetCoMi‚Äôs plot function.\n\nplot(spring_diffnet_unadj, \n     cexLabels = 2,\n     cexNodes = 0.7, \n     cexLegend = 2.5,\n     cexTitle = 3,\n     mar = c(3,2,5,15),\n     legendGroupnames = c(\"Mixed diet\", \"Vegetarian\"),\n     legendPos = c(1.2,1.5),\n     legendArgs = list(lwd = 4),\n     fade = FALSE)\n\n\n\n\n\n\n\nEdge colors represent the direction of the associations in the two groups. For example, if two OTUs are positively correlated in the mixed diet group and uncorrelated in the vegetarian group (such as Serratia and Citrobacter), the edge color is dark green."
  },
  {
    "objectID": "pages/61_network_comparison.html#sec-netcomp-methods",
    "href": "pages/61_network_comparison.html#sec-netcomp-methods",
    "title": "12¬† Network comparison",
    "section": "\n12.5 Network comparison methods",
    "text": "12.5 Network comparison methods\nWhile many approaches exist for the detection of differential correlations, e.g. (Yu et al. 2019; McKenzie et al. 2016; Siska and Kechris 2017), the literature on the more general case of differential association detection is scarce. Bhuva et al. (2019) compare various methods in a simulation study, which again includes many differential correlation approaches, but also more general methods such as latent differential graphical models. Gill, Datta, and Datta (2010) introduce an approach to analyze whether the connectivity of individual nodes is different between two groups using permutation tests, which is applicable to any kind of association. He et al. (2019) propose a test to infer the differential network structure for two conditional dependence networks.\n\nYu, Danyang, Zeyu Zhang, Kimberly Glass, Jessica Su, Dawn L. DeMeo, Kelan Tantisira, Scott T. Weiss, and Weiliang Qiu. 2019. ‚ÄúNew Statistical Methods for Constructing Robust Differential Correlation Networks to characterize the interactions among microRNAs.‚Äù Scientific Reports 9 (1): 1‚Äì12. https://doi.org/10.1038/s41598-019-40167-8.\n\nMcKenzie, Andrew T., Igor Katsyv, Won Min Song, Minghui Wang, and Bin Zhang. 2016. ‚ÄúDGCA: A comprehensive R package for Differential Gene Correlation Analysis.‚Äù BMC Systems Biology 10 (1): 1‚Äì25. https://doi.org/10.1186/s12918-016-0349-1.\n\nSiska, Charlotte, and Katerina Kechris. 2017. ‚ÄúDifferential correlation for sequencing data.‚Äù BMC Research Notes 10 (1): 1‚Äì9. https://doi.org/10.1186/s13104-016-2331-9.\n\nBhuva, Dharmesh D., Joseph Cursons, Gordon K. Smyth, and Melissa J. Davis. 2019. ‚ÄúDifferential co-expression-based detection of conditional relationships in transcriptional data: comparative analysis and application to breast cancer.‚Äù Genome Biology 20 (1). https://doi.org/10.1186/S13059-019-1851-8.\n\nGill, Ryan, Somnath Datta, and Susmita Datta. 2010. ‚ÄúA statistical framework for differential network analysis from microarray data.‚Äù BMC Bioinformatics 11 (1): 95.\n\nHe, Hao, Shaolong Cao, Ji gang Zhang, Hui Shen, Yu Ping Wang, and Hong wen Deng. 2019. ‚ÄúA Statistical Test for Differential Network Analysis Based on Inference of Gaussian Graphical Model.‚Äù Scientific Reports 9 (1): 1‚Äì8. https://doi.org/10.1038/s41598-019-47362-7.\n\nShojaie, Ali. 2021. ‚ÄúDifferential network analysis: A statistical perspective.‚Äù Wiley Interdisciplinary Reviews: Computational Statistics 13 (2): e1508. https://doi.org/10.1002/WICS.1508.\n\nLichtblau, Yvonne, Karin Zimmermann, Berit Haldemann, Dido Lenze, Michael Hummel, and Ulf Leser. 2017. ‚ÄúComparative assessment of differential network analysis methods.‚Äù Briefings in Bioinformatics 18 (5): 837‚Äì50. https://doi.org/10.1093/bib/bbw061.\n\nJardim, Vin√≠cius Carvalho, Suzana De Siqueira Santos, Andre Fujita, and Marcos Silveira Buckeridge. 2019. ‚ÄúBioNetStat: A tool for biological networks differential analysis.‚Äù Frontiers in Genetics 10 (JUN): 1‚Äì13. https://doi.org/10.3389/fgene.2019.00594.\nPerforming differential network analysis is challenging because network measures do not follow classical statistical distributions. Shojaie (2021) provide an overview of differential network analysis methods, but focus only on changes in edge sets. Lichtblau et al. (2017) compare differential network analysis methods that incorporate multiple local and global network measures. Jardim et al. (2019) present a tool ‚ÄúBioNetStat‚Äù for differential analysis of biological networks, which is able to compare certain network measures between groups.\nThe NetCoMi package used for network comparison in this chapter includes the following differential network analysis approaches::\n\n\nPermutation approach to test global network measures (e.g., transitivity, connectivity, or average path length) as well as centrality measures for group differences.\n\nJaccard index to assess the similarity between sets of most central nodes\n\nAdjusted Rand index to assess the similarity between clusterings\n\nGraphlet Correlation Distance (GCM)\n\nSee (Peschel et al. 2021) for an explanation of the first three approaches. The GCM was proposed by Yaveroƒülu et al. (2014).\n\nPeschel, Stefanie, Christian L M√ºller, Erika von Mutius, Anne-Laure Boulesteix, and Martin Depner. 2021. ‚ÄúNetCoMi: network construction and comparison for microbiome data in R.‚Äù Briefings in Bioinformatics 22 (4): bbaa290. https://doi.org/10.1093/bib/bbaa290.\n\nYaveroƒülu, √ñmer Nebil, No√´l Malod-Dognin, Darren Davis, Zoran Levnajic, Vuk Janjic, Rasa Karapandza, Aleksandar Stojmirovic, and Nata≈°a Pr≈æulj. 2014. ‚ÄúRevealing the Hidden Language of Complex Networks.‚Äù Scientific Reports 4 (1): 1‚Äì9. https://doi.org/10.1038/srep04547.\n\nFisher, Ronald Aylmer. 1970. ‚ÄúStatistical Methods for Research Workers.‚Äù In Breakthroughs in statistics: Methodology and distribution, 66‚Äì70. Springer.\n\nSiska, Charlotte, Russell Bowler, and Katerina Kechris. 2016. ‚ÄúThe discordant method: A novel approach for differential correlation.‚Äù Bioinformatics 32 (5): 690‚Äì96. https://doi.org/10.1093/bioinformatics/btv633.\nTwo methods (Fisher‚Äôs z-test (Fisher 1970) and the Discordant method (Siska, Bowler, and Kechris 2016)) are available for identifying differential correlations, and permutation tests for the more general case of identifying differential associations. See (Peschel et al. 2021) for details. NetCoMi offers also a function for plotting a differential network."
  },
  {
    "objectID": "pages/40_machine_learning.html#supervised-machine-learning",
    "href": "pages/40_machine_learning.html#supervised-machine-learning",
    "title": "13¬† Machine Learning",
    "section": "\n13.1 Supervised machine learning",
    "text": "13.1 Supervised machine learning\n‚ÄúSupervised‚Äù means that the training data is introduced before. The training data contains labels (e.g., patient status), and the model is fitted based on the training data. After fitting, the model is utilized to predict labels of data whose labels are not known.\n\nlibrary(mia)\n\n# Load experimental data\ndata(peerj13075, package=\"mia\")\ntse &lt;- peerj13075\n\nLet‚Äôs first preprocess the data.\n\n# Agglomerate data\ntse &lt;- mergeFeaturesByRank(tse, rank = \"order\")\n\n# Apply CLR transform\ntse &lt;- transformAssay(tse, assay.type = \"counts\", method = \"clr\",\n                       MARGIN=\"samples\", pseudocount=1)\n\n# Get assay\nassay &lt;- assay(tse, \"clr\")\n# Transpose assay\nassay &lt;- t(assay)\n\n# Convert into data.frame\ndf &lt;- as.data.frame(assay)\n\n# Add labels to assay\nlabels &lt;- colData(tse)$Diet\nlabels &lt;- as.factor(labels)\ndf$diet &lt;- labels \n\ndf[5, 5]\n##  [1] -0.4612\n\nIn the example below, we use mikropml package. We try to predict the diet type based on the data.\n\nlibrary(mikropml)\n\n# Run random forest \nresults &lt;- run_ml(df, \"rf\", outcome_colname = \"diet\", \n                  kfold = 2, cv_times = 5, training_frac = 0.8)\n\n# Print result\nconfusionMatrix(data = results$trained_model$finalModel$predicted, \n                reference = results$trained_model$finalModel$y)\n##  Confusion Matrix and Statistics\n##  \n##            Reference\n##  Prediction Mixed Veg\n##       Mixed    10  13\n##       Veg      13  11\n##                                          \n##                 Accuracy : 0.447         \n##                   95% CI : (0.302, 0.599)\n##      No Information Rate : 0.511         \n##      P-Value [Acc &gt; NIR] : 0.846         \n##                                          \n##                    Kappa : -0.107        \n##                                          \n##   Mcnemar's Test P-Value : 1.000         \n##                                          \n##              Sensitivity : 0.435         \n##              Specificity : 0.458         \n##           Pos Pred Value : 0.435         \n##           Neg Pred Value : 0.458         \n##               Prevalence : 0.489         \n##           Detection Rate : 0.213         \n##     Detection Prevalence : 0.489         \n##        Balanced Accuracy : 0.447         \n##                                          \n##         'Positive' Class : Mixed         \n##  \n\nmikropml offers easier interface to caret package. However, we can also use it directly.\nLet‚Äôs use xgboost model which is another commonly used algorithm in bioinformatics.\n\n# Set seed for reproducibility\nset.seed(6358)\n\n# Specify train control\ntrain_control &lt;- trainControl(method = \"cv\", number = 5,\n                              classProbs = TRUE, \n                              savePredictions = \"final\",\n                              allowParallel = TRUE)\n\n# Specify hyperparameter tuning grid\ntune_grid &lt;- expand.grid(nrounds = c(50, 100, 200),\n                         max_depth = c(6, 8, 10),\n                         colsample_bytree = c(0.6, 0.8, 1),\n                         eta = c(0.1, 0.3),\n                         gamma = 0,\n                         min_child_weight = c(3, 4, 5),\n                         subsample = c(0.6, 0.8)\n                         )\n\n# Train the model, use LOOCV to evaluate performance\nmodel &lt;- train(x = assay, \n               y = labels, \n               method = \"xgbTree\",\n               objective = \"binary:logistic\",\n               trControl = train_control,\n               tuneGrid = tune_grid,\n               metric = \"AUC\",\n               verbosity = 0\n)\n\nLet‚Äôs create ROC curve which is a commonly used method in binary classification. For unbalanced data, you might want to plot precision-recall curve.\n\nlibrary(MLeval)\n\n# Calculate different evaluation metrics\nres &lt;- evalm(model, showplots = FALSE)\n\n# Use patchwork to plot ROC and precision-recall curve side-by-side\nlibrary(patchwork)\nres$roc + res$proc + \n    plot_layout(guides = \"collect\") & theme(legend.position = 'bottom')"
  },
  {
    "objectID": "pages/40_machine_learning.html#unsupervised-machine-learning",
    "href": "pages/40_machine_learning.html#unsupervised-machine-learning",
    "title": "13¬† Machine Learning",
    "section": "\n13.2 Unsupervised machine learning",
    "text": "13.2 Unsupervised machine learning\n‚ÄúUnsupervised‚Äù means that the labels (e.g., patient status is not known), and patterns are learned based only the abundance table, for instance. Unsupervised ML is also known as a data mining where patterns are extracted from big datasets.\nFor unsupervised machine learning, please refer to chapters that are listed below:\n\nChapter Chapter¬†9\n\nChapter Chapter¬†7"
  },
  {
    "objectID": "pages/23_multi-assay_analyses.html#sec-cross-correlation",
    "href": "pages/23_multi-assay_analyses.html#sec-cross-correlation",
    "title": "14¬† Multi-Assay Analyses",
    "section": "\n14.1 Cross-correlation Analysis",
    "text": "14.1 Cross-correlation Analysis\nNext we can perform a cross-correlation analysis. Let us analyze if individual bacteria genera are correlated with concentrations of individual metabolites. This helps to answer the following question: ‚ÄúIf bacterium X is present, is the concentration of metabolite Y lower or higher‚Äù?\n\n# Agglomerate microbiome data at family level\nmae[[1]] &lt;- mergeFeaturesByPrevalence(mae[[1]], rank = \"Family\")\n# Does log10 transform for microbiome data\nmae[[1]] &lt;- transformAssay(mae[[1]], method = \"log10\", pseudocount = TRUE)\n\n# Give unique names so that we do not have problems when we are creating a plot\nrownames(mae[[1]]) &lt;- getTaxonomyLabels(mae[[1]])\n\n# Cross correlates data sets\ncorrelations &lt;- testExperimentCrossCorrelation(mae, \n                                               experiment1 = 1,\n                                               experiment2 = 2,\n                                               assay.type1 = \"log10\", \n                                               assay.type2 = \"nmr\",\n                                               method = \"spearman\", \n                                               p_adj_threshold = NULL,\n                                               cor_threshold = NULL,\n                                               # Remove when mia is fixed\n                                               mode = \"matrix\",\n                                               sort = TRUE,\n                                               show_warnings = FALSE)\n\nNext, we create a heatmap depicting all cross-correlations between bacterial genera and metabolite concentrations.\n\nlibrary(ComplexHeatmap) \n\n# Create a heatmap and store it\nplot &lt;- Heatmap(correlations$cor,\n                # Print values to cells\n                cell_fun = function(j, i, x, y, width, height, fill) {\n                    # If the p-value is under threshold\n                    if( !is.na(correlations$p_adj[i, j]) & correlations$p_adj[i, j] &lt; 0.05 ){\n                        # Print \"X\"\n                        grid.text(sprintf(\"%s\", \"X\"), x, y, gp = gpar(fontsize = 10, col = \"#1dff00\"))\n                        }\n                    },\n                heatmap_legend_param = list(title = \"\", legend_height = unit(5, \"cm\"))\n                )\nplot"
  },
  {
    "objectID": "pages/23_multi-assay_analyses.html#sec-mofa",
    "href": "pages/23_multi-assay_analyses.html#sec-mofa",
    "title": "14¬† Multi-Assay Analyses",
    "section": "\n14.2 Multi-Omics Factor Analysis",
    "text": "14.2 Multi-Omics Factor Analysis\nMulti-Omics Factor Analysis (MOFA) is an unsupervised method for integrating multi-omic data sets in a downstream analysis (Argelaguet 2018). It could be seen as a generalization of principal component analysis. Yet, with the ability to infer a latent (low-dimensional) representation, shared among the multiple (-omics) data sets in hand.\n\nArgelaguet, Ricard et al. 2018. ‚ÄúMulti-Omics Factor Analysis‚Äîa Framework for Unsupervised Integration of Multi-Omics Data Sets.‚Äù Molecular Systems Biology 14 (6): e8124. https://doi.org/10.15252/msb.20178124.\nWe use the R MOFA2 package for the analysis, and install the corresponding dependencies.\n\nlibrary(MOFA2)\n\n# For inter-operability between Python and R, and setting Python dependencies,\n# reticulate package is needed\nlibrary(reticulate)\n# Let us assume that these have been installed already.\n#reticulate::install_miniconda(force = TRUE)\n#reticulate::use_miniconda(condaenv = \"env1\", required = FALSE)\n#reticulate::py_install(packages = c(\"mofapy2\"), pip = TRUE, python_version=3.6)\n\nThe mae object could be used straight to create the MOFA model. Yet, we transform our assays since the model assumes normality per default. We can also use Poisson or Bernoulli distributions among others.\nNote that duplicates, such as ‚Äúuncultured‚Äù, might appear when aggregating the microbiome data by a taxonomic rank. To check for duplicates, run any(duplicated(rownames(mae[[1]]))). If it returns TRUE, then the duplicates are present. We can add rownames(mae[[1]]) &lt;- getTaxonomyLabels(mae[[1]], make_unique=TRUE) to remove them.\n\nlibrary(MOFA2)\n# For simplicity, classify all high-fat diets as high-fat, and all the low-fat \n# diets as low-fat diets\ncolData(mae)$Diet &lt;- ifelse(colData(mae)$Diet == \"High-fat\" | \n                              colData(mae)$Diet == \"High-fat + XOS\", \n                            \"High-fat\", \"Low-fat\")\n\n# Transforming microbiome data with rclr\nmae[[1]] &lt;- transformAssay(mae[[1]], method = \"relabundance\")\nmae[[1]] &lt;- transformAssay(mae[[1]], assay.type = \"relabundance\", method = \"rclr\")\n\n# Transforming metabolomic data with log10\nmae[[2]] &lt;- transformAssay(mae[[2]], assay.type = \"nmr\",\n                            MARGIN = \"samples\",\n                            method = \"log10\")\n\n# Transforming biomarker data with z-transform\nmae[[3]] &lt;- transformAssay(mae[[3]], assay.type = \"signals\",\n                           MARGIN = \"features\",\n                           method = \"z\", pseudocount = 1)\n\n# Removing assays no longer needed\nassay(mae[[1]], \"counts\") &lt;- NULL\nassay(mae[[1]], \"log10\") &lt;- NULL\nassay(mae[[2]], \"nmr\") &lt;- NULL\nassay(mae[[3]], \"signals\") &lt;- NULL\n\n# Building our mofa model\nmodel &lt;- create_mofa_from_MultiAssayExperiment(mae,\n                                               groups = \"Diet\", \n                                               extract_metadata = TRUE)\nmodel\n\nModel options can be defined as follows:\n\nmodel_opts &lt;- get_default_model_options(model)\nmodel_opts$num_factors &lt;- 5\nhead(model_opts)\n\nTraining options for the model are defined in the following way:\n\ntrain_opts &lt;- get_default_training_options(model)\nhead(train_opts)\n\nThe model is then prepared with prepare_mofa and trained with run_mofa:\n\nmodel.prepared &lt;- prepare_mofa(\n  object = model,\n  model_options = model_opts\n)\n\n# Some systems may require the specification `use_basilisk = TRUE`\n# so it has been added to the following code\nmodel.trained &lt;- run_mofa(model.prepared, use_basilisk = TRUE)\n\nThe explained variance is visualized with the plot_variance_explained function:\n\nlibrary(patchwork)\nlibrary(ggplot2)\n\nplot_list &lt;- plot_variance_explained(model.trained,\n                                     x = \"view\", y = \"factor\",\n                                     plot_total = T)\n\nwrap_plots(plot_list, nrow = 2) +\n  plot_annotation(title = \"Variance Explained per factor and assay\",\n                  theme = theme(plot.title = element_text(hjust = 0.5)))\n\nThe top weights for each assay using all five factors:\n\ncustom_plotter &lt;- function(name) {\n  \n  p &lt;- plot_top_weights(model.trained,\n                        view = name,\n                        factors = \"all\",\n                        nfeatures = 10) +\n    labs(title = paste0(\"Top weights of the \", name, \" assay\"))\n  \n}\n\nplot_list &lt;- lapply(c(\"microbiota\", \"metabolites\", \"biomarkers\"), custom_plotter)\n\nwrap_plots(plot_list, nrow = 3) & theme(text = element_text(size = 8))\n\nMore tutorials and examples of using the package are found at link"
  },
  {
    "objectID": "pages/19_visualization_techniques.html#pre-analysis-exploration",
    "href": "pages/19_visualization_techniques.html#pre-analysis-exploration",
    "title": "15¬† Visualization",
    "section": "\n15.1 Pre-analysis exploration",
    "text": "15.1 Pre-analysis exploration\n\n15.1.1 Accessing row and column data\nSCE and TreeSE objects contain multiple layers of information in the form of rows, columns and meta data. The scater package supports in accessing, modifying and graphing the meta data related to features as well as samples.\n\n# list row meta data\nnames(rowData(tse))\n##  [1] \"Kingdom\" \"Phylum\"  \"Class\"   \"Order\"   \"Family\"  \"Genus\"   \"Species\"\n# list column meta data\nnames(colData(tse))\n##  [1] \"X.SampleID\"               \"Primer\"                  \n##  [3] \"Final_Barcode\"            \"Barcode_truncated_plus_T\"\n##  [5] \"Barcode_full_length\"      \"SampleType\"              \n##  [7] \"Description\"\n\nSuch meta data can be directly plotted with the functions plotRowData and plotColData.\n\n# obtain QC data\ntse &lt;- addPerCellQC(tse)\ntse &lt;- addPerFeatureQC(tse)\n# plot QC Mean against Species\nplotRowData(tse, \"mean\", \"Species\") +\n  theme(axis.text.x = element_blank()) +\n  labs(x = \"Species\", y = \"QC Mean\")\n\n\n\n\n\n\n# plot QC Sum against Sample ID, colour-labeled by Sample Type\nplotColData(tse, \"sum\", \"X.SampleID\", colour_by = \"SampleType\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(x = \"Sample ID\", y = \"QC Sum\")\n\n\n\n\n\n\n\nAlternatively, they can be converted to a data.frame object and passed to ggplot.\n\n# store colData into a data frame\ncoldata &lt;- as.data.frame(colData(tse))\n# plot Number of Samples against Sampling Site\nggplot(coldata, aes(x = SampleType)) +\n  geom_bar(width = 0.5) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(x = \"Sampling Site\",\n       y = \"Number of Samples\")\n\n\n\n\n\n\n\nFurther methods of application can be found in the chapters Section¬†4.3 and Section¬†6.1.1 and in a few external tutorials with open data. Additionally, rowData and colData allow manipulation and subsetting of large data sets into smaller units, as explained in chapter Chapter¬†3.\n\n15.1.2 Viewing abundance and prevalence patterns\nPrior-to-analysis exploration may involve questions such as how microorganisms are distributed across samples (abundance) and what microorganisms are present in most of the samples (prevalence). The information on abundance and prevalence can be summarized into a jitter or density plot and a tree, respectively, with the miaViz package.\nSpecifically, the functions plotAbundance, plotAbundanceDensity and plotRowTree are used, and examples on their usage are discussed throughout chapter Chapter¬†4."
  },
  {
    "objectID": "pages/19_visualization_techniques.html#diversity-estimation",
    "href": "pages/19_visualization_techniques.html#diversity-estimation",
    "title": "15¬† Visualization",
    "section": "\n15.2 Diversity estimation",
    "text": "15.2 Diversity estimation\nAlpha diversity is commonly measured as one of the diversity indices explained in chapter Chapter¬†6. Because the focus lies on each sample separately, one-dimensional plots, such as scatter, violin and box plots, are suitable.\nBeta diversity is generally evaluated as one of the dissimilarity indices reported in chapter Chapter¬†7. Unlike alpha diversity, samples are compared collectively to estimate the heterogeneity across them, therefore multidimensional plots, such as Shepard and ordination plots are suitable.\n\n\n\n\n\n\n\n\nalpha diversity\nbeta diversity\n\n\n\nused metrics\ndiversity indices\ndissimilarity indices\n\n\nmetric dimensionality\none-dimensional\nmultidimensional\n\n\nsuitable visualization\nscatter, violin, box plots\nShepard, ordination plots\n\n\n\nIn conclusion, visualization techniques for alpha and beta diversity significantly differ from one another.\n\n15.2.1 Alpha diversity with scatter, violin and box plots\nThe basic method to visualize the diversity values assigned to the different samples in a TSE object includes the following, where each data point represents one sample:\n\n# estimate shannon diversity index\ntse &lt;- mia::estimateDiversity(tse, \n                              assay.type = \"counts\",\n                              index = \"shannon\", \n                              name = \"shannon\")\n# plot shannon diversity index, colour-labeled by Sample Type\nplotColData(tse, \"shannon\", colour_by = \"SampleType\")\n\n\n\n\n\n\n\nThe several indices available for the evaluation of alpha diversity often return slightly divergent results, which can be visually compared with a multiple violin or box plot. For this purpose, plotColData (for violin plots) or ggplot (for box plots) are recursively applied to a number of diversity indices with the function lapply and the multi-panel plotting functionality of the patchwork package is then exploited.\n\n# estimate faith diversity index\ntse &lt;- mia::estimateFaith(tse,\n                          assay.type = \"counts\")\n# store colData into a data frame\ncoldata &lt;- as.data.frame(colData(tse))\n# generate plots for shannon and faith indices\n# and store them into a list\nplots &lt;- lapply(c(\"shannon\", \"faith\"),\n                function(i) ggplot(coldata, aes_string(y = i)) +\n                  geom_boxplot() +\n                  theme(axis.text.x = element_blank(),\n                        axis.ticks.x = element_blank()))\n# combine plots with patchwork\nplots[[1]] + plots[[2]]\n\n\n\n\n\n\n\nThe analogous output in the form of a violin plot is obtained in chapter Section¬†6.1.3. In addition, box plots that group samples according to certain information, such as origin, sex, age and health condition, can be labeled with p-values for significant differences with the package ggsignif package, as shown in chapter Section¬†6.1.2.\n\n15.2.2 Beta diversity with Shepard and coordination plots\nThe scater package offers the general function plotReducedDim. In its basic form, it takes a TSE object and the results on sample similarity stored in the same object, which can be evaluated with the following coordination methods:\n\nrunMDS\nrunNMDS\nrunPCA\nrunTSNE\nrunUMAP\n\nSince these clustering techniques allow for multiple coordinates or components, coordination plots can also span multiple dimensions, which is explained in chapter Appendix¬†A.\n\n# perform NMDS coordination method\ntse &lt;- runNMDS(tse,\n               FUN = vegan::vegdist,\n               name = \"NMDS\")\n##  initial  value 47.733208 \n##  iter   5 value 33.853364\n##  iter  10 value 32.891200\n##  final  value 32.823570 \n##  converged\n# plot results of a 2-component NMDS on tse,\n# coloured-scaled by shannon diversity index\nplotReducedDim(tse, \"NMDS\", colour_by = \"shannon\")\n\n\n\n\n\n\n\nMultiple combinations of coordinates or dimensions can also be integrated into a multi-panel arrangement.\n\n# perform MDS coordination method\ntse &lt;- runMDS(tse,\n              FUN = vegan::vegdist,\n              method = \"bray\",\n              name = \"MDS\",\n              assay.type = \"counts\",\n              ncomponents = 3)\n# plot results of a 3-component MDS on tse,\n# coloured-scaled by faith diversity index\nplotReducedDim(tse, \"MDS\", ncomponents = c(1:3), colour_by = \"faith\")\n\n\n\n\n\n\n\nSimilarly to iterating plotColData over indices of alpha diversity, lapply can be used in combination with patchwork to recursively apply plotReducedDim and visually compare results among various coordination methods.\n\n# generate plots for MDS and NMDS methods\n# and store them into a list\nplots &lt;- lapply(c(\"MDS\", \"NMDS\"),\n                plotReducedDim,\n                object = tse,\n                colour_by = \"shannon\")\n# combine plots with patchwork\nplots[[1]] + plots[[2]] +\n  plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\nFor similar examples, readers are referred to chapter Chapter¬†7. Further material on the graphic capabilities of patchwork is available in its official package tutorial."
  },
  {
    "objectID": "pages/19_visualization_techniques.html#statistical-analysis",
    "href": "pages/19_visualization_techniques.html#statistical-analysis",
    "title": "15¬† Visualization",
    "section": "\n15.3 Statistical analysis",
    "text": "15.3 Statistical analysis\n\n15.3.1 Heatmaps\nAs described in chapter Section¬†8.1, bar plots and heatmaps can offer a useful insight into the composition of a community. Simple methods involve the functions plotAbundance and geom_tile in combination with scale_fill_gradientn from the packages miaViz and ggplot2, respectively.\nFor instance, below the composition of multiple samples (x axis) is reported in terms of relative abundances (y axis) for the top 10 taxa at the Order rank. Bar plots and heatmaps with analogous information at the Phylum level are available in the aforementioned chapter.\n\n# agglomerate tse by Order\ntse_order &lt;- mergeFeaturesByRank(tse,\n                                rank = \"Order\",\n                                onRankOnly = TRUE)\n# transform counts into relative abundance\ntse_order &lt;- transformAssay(tse_order,\n                              assay.type = \"counts\",\n                              method = \"relabundance\")\n# get top orders\ntop_taxa &lt;- getTopFeatures(tse_order,\n                       top = 10,\n                       assay.type = \"relabundance\")\n# leave only names for top 10 orders and label the rest with \"Other\"\norder_renamed &lt;- lapply(rowData(tse_order)$Order,\n                   function(x){if (x %in% top_taxa) {x} else {\"Other\"}})\nrowData(tse_order)$Order &lt;- as.character(order_renamed)\n# plot composition as a bar plot\nplotAbundance(tse_order,\n              assay.type = \"relabundance\",\n              rank = \"Order\",\n              order_rank_by = \"abund\",\n              order_sample_by = \"Clostridiales\")\n\n\n\n\n\n\n\nTo add a sample annotation, you can combine plots that you get from the output of plotAbundance.\n\n# Create plots\nplots &lt;- plotAbundance(tse_order,\n            assay.type = \"relabundance\",\n        rank = \"Order\",\n            order_rank_by = \"abund\",\n        order_sample_by = \"Clostridiales\",\n            features = \"SampleType\")\n\n# Modify the legend of the first plot to be smaller \nplots[[1]] &lt;- plots[[1]] +\n    theme(legend.key.size = unit(0.3, 'cm'),\n          legend.text = element_text(size = 6),\n          legend.title = element_text(size = 8))\n\n# Modify the legend of the second plot to be smaller \nplots[[2]] &lt;- plots[[2]] +\n    theme(legend.key.height = unit(0.3, 'cm'),\n          legend.key.width = unit(0.3, 'cm'),\n          legend.text = element_text(size = 6),\n          legend.title = element_text(size = 8),\n          legend.direction = \"vertical\")\n\n# Load required packages\nlibrary(ggpubr)\nlibrary(patchwork) \n# Combine legends\nlegend &lt;- wrap_plots(as_ggplot(get_legend(plots[[1]])), as_ggplot(get_legend(plots[[2]])), ncol = 1) \n\n# Remove legends from the plots\nplots[[1]] &lt;- plots[[1]] + theme(legend.position = \"none\")\nplots[[2]] &lt;- plots[[2]] + theme(legend.position = \"none\", axis.title.x=element_blank()) \n\n# Combine plots\nplot &lt;- wrap_plots(plots[[2]], plots[[1]], ncol = 1, heights = c(2, 10))\n# Combine the plot with the legend\nwrap_plots(plot, legend, nrow = 1, widths = c(2, 1))\n\n\n\n\n\n\n\nFor more sophisticated visualizations than those produced with plotAbundance and ggplot2, the packages pheatmap and sechm provide methods to include feature and sample clusters in a heatmap, along with further functionality.\n\n# Agglomerate tse by phylum\ntse_phylum &lt;- mergeFeaturesByRank(tse,\n                                rank = \"Phylum\",\n                                onRankOnly = TRUE)\n\n# Add clr-transformation on samples\ntse_phylum &lt;- transformAssay(tse_phylum, MARGIN = \"samples\", method = \"clr\", assay.type = \"counts\", pseudocount=1)\n\n# Add z-transformation on features (taxa)\ntse_phylum &lt;- transformAssay(tse_phylum, assay.type = \"clr\",\n                              MARGIN = \"features\", \n                              method = \"z\", name = \"clr_z\")\n\n# Take subset: only samples from feces, skin, or tongue\ntse_phylum_subset &lt;- tse_phylum[ , tse_phylum$SampleType %in% c(\"Feces\", \"Skin\", \"Tongue\") ]\n\n# Add clr-transformation\ntse_phylum_subset &lt;- transformAssay(tse_phylum_subset, method = \"clr\",\n                                     MARGIN=\"samples\",\n                                     assay.type = \"counts\", pseudocount=1)\n# Does z-transformation\ntse_phylum_subset &lt;- transformAssay(tse_phylum_subset, assay.type = \"clr\",\n                                     MARGIN = \"features\", \n                                     method = \"z\", name = \"clr_z\")\n\n# Get n most abundant taxa, and subsets the data by them\ntop_taxa &lt;- getTopFeatures(tse_phylum_subset, top = 20)\ntse_phylum_subset &lt;- tse_phylum_subset[top_taxa, ]\n\n# Gets the assay table\nmat &lt;- assay(tse_phylum_subset, \"clr_z\")\n\n# Creates the heatmap\npheatmap(mat)\n\n\n\n\n\n\n\nWe can cluster both samples and features hierarchically and add them to the x and y axes of the heatmap, respectively.\n\n# Hierarchical clustering\ntaxa_hclust &lt;- hclust(dist(mat), method = \"complete\")\n\n# Creates a phylogenetic tree\ntaxa_tree &lt;- as.phylo(taxa_hclust)\n\n# Plot taxa tree\ntaxa_tree &lt;- ggtree(taxa_tree) + \n  theme(plot.margin=margin(0,0,0,0)) # removes margins\n\n# Get order of taxa in plot\ntaxa_ordered &lt;- get_taxa_name(taxa_tree)\n\n# to view the tree, run\n# taxa_tree\n\nBased on phylo tree, we decide to create three clusters.\n\n# Creates clusters\ntaxa_clusters &lt;- cutree(tree = taxa_hclust, k = 3)\n\n# Converts into data frame\ntaxa_clusters &lt;- data.frame(clusters = taxa_clusters)\ntaxa_clusters$clusters &lt;- factor(taxa_clusters$clusters)\n\n# Order data so that it's same as in phylo tree\ntaxa_clusters &lt;- taxa_clusters[taxa_ordered, , drop = FALSE] \n\n# Prints taxa and their clusters\ntaxa_clusters\n##                   clusters\n##  Chloroflexi             3\n##  Actinobacteria          3\n##  Crenarchaeota           3\n##  Planctomycetes          3\n##  Gemmatimonadetes        3\n##  Thermi                  3\n##  Acidobacteria           3\n##  Spirochaetes            2\n##  Fusobacteria            2\n##  SR1                     2\n##  Cyanobacteria           2\n##  Proteobacteria          2\n##  Synergistetes           2\n##  Lentisphaerae           1\n##  Bacteroidetes           1\n##  Verrucomicrobia         1\n##  Tenericutes             1\n##  Firmicutes              1\n##  Euryarchaeota           1\n##  SAR406                  1\n\nThe information on the clusters is then added to the feature meta data.\n\n# Adds information to rowData\nrowData(tse_phylum_subset)$clusters &lt;- taxa_clusters[order(match(rownames(taxa_clusters), rownames(tse_phylum_subset))), ]\n\n# Prints taxa and their clusters\nrowData(tse_phylum_subset)$clusters\n##   [1] 1 1 2 3 2 2 1 1 1 1 3 2 3 3 3 2 2 3 3 1\n##  Levels: 1 2 3\n\nSimilarly, samples are hierarchically grouped into clusters, the most suitable number of clusters for the plot is selected and the new information is stored into the sample meta data.\n\n# Hierarchical clustering\nsample_hclust &lt;- hclust(dist(t(mat)), method = \"complete\")\n\n# Creates a phylogenetic tree\nsample_tree &lt;- as.phylo(sample_hclust)\n\n# Plot sample tree\nsample_tree &lt;- ggtree(sample_tree) + layout_dendrogram() + \n  theme(plot.margin=margin(0,0,0,0)) # removes margins\n\n# Get order of samples in plot\nsamples_ordered &lt;- rev(get_taxa_name(sample_tree))\n\n# to view the tree, run\n# sample_tree\n\n# Creates clusters\nsample_clusters &lt;- factor(cutree(tree = sample_hclust, k = 3))\n\n# Converts into data frame\nsample_data &lt;- data.frame(clusters = sample_clusters)\n\n# Order data so that it's same as in phylo tree\nsample_data &lt;- sample_data[samples_ordered, , drop = FALSE] \n\n# Order data based on \ntse_phylum_subset &lt;- tse_phylum_subset[ , rownames(sample_data)]\n\n# Add sample type data\nsample_data$sample_types &lt;- unfactor(colData(tse_phylum_subset)$SampleType)\n\nsample_data\n##          clusters sample_types\n##  M11Plmr        2         Skin\n##  M31Plmr        2         Skin\n##  F21Plmr        2         Skin\n##  M31Fcsw        1        Feces\n##  M11Fcsw        1        Feces\n##  TS28           3        Feces\n##  TS29           3        Feces\n##  M31Tong        3       Tongue\n##  M11Tong        3       Tongue\n\nNow we can create heatmap with additional annotations.\n\n# Determines the scaling of colorss\n# Scale colors\nbreaks &lt;- seq(-ceiling(max(abs(mat))), ceiling(max(abs(mat))), \n              length.out = ifelse( max(abs(mat))&gt;5, 2*ceiling(max(abs(mat))), 10 ) )\ncolors &lt;- colorRampPalette(c(\"darkblue\", \"blue\", \"white\", \"red\", \"darkred\"))(length(breaks)-1)\n\npheatmap(mat, annotation_row = taxa_clusters, \n         annotation_col = sample_data,\n         breaks = breaks,\n         color = colors)\n\n\n\n\n\n\n\nThe package sechm allows for further visual capabilities and flexibility. In this case, the clustering step is automatically performed by the plotting function and does not need to be executed in advance.\n\n# Stores annotation colros to metadata\nmetadata(tse_phylum_subset)$anno_colors$SampleType &lt;- c(Feces = \"blue\", \n                                                        Skin = \"red\", \n                                                        Tongue = \"gray\")\n\n# Create a plot\nsechm(tse_phylum_subset, \n      features = rownames(tse_phylum_subset), \n      assayName = \"clr\", \n      do.scale = TRUE, \n      top_annotation = c(\"SampleType\"), \n      gaps_at = \"SampleType\",\n      cluster_cols = TRUE, cluster_rows = TRUE)\n\n\n\n\n\n\n\nIt is also possible to create an analogous heatmap by just using the ggplot2 package. However, a relatively long code is required to generate an identical output.\n\n# Add feature names to column as a factor\ntaxa_clusters$Feature &lt;- rownames(taxa_clusters)\ntaxa_clusters$Feature &lt;- factor(taxa_clusters$Feature, levels = taxa_clusters$Feature)\n\n# Create annotation plot\nrow_annotation &lt;- ggplot(taxa_clusters) + \n  geom_tile(aes(x = NA, y = Feature, fill = clusters)) +\n  coord_equal(ratio = 1) +\n  theme(\n        axis.text.x=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank(),\n        axis.title.y=element_blank(),\n        axis.title.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n        plot.margin=margin(0,0,0,0),\n        ) +\n      labs(fill = \"Clusters\", x = \"Clusters\")\n\n# to view the notation, run\n# row_annotation\n\n# Add sample names to one of the columns\nsample_data$sample &lt;- factor(rownames(sample_data), levels = rownames(sample_data))\n\n# Create annotation plot\nsample_types_annotation &lt;- ggplot(sample_data) +\n  scale_y_discrete(position = \"right\", expand = c(0,0)) +\n  geom_tile(aes(y = NA, x = sample, fill = sample_types)) +\n  coord_equal(ratio = 1) +\n  theme(\n        axis.text.x=element_blank(),\n        axis.text.y=element_blank(),\n        axis.title.x=element_blank(),\n        axis.ticks.x=element_blank(),\n        plot.margin=margin(0,0,0,0),\n        axis.title.y.right = element_text(angle=0, vjust = 0.5)\n        ) +\n      labs(fill = \"Sample types\", y = \"Sample types\")\n# to view the notation, run\n# sample_types_annotation\n\n# Create annotation plot\nsample_clusters_annotation &lt;- ggplot(sample_data) +\n  scale_y_discrete(position = \"right\", expand = c(0,0)) +\n  geom_tile(aes(y = NA, x = sample, fill = clusters)) +\n  coord_equal(ratio = 1) +\n  theme(\n        axis.text.x=element_blank(),\n        axis.text.y=element_blank(),\n        axis.title.x=element_blank(),\n        axis.ticks.x=element_blank(),\n        plot.margin=margin(0,0,0,0),\n        axis.title.y.right = element_text(angle=0, vjust = 0.5)\n        ) +\n      labs(fill = \"Clusters\", y = \"Clusters\")\n# to view the notation, run\n# sample_clusters_annotation\n\n# Order data based on clusters and sample types\nmat &lt;- mat[unfactor(taxa_clusters$Feature), unfactor(sample_data$sample)]\n\n# ggplot requires data in melted format\nmelted_mat &lt;- melt(mat)\ncolnames(melted_mat) &lt;- c(\"Taxa\", \"Sample\", \"clr_z\")\n\n# Determines the scaling of colorss\nmaxval &lt;- round(max(abs(melted_mat$clr_z)))\nlimits &lt;- c(-maxval, maxval)\nbreaks &lt;- seq(from = min(limits), to = max(limits), by = 0.5)\ncolours &lt;- c(\"darkblue\", \"blue\", \"white\", \"red\", \"darkred\")\n\nheatmap &lt;- ggplot(melted_mat) + \n  geom_tile(aes(x = Sample, y = Taxa, fill = clr_z)) +\n  theme(\n    axis.title.y=element_blank(),\n    axis.title.x=element_blank(),\n    axis.ticks.y=element_blank(),\n    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n    \n    plot.margin=margin(0,0,0,0), # removes margins\n    legend.key.height= unit(1, 'cm')\n    ) +\n  scale_fill_gradientn(name = \"CLR + Z transform\", \n                       breaks = breaks, \n                       limits = limits, \n                       colours = colours) + \n  scale_y_discrete(position = \"right\")\n\nheatmap\n\n\n\n\n\n\n\n\nlibrary(patchwork)\n\n# Create layout\ndesign &lt;- c(\n  patchwork::area(3, 1, 4, 1),\n  patchwork::area(1, 2, 1, 3),\n  patchwork::area(2, 2, 2, 3),\n  patchwork::area(3, 2, 4, 3)\n)\n# to view the design, run\n# plot(design)\n\n# Combine plots\nplot &lt;- row_annotation + sample_clusters_annotation +\n                         sample_types_annotation +\n             heatmap  +\n    plot_layout(design = design, guides = \"collect\",\n                # Specify layout, collect legends\n                \n                # Adjust widths and heights to align plots.\n                # When annotation plot is larger, it might not fit into\n        # its column/row.\n                # Then you need to make column/row larger.\n                \n                # Relative widths and heights of each column and row:\n                # Currently, the width of the first column is 15 % and the height of\n                # first two rows are 30 % the size of others\n                \n                # To get this work most of the times, you can adjust all sizes to be 1, i.e. equal, \n                # but then the gaps between plots are larger.\n                widths = c(0.15, 1, 1),\n                heights = c(0.3, 0.3, 1, 1))\n\n# plot\n\n\n# Create layout\ndesign &lt;- c(\n  patchwork::area(4, 1, 5, 1),\n  patchwork::area(4, 2, 5, 2),\n  patchwork::area(1, 3, 1, 4),\n  patchwork::area(2, 3, 2, 4),\n  patchwork::area(3, 3, 3, 4),\n  patchwork::area(4, 3, 5, 4)\n)\n\n# to view the design, run\n# plot(design)\n\n# Combine plots\nplot &lt;- taxa_tree + \n  row_annotation +\n  sample_tree + \n  sample_clusters_annotation +\n  sample_types_annotation +\n  heatmap +\n    plot_layout(design = design, guides = \"collect\", # Specify layout, collect legends\n                widths = c(0.2, 0.15, 1, 1, 1),\n                heights = c(0.1, 0.15, 0.15, 0.25, 1, 1))\n\nplot\n\nHeatmaps find several other applications in biclustering and multi-assay analyses. These are discussed further in chapters Chapter¬†9 and Chapter¬†14."
  },
  {
    "objectID": "pages/80_training.html#sec-checklist",
    "href": "pages/80_training.html#sec-checklist",
    "title": "16¬† Training",
    "section": "\n16.1 Checklist",
    "text": "16.1 Checklist\nBrief checklist to prepare for training (see below for links).\n\nInstall the recommended software\nIf the time allows, watch the short online videos and familiarize with the other available material\nJoin Gitter online chat for support"
  },
  {
    "objectID": "pages/80_training.html#sec-software",
    "href": "pages/80_training.html#sec-software",
    "title": "16¬† Training",
    "section": "\n16.2 Recommended software",
    "text": "16.2 Recommended software\nWe recommend to install and set up the relevant software packages on your own computer as this will support later use. The essential components to install include:\n\nR (the latest official release)\nRStudio; choose ‚ÄúRstudio Desktop‚Äù to download the latest version. Check the Rstudio home page for more information. RStudio is optional.\nInstall key R packages (Section Chapter¬†1 provides an installation script)\nAfter a successful installation you can consider trying out examples from Section Chapter¬†18 already before training. You can run the workflows by simply copy-pasting examples. You can then test further examples from this tutorial, modifying and applying these techniques to your own data. Plain source code for the individual chapters of this book are available via Github"
  },
  {
    "objectID": "pages/80_training.html#sec-material",
    "href": "pages/80_training.html#sec-material",
    "title": "16¬† Training",
    "section": "\n16.3 Study material",
    "text": "16.3 Study material\nWe encourage to familiarize with the material and test examples in advance but this is optional:\n\nIntroduction to data analysis with R and Bioconductor (for beginners with R)\nShort online videos on microbiome data science with R/Bioconductor\nQuarto presentations\nOrchestrating Microbiome Analysis with Bioconductor (OMA) (this book)\nOther outreach material\nChapter¬†18 for self-study\nChapter¬†17 and links to complementary external material"
  },
  {
    "objectID": "pages/80_training.html#support-and-resources",
    "href": "pages/80_training.html#support-and-resources",
    "title": "16¬† Training",
    "section": "\n16.4 Support and resources",
    "text": "16.4 Support and resources\nFor online support on installation and other matters, join us at Gitter.\nYou are also welcome to connect through various channels with our broader developer and user community."
  },
  {
    "objectID": "pages/80_training.html#further-reading",
    "href": "pages/80_training.html#further-reading",
    "title": "16¬† Training",
    "section": "\n16.5 Further reading",
    "text": "16.5 Further reading\nThe following online books provide good general data science background:\n\n(Data science basics in R](https://r4ds.had.co.nz)\n(Modern Statistics for Modern Biology)[https://www.huber.embl.de/msmb/] open access book (Holmes S, Huber W)\n\nThe Bioconductor project (background on the Bioconductor project; Carpentries workshop)"
  },
  {
    "objectID": "pages/80_training.html#sec-coc",
    "href": "pages/80_training.html#sec-coc",
    "title": "16¬† Training",
    "section": "\n16.6 Code of Conduct",
    "text": "16.6 Code of Conduct\nWe support the Bioconductor Code of Conduct. The community values an open approach to science that promotes\n\nsharing of ideas, code, software and expertise\na kind and welcoming environment, diversity and inclusivity\ncommunity contributions and collaboration"
  },
  {
    "objectID": "pages/95_resources.html#data-containers",
    "href": "pages/95_resources.html#data-containers",
    "title": "17¬† Resources",
    "section": "17.1 Data containers",
    "text": "17.1 Data containers\n\n17.1.1 Data container documentation\n\nSingleCellExperiment (Lun and Risso 2020)\n\nOnline tutorial\n\nProject page\n\nPublication\n\nSummarizedExperiment (Morgan et al. 2020)\n\nOnline tutorial\n\nProject page\n\nTreeSummarizedExperiment (Huang 2020)\n\nOnline tutorial\n\nProject page\n\nPublication\n\nMultiAssayExperiment (Ramos et al. 2017)\n\nOnline tutorial\n\nProject page\n\nPublication\n\n\n\nLun, Aaron, and Davide Risso. 2020. SingleCellExperiment: S4 Classes for Single Cell Data.\n\nMorgan, Martin, Valerie Obenchain, Jim Hester, and Herv√© Pag√®s. 2020. SummarizedExperiment: SummarizedExperiment Container. https://bioconductor.org/packages/SummarizedExperiment.\n\nHuang, Ruizhu. 2020. TreeSummarizedExperiment: A S4 Class for Data with Tree Structures.\n\n\n17.1.2 Other relevant containers\n\nDataFrame which behaves similarly to data.frame, yet efficient and fast when used with large datasets.\n\nDNAString along with DNAStringSet,RNAString and RNAStringSet efficient storage and handling of long biological sequences are offered within the Biostrings package (Pag√®s et al. 2020).\n\nGenomicRanges ((Lawrence et al. 2013)) offers an efficient representation and manipulation of genomic annotations and alignments, see e.g.¬†GRanges and GRangesList at An Introduction to the GenomicRangesPackage.\n\n\nPag√®s, H., P. Aboyoun, R. Gentleman, and S. DebRoy. 2020. Biostrings: Efficient Manipulation of Biological Strings. https://bioconductor.org/packages/Biostrings.\n\nLawrence, Michael, Wolfgang Huber, Herv√© Pag√®s, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin Morgan, and Vincent Carey. 2013. ‚ÄúSoftware for Computing and Annotating Genomic Ranges.‚Äù PLoS Computational Biology 9. https://doi.org/10.1371/journal.pcbi.1003118.\nNGS Analysis Basics provides a walk-through of the above-mentioned features with detailed examples.\n\n\n17.1.3 phyloseq: an alternative container for microbiome data\nThe phyloseq package and class became the first widely used data container for microbiome data science in R. Many methods for taxonomic profiling data are readily available for this class. We provide here a short description how phyloseq and *Experiment classes relate to each other.\nassays : This slot is similar to otu_table in phyloseq. In a SummarizedExperiment object multiple assays, raw counts, transformed counts can be stored. See also (2017) for storing data from multiple experiments such as RNASeq, Proteomics, etc. rowData : This slot is similar to tax_table in phyloseq to store taxonomic information. colData : This slot is similar to sample_data in phyloseq to store information related to samples. rowTree : This slot is similar to phy_tree in phyloseq to store phylogenetic tree.\n\nRamos, Marcel, Lucas Schiffer, Angela Re, Rimsha Azhar, Azfar Basunia, Carmen Rodriguez Cabrera, Tiffany Chan, et al. 2017. ‚ÄúSoftware for the Integration of Multiomics Experiments in Bioconductor.‚Äù Cancer Research. https://doi.org/10.1158/0008-5472.CAN-17-0344.\nIn this book, you will encounter terms such as FeatureIDs and SampleIDs. FeatureIDs : These are basically OTU/ASV ids which are row names in assays and rowData. SampleIDs : As the name suggests, these are sample ids which are column names in assays and row names in colData. FeatureIDs and SampleIDs are used but the technical terms rownames and colnames are encouraged to be used, since they relate to actual objects we work with.\n\n\n17.1.3.1 Benchmarking TreeSE with phyloseq\nTreeSE objects can be converted into phyloseq objects and vice versa, therefore it is possible to compare the two containers in terms of computational efficiency. Remarkably, TreeSE and phyloseq were benchmarked against one another in mia v1.2.3 and phyloseq v1.38.0, respectively. 5 standard microbiome analysis operationswere applied to 4 datasets of varying size with both containers. In a nutshell, TreeSE and phyloseq showed a similar performance for datasets of small and medium size for most of the operations. However, TreeSE performed more efficiently as the size of the datasets increased. Further details on such results can be found in the benchmarking repository.\n\n\n17.1.3.2 Resources on phyloseq\nThe phyloseq container provides analogous methods to TreeSE. The following material can be used to familiarize with such alternative methods:\n\nList of R tools for microbiome analysis\n\nphyloseq (McMurdie and Holmes 2013)\n\nmicrobiome tutorial\n\nmicrobiomeutilities\n\nBioconductor Workflow for Microbiome Data Analysis: from raw reads to community analyses (Callahan et al. 2016).\n\n\nMcMurdie, PJ, and S Holmes. 2013. ‚ÄúPhyloseq: An r Package for Reproducible Interactive Analysis and Graphics of Microbiome Census Data.‚Äù PLoS ONE 8: e61217. https://doi.org/10.1371/journal.pone.0061217.\n\nCallahan, Ben J., Kris Sankaran, Julia A. Fukuyama, Paul J. McMurdie, and Susan P. Holmes. 2016. ‚ÄúBioconductor Workflow for Microbiome Data Analysis: From Raw Reads to Community Analyses [Version 2; Peer Review: 3 Approved].‚Äù F1000Research 5: 1492. https://doi.org/10.12688/f1000research.8986.2."
  },
  {
    "objectID": "pages/95_resources.html#r-programming-resources",
    "href": "pages/95_resources.html#r-programming-resources",
    "title": "17¬† Resources",
    "section": "17.2 R programming resources",
    "text": "17.2 R programming resources\n\n17.2.1 Base R and RStudio\nIf you are new to R, you could try swirl for a kickstart to R programming. Further support resources are available through the Bioconductor project (Huber et al. 2015).\n\nBase R and RStudio cheatsheets\n\nPackage-specific cheatsheets\n\nVisualization with ggplot2\n\nR graphics cookbook\n\n\n\n17.2.2 Bioconductor Classes\nS4 system\nS4 class system has brought several useful features to the object-oriented programming paradigm within R, and it is constantly deployed in R/Bioconductor packages (Huber et al. 2015).\n\nHuber, W., V. J. Carey, R. Gentleman, S. Anders, M. Carlson, B. S. Carvalho, H. C. Bravo, et al. 2015. ‚ÄúOrchestrating High-Throughput Genomic Analysis with Bioconductor.‚Äù Nature Methods 12 (2): 115‚Äì21. http://www.nature.com/nmeth/journal/v12/n2/full/nmeth.3252.html.\n¬†¬†Online Document:\n\nHerv√© Pag√®s, A quick overview of the S4 class system.\n\nLaurent Gatto, A practical tutorial on S4 programming\n\nHow S4 Methods Work (J. Chambers 2006)\n\n\nChambers, JM. 2006. ‚ÄúHow S4 Methods Work.‚Äù Technical report.\n¬†¬†Books:\n\nJohn M. Chambers. Software for Data Analysis: Programming with R. Springer, New York, 2008. ISBN-13 978-0387759357 (J. M. Chambers 2008)\n\nI Robert Gentleman. R Programming for Bioinformatics. Chapman & Hall/CRC, New York, 2008. ISBN-13 978-1420063677 (Gentleman 2008)\n\n\nChambers, John M. 2008. Software for Data Analysis: Programming with r. Vol. 2. Springer.\n\nGentleman, Robert. 2008. R Programming for Bioinformatics. CRC Press."
  },
  {
    "objectID": "pages/95_resources.html#sec-quarto",
    "href": "pages/95_resources.html#sec-quarto",
    "title": "17¬† Resources",
    "section": "17.3 Reproducible reporting with Quarto",
    "text": "17.3 Reproducible reporting with Quarto\n\n17.3.1 Learn Quarto\nReproducible reporting is the starting point for robust interactive data science. Perform the following tasks:\n\nIf you are entirely new to Quarto, take this short tutorial to get introduced to the most important functions within Quarto. Then experiment with different options from the Quarto cheatsheet.\nCreate a Quarto template in RStudio, and render it into a document (markdown, PDF, docx or other format). In case you are new to Quarto, its documentation provides guidelines to use Quarto with the R language (here) and the RStudio IDE (here).\nFurther examples are tips for Quarto are available in this online tutorial to interactive reproducible reporting.\n\n\n\n17.3.2 Additional material on Rmarkdown\nBeing able to use Quarto in R partly relies on your previous knowledge of Rmarkdown. The following resources can help you get familiar with Rmarkdown:\n\nOnline tutorial\n\nCheatsheet\n\nDocumentation\n\nDr.¬†C Titus Brown‚Äôs tutorial\n\nFigure sources:\nOriginal article\n\nHuang R et al. (2021) TreeSummarizedExperiment: a S4 class for data with hierarchical structure. F1000Research 9:1246. (Huang et al. 2021)\n\n\nHuang, Ruizhu, Charlotte Soneson, Felix G. M. Ernst, et al. 2021. ‚ÄúTreeSummarizedExperiment: A S4 Class for Data with Hierarchical Structure [Version 2; Peer Review: 3 Approved].‚Äù F1000Research 9: 1246. https://doi.org/10.12688/f1000research.26669.2.\nReference Sequence slot extension\n\nLahti L et al. (2020) Upgrading the R/Bioconductor ecosystem for microbiome research F1000Research 9:1464 (slides)."
  },
  {
    "objectID": "pages/98_exercises.html#basics-of-rbioconductor",
    "href": "pages/98_exercises.html#basics-of-rbioconductor",
    "title": "18¬† Exercises",
    "section": "\n18.1 Basics of R/Bioconductor",
    "text": "18.1 Basics of R/Bioconductor\nBioconductor training material has been contributed to Carpentries. You can check the following lessons for basic background of R and Bioconductor.\n\nIntroduction to data analysis with R and Bioconductor\nIntroduction to the Bioconductor project"
  },
  {
    "objectID": "pages/98_exercises.html#workflows",
    "href": "pages/98_exercises.html#workflows",
    "title": "18¬† Exercises",
    "section": "\n18.2 Workflows",
    "text": "18.2 Workflows\n\n18.2.1 Reproducible reporting with Quarto\nThe following batch of exercises walks you through typical use cases of Quarto in RStudio. Before heading to the exercises, it is recommended to read the Quarto guidelines for RStudio\n\n18.2.1.1 New document\nThis exercise gets you started with creating a Quarto document and adding text to it with typing conventions borrowed from the markdown syntax. Feel free to render the document with the Render button after each step to see the changes in the final report.\n\nOpen RStudio and create a new Quarto file named My first Quarto.\nAdd the subtitle My first section and write some text of your choice underneath. You can choose the level of headings by the number of preceding hashes (#).\nAdd a subsection named List of items and list three items underneath, both ordered and unordered. You can initialize items with numbers (1., 2., 3., ‚Ä¶) or stars (*) for the ordered and unordered case, respectively.\nAdd another subsection named Link to web and add a clickable link to the OMA book, using the pattern [text](url).\nRender the document and check its appearance\n\nNice start! You are now able to create a Quarto document, understand its syntax and can render it into a reproducible report. If you got stuck, you can look up the docs on creating and rendering Quarto documents.\n\n18.2.1.2 Code chunks\nWhile customizable text is nothing new by itself, the advantage of Quarto (and previously Rmakdown) is to combine text with code in R or other programming languages, so that both the analytical pipeline and verbal description can be put in one place. In this exercise, we learn how to write and run code in Quarto.\n\nOpen RStudio and create a new Quarto file.\n\nInitialize a code chunk by pressing alt + cmd + i and define the variables A &lt;- \"my name\" and B &lt;- 0 in it.\n\nWrite the text Below is my first code chunk just above the code chunk.\n\nInitialize one more code chunk and add 100 to the variable B in it.\n\nWrite the text Below I change variable B just above the second chunk.\n\n\nExtra: Write the following line of text: my name is A and I am B years old, where A and B are variables defined in the code chunks upstream and change if those variables are modified. Be aware that inline code can be added as &gt; r my_inline_command (without &gt;).\n\nGood job. You are now able to combine text and code in a Quarto document. If you got stuck, you can refer to the Quarto docs on using code chunks.\n\n18.2.1.3 Knitr options\nCode chunks can be greatly customized in terms of visibility and execution, output size and location and much more. This is possible with the knitr chunk options, which usually appear at the beginning of the target chunk with the syntax #| option-name: value, also described here. In this exercise, we explore part of the knitr potential.\n\nOpen RStudio and create a new Quarto file.\n\nInitialize three code chunks and label them as setup, fig-box and tbl-coldata, respectively. Remember that the name of a chunk can be specified with the label option.\n\nWrite the following code in the corresponding chunk and render the document.\n\n\n# setup\nlibrary(mia)\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\n# this line sets some options for all the chunks (global chunk options)\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\n\n\n# fig-box\nboxplot(colSums(assay(tse)) ~ tse$SampleType)\n\n\n# tbl-coldata\nknitr::kable(head(colData(tse)))\n\n\n?(caption)\n\n\n\n\nSet include: false in the setup chunk, fig-width: 10 in the fig-box chunk and echo: false in the tbl-coldata chunk. Render the document again and find the differences from before.\n\nAdd the options fig-cap and tab-cap to the fig-box and tbl-coldata chunks, respectively. They require some text input, which makes for the caption of the figures or tables.\n\n\nExtra: Create a cross-reference to fig-box and tbl-coldata in the text above the respective code chunk. You can do that with the syntax @chunk-name.\n\n\nExtra: Define a custom folder for storing figures with fig-path. Insert it in knitr::opts_chunk$set, so that it applies globally to all the figures generated in the document.\n\nCongratulations! You are now familiar with the great potential and flexibility of knitr chunk options. An exhaustive list of available options can be found in the knitr documentation.\n\n18.2.1.4 YAML instructions\nThe box at the beginning of every Quarto document contains yaml options that let you define the metadata of the document. They will affect the appearance of the document when it is rendered. By default, the box includes yaml options for the title, format and editor to be used, but much more information on layout, code execution and figures can be specified. A comprehensive list of yaml options is available here. In this exercise, we will get a tiny taste of such functionality.\n\nOpen RStudio and create a new Quarto file.\n\nIn the yaml box at the beginning of the document, change the title from Untitled to My first Quarto.\n\nIn the same box, add the two lines author and date followed by your name and today‚Äôs date, respectively.\n\nRender the document and check its appearance.\n\n\nExtra: Set toc: true to produce a table of contents. This line should follow format and html at the second level of indentation.\n\nWell done! Now you are able to specify yaml options and understand how they affect your Quarto document. If you got stuck, you can check this section of the Quarto documentation.\n\n18.2.1.5 Quarto parameters\nAn advanced feature of Quarto consists of execution parameters, which are externally pre-defined variables that are also accessible in the Quarto document. They can be specified in the yaml box as params. Here we learn how to use them.\n\nOpen RStudio and create a new Quarto file.\n\nIn the yaml box at the beginning of the document, add a line named params followed by an indented line with gamma: 10\n\nInitialize a code chunk and type str(params$gamma) in it.\n\nRender the document and check what happened.\n\nDefine one more parameter beta: 3 and multiply gamma by beta in a code chunk below.\n\nRender the document again and check what happened.\n\nWell done! You can now use an advanced feature of Quarto such as parameters. If you got stuck, here you can find more information about parameter definition and usage."
  },
  {
    "objectID": "pages/98_exercises.html#data-containers-treese",
    "href": "pages/98_exercises.html#data-containers-treese",
    "title": "18¬† Exercises",
    "section": "\n18.3 Data containers: TreeSE",
    "text": "18.3 Data containers: TreeSE\nTreeSE containers represent the working unit of the mia package. In the following exercises we learn how to construct, explore and work with them. A few demo datasets can be imported with mia and can be accessed as explained in chapter Section¬†2.3.\n\n18.3.1 Constructing a data object\nHere we cover how to construct a TreeSE from CSV files, using the components of OKeefeDSData from the microbiomeDataSets package as an example dataset.\n\nFetch or download the files in this directory.\n\nRead in the csv files with read.csv and store them into the variables assays, rowdata and coldata, respectively.\n\nCreate a TreeSE from the individual components with TreeSummarizedExperiment. Note that the function requires three arguments: assays, rowData and colData, to which you can give the appropriate item.\n\nCheck that importing is done correctly. E.g., choose random samples and features, and check that their values equal between raw files and TreeSE.\n\nUsefuls functions: DataFrame, TreeSummarizedExperiment, matrix, rownames, colnames, SimpleList\n\n18.3.2 Importing data\nRaw data of different types can be imported as a TreeSE with a number of functions explained in chapter Section¬†2.4.2. You can also check the function reference in the mia package.\n\nGet familiar with the microbiome data repository and read the instructions in its README to import and construct datasets from there.\n\nImport data from another format (functions: loadFromMetaphlan | loadFromMothur | loadFromQIIME2 | makeTreeSummarizedExperimentFromBiom | makeTreeSummarizedExperimentFromDADA2 ‚Ä¶)\n\nTry out conversions between TreeSE and phyloseq data containers (makeTreeSummarizedExperimentFromPhyloseq; makephyloseqFromTreeSummarizedExperiment)\n\n18.3.3 Preliminary exploration\n\nImport the mia package, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\n\nGet a summary about the TreeSE with summary. What is the mean count across samples? How many features recur only once (singletons)?\n\nCheck the dimensions of the TreeSE with dim or alternatively with nrow and ncol. How many samples and features are present?\n\nList sample and features names with rownames and colnames.\n\nCheck what information about samples and features is contained by the colData and rowData of the TreeSE with names.\n\n\nExtra: Calculate the number of unique taxa for each taxonomic rank. You can use apply to count unique elements for each column of rowData.\n\n18.3.4 Assay retrieval\n\nImport the mia package, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\n\nList the names of all available assays with assayNames.\n\nFetch the list of assays with assays.\n\nRetrieve the first assay of the TreeSE with assay, where the second argument can be either the name or the index of the desired assay.\n\nWell done! You can now locate and retrieve individual assays of a TreeSE. If you got stuck, you can refer to chapter Section¬†2.2.1 of this book.\n\n18.3.5 Sample information\n\nImport the mia package, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\n\nCheck the names of the samples with colnames.\n\nList the information on samples available in colData with names.\n\nVisualize the colData with View and briefly look at the information stored in the different columns.\n\nGet the abundances of all features for a specific sample, such as ID34, for an assay of your choice.\n\n18.3.6 Feature information\n\nImport the mia package, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\n\nCheck the names of the features with rownames.\n\nList the information on features available in rowData with names.\n\nVisualize the rowData with View and briefly look at the information stored in the different columns.\n\nGet the abundances for a specific feature, such as OTU1810, in all the samples. You can access feature-specific abundances for an assay of your choice.\n\n\nExtra: Create a taxonomy tree based on the taxonomy mappings with addTaxonomyTree and display its content with taxonomyTree and ggtree.\n\nIf you got stuck, you can look up chapters Chapter¬†3 and Section¬†5.2.1 on how to pick specific abundances and generate row trees, respectively.\n\n18.3.7 Other elements\nTry to extract some of the other TreeSE elements listed in chapter Chapter¬†2. However, such data are not always included.\n\nImport the mia package, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\n\nFetch the metadata of the TreeSE. Is there any iformation available?\n\nAccess the phylogenetic tree with rowTree. How big is it in terms of tips and nodes. If you like you can visualize it with ggtree.\n\nCheck if a sample tree is available with colTree, which is suitable for hierarchical or nested study designs.\n\nIf present, obtain the information on feature DNA sequences from the DNA sequence slot."
  },
  {
    "objectID": "pages/98_exercises.html#data-manipulation",
    "href": "pages/98_exercises.html#data-manipulation",
    "title": "18¬† Exercises",
    "section": "\n18.4 Data manipulation",
    "text": "18.4 Data manipulation\n\n18.4.1 Subsetting\n\nSubset the TreeSE object to specific samples\n\nSubset the TreeSE object to specific features\n\nSubset the TreeSE object to specific samples and features\n\n18.4.2 Library sizes\n\nCalculate library sizes\n\nSubsample / rarify the counts (see: subsampleCounts)\n\nUseful functions: nrow, ncol, dim, summary, table, quantile, unique, addPerCellQC, mergeFeaturesByRank\n\n18.4.3 Prevalent and core taxonomic features\n\nEstimate prevalence for your chosen feature (row, taxonomic group)\n\nIdentify all prevalent features and subset the data accordingly\n\nReport the thresholds and the dimensionality of the data before and after subsetting\n\nVisualize prevalence\n\nUseful functions: getPrevalence, getPrevalentFeatures, subsetByPrevalentFeatures\n\n18.4.4 Data exploration\n\nSummarize sample metadata variables. (How many age groups, how they are distributed? 0%, 25%, 50%, 75%, and 100% quantiles of library size?)\n\nCreate two histograms. Another shows the distribution of absolute counts, another shows how CLR transformed values are distributed.\n\nVisualize how relative abundances are distributed between taxa in samples.\n\nUseful functions: nrow, ncol, dim, summary, table, quantile, unique, transformAssay, ggplot, wilcox.test, mergeFeaturesByRank, plotAbundance\n\n18.4.5 Other functions\n\nMerge data objects (merge, mergeSEs)\n\nMelt the data for visualization purposes (meltAssay)\n\n18.4.6 Assay transformation\n\nImport the mia package, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\n\nTransform the counts assay into relative abundances with transformAssay and store it into the TreeSE as an assay named relabund (see chapter Section¬†5.4).\n\nSimilarly, perform a clr transformation on the counts assay with a pseudocount of 1 and add it to the TreeSE as a new assay.\n\nList the available assays by name with assays.\n\nAccess the clr assay and select a subset of its first 100 features and 10 samples. Remember that assays are subsettable with assay[row_idx, col_idx].\n\nTake the same subset from the TreeSE, and check how this affects the individual transformed assays. TreeSE can also be subsetted with tse[row_idx, col_idx].\n\n\nExtra: If the data has phylogenetic tree, perform the phILR transformation."
  },
  {
    "objectID": "pages/98_exercises.html#abundance-tables",
    "href": "pages/98_exercises.html#abundance-tables",
    "title": "18¬† Exercises",
    "section": "\n18.5 Abundance tables",
    "text": "18.5 Abundance tables\n\n18.5.1 Taxonomic levels\n\nImport the mia package, load one of the example data sets mentioned in Chapter 3.3 with data (you need one with taxonomic information at Phylum level) and store it into a variable named tse.\n\nList the available taxonomic ranks in the data with taxonomyRanks.\n\nAgglomerate the data to Phylum level with mergeFeaturesByRank and the appropriate value for Rank.\n\nReport the dimensions of the TreeSE before and after agglomerating. You can use dim for that.\n\n\nExtra: Perform CLR transformation on the data. Does this affect agglomeration?\n\n\nExtra: List full taxonomic information for a few selected taxa, such as OTU1 and OTU1368. For that you can use mapTaxonomy on a specific subset of the TreeSE.\n\n18.5.2 Alternative experiments\n\nImport the mia package, load one of the example data sets mentioned in Chapter 3.3 with data (you need one with taxonomic information) and store it into a variable named tse.\n\nCheck the taxonomic ranks of the features with taxonomyRanks. What is the deepest taxonomic rank available?\n\nAgglomerate the TreeSE to each taxonomic rank and store the resulting experiments as altExps. This can be performed automatically with splitByRanks.\n\nCheck the names of the generated altExps with altExpNames and retrieve a complete list with altExps.\n\nRetrieve the data agglomerated by genus from the corresponding altExp. As for assays, you can access the desired altExp by name or index.\n\n\nExtra: Split the data based on other features with splitOn."
  },
  {
    "objectID": "pages/98_exercises.html#community-alpha-diversity",
    "href": "pages/98_exercises.html#community-alpha-diversity",
    "title": "18¬† Exercises",
    "section": "\n18.6 Community (alpha) diversity",
    "text": "18.6 Community (alpha) diversity\n\n18.6.1 Estimation\n\nImport the mia package, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\nCalculate multiple alpha diversity indices with estimateDiversity without any additional arguments.\nCheck the names of colData with names. Can you identify which columns contain the alpha diversity indices?\n\nExtra: Agglomerate the TreeSE by phylum and compare the mean Shannon diversity of the original experiment with its agglomerated version. You can use mergeFeaturesByRank to perform agglomeration and mean to calculate the mean values of the respective columns in colData.\n\n18.6.2 Visualization\n\nImport the mia and scater packages, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\nCalculate Shannon diversity index and Faith‚Äôs phylogenetic diversity with estimateDiversity and the appropriate arguments for index.\nMake a boxplot of Shannon diversity on the y axis and sample type on the x axis with plotColData.\nRepeat the previous point with Faith‚Äôs phylogenetic diversity and compare the sample distributions of the two alpha diversity indices. How greatly do they differ?\n\nExtra: Make a scatterplot of Shannon diversity on the y axis and Faith‚Äôs phylogenetic diversity on the x axis with plotColData. Colour the points by sample type with the appropriate optional argument.\n\n18.6.3 Correlation\n\nImport the mia and scater packages, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\nCalculate coverage and Shannon diversity index with estimateDiversity and the appropriate arguments for index.\nTest the correlation between the two indices with cor.test. Remember that colData parameters are accessible with tse$param_name. Use Kendall tau coefficients as method to measure correlation. Is the correlation weak or strong, significant or not?\nMake a scatterplot of Shannon diversity index on the y axis and coverage on the x axis. You can do that with plotColData. How do the two indices relate to one another?\n\nExtra: Compute the library size of the samples by applying colSums to the counts assay of the TreeSE, and test the correlation of library size with Shannon diversity or coverage. Which index is more correlated with library size?\n\nIn this example, we inspected the correlation between two related variables, also known as multicollinearity, and checked the correlation to library size, which is part of quality control. However, the correlation between alpha diversity and other numerical data about samples, such as participant‚Äôs age and weight, also represent an important analysis in several studies.\n\n18.6.4 Differences between groups\n\nImport the mia package, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\nCalculate the Gini-Simpson diversity with estimateDiversity and the appropriate argument for index. Set name to simpson. You will use this name to access the diversity index from colData.\nInspect the Diet column in the colData. Determine how the samples are grouped in terms of diet. You can see the number of unique elements in a column with unique.\nTest differences in Gini-Simpson diversity between different diets with kruskal.test. Remember that colData parameters are accessible with tse$param_name.\nIs diversity significantly different between vegan and mixed diet? To visualize that, make a boxplot of Gini-Simpson diversity on the y axis and diet on the x axis with plotColData.\n\nExtra: Repeat points 3 through 5, this time for age groups. Make sure that you are using an appropriate statistical test for the number of groups and distribution."
  },
  {
    "objectID": "pages/98_exercises.html#community-similarity",
    "href": "pages/98_exercises.html#community-similarity",
    "title": "18¬† Exercises",
    "section": "\n18.7 Community similarity",
    "text": "18.7 Community similarity\n\n18.7.1 Reduced dimensions retrieval\n\nImport the mia package, load enterotype with data and store it into a variable named tse.\nList all available reduced dimensions with reducedDims. At this point, no reducedDims are likely found, because we haven‚Äôt created any yet.\nPerform PCA and store its output in the TreeSE by running tse &lt;- runPCA(tse, assay.type = \"counts\"). Note that it is required to specify the assay on which dimensionality reduction should be conducted.\nView the names of all available reduced dimensions with reducedDimNames. Has something new appeared?\n\nExtra: Access the PCA reducedDim object with reducedDim and explore its content. How are the different dimensions stored? Try to extract an array with only the values from the second dimension by indexing the object with [ , 2].\n\n18.7.2 Visualization basics with PCA\n\nImport the mia and scater packages, load enterotype with data and store it into a variable named tse.\nPerform a 3-component PCA based on the counts assay. You can use runPCA and set the optional arguments ncomponents and assay.type to the appropriate values.\nPlot the first two dimensions of PCA with plotReducedDim, to which you should give the appropriate reducedDim name as the second argument. Note that by default only the first two dimensions are shown.\nCheck which information is stored in the ColData of the TreeSE. What would be worth visualizing in our coordination plot?\nMake the same plot again, but this time colour the observations by Enterotype. You can do that by setting colour_by to the appropriate colname in the colData of the TreeSE.\n\nExtra: Plot all three dimensions of PCA with plotReducedDim and the optional argument ncomponents. Colour observations by Enterotype. Which pair of dimensions best explains the variance between Enterotypes?\n\n18.7.3 Principal Coordinate Analysis (PCoA)\nPCoA turns out to be particularly relevant for microbiome analysis, because unlike PCA it can generate reduced dimensions from distances other than Euclidean. There are several ecological distances to choose from and you can find many of them under methods in the vignettes of vegan::vegdist.\n\nImport the mia and scater packages, load enterotype with data and store it into a variable named tse.\nTransform the counts assay to relative abundances with transformAssay.\nPerform a Multi-Dimensional Scaling (MDS) based on the relative abundance assay in terms of Bray-Curtis dissimilarity. You can use runMDS with the compulsory argument FUN = vegan::vegdist.\nPlot the first two dimensions of PCA with plotReducedDim, to which you should give the appropriate reducedDim name as the second argument. Colour the observations by Enterotype with colour_by.\n\nExtra: Perform MDS again with runMDS, but this time use Jaccard dissimilarity. The distance metric to use can be defined with the optional argument method, choosing from the methods in ?vegan::vegdist. If you don‚Äôt want to overwrite the reducedDim object made in point 3, set name to a name of your choice. Visualize and compare it to the plot from point 4.\n\nGood job! You are now able to produce and visualize reduced dimensions of a TreeSE. runMDS is actually one of several algorithms for PCoA and dimensionality reduction, which you can find in section Section¬†7.1.2.\n\n18.7.4 PERMANOVA analysis\nIn this exercise we focus on studying the weight of variables on the microbiome composition. Significance of each variable on beta diversity is tested with PERMANOVA (point 4) and the homogeneity assumption is also be controlled with a PERMDISP2 analysis (point 5).\n\nImport the mia and vegan packages, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\nTransform the counts assay into relative abundances with transformAssay.\nExtract the relative abundance assay, transpose it and save it into a variable named relabund_assay.\nPerform PERMANOVA with adonis2 to see how much Diet can explain the relative abundance assay (formula = relabund_assay ~ Diet) in terms of Bray-Curtis dissimilarity (method = \"bray\"). Also set data = colData(tse) by = \"margin\" and permutations = 99. What do the results tell you about Diet with respect to beta diversity?\n\nExtra: Test homogeneity of distribution across Diet groups with anova(betadisper(my_mat), my_groups, where my_mat is the Bray-Curtis dissimilarity matrix of relabund_assay calculated with vegdist(relabund_assay, \"bray\") and my_groups is the vector of Diet values obtained from the colData of the TreeSE.\n\nWell done! You went through testing the effect and significance of Diet on beta diversity. Keep in mind that the formula fed to adonis2 can take more than one independent variable, so that you can also (and very often should) include covariates of your studies.\n\n18.7.5 Redundancy analysis (RDA)\nHere we apply RDA, an ordination method that provides dimensions with the largest variation between the data based in the light of the specified variables (point 3). The results of RDA are usually assessed with PERMANOVA (point 5) and the homogeneity assumption should be checked as in the previous exercise. This is a relatively complex procedure, but the way this is broken down into steps below will hopefully make more sense.\n\nImport the mia and vegan packages, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\nTransform the counts assay into relative abundances with transformAssay.\nPerform RDA with calculateRDA to see how much Diet can explain the relative abundance assay (formula = assay ~ Diet and assay.type = relabundance) in terms of Bray-Curtis dissimilarity (method = \"bray\").\nExtract the RDA dimensions from the appropriate reducedDim slot with attr(reducedDim(tse, \"RDA\"), \"rda) and store it into rda.\nTest the effect and significance of Diet on beta diversity by PERMANOVA with anova.cca. Feed this function with rda and set by = \"margin\" and permutations = 99, respectively. What do the results tell you about Diet?\n\nExtra: Check what other parameters are stored in the colData of peerj13075, add them to the formula (formula = assay ~ Diet + ...) of calculateRDA and proceed to see how that changes the results of PERMANOVA.\n\nWell done! You went through an RDA analysis followed by significance testing with PERMANOVA and BETADISPER2. In the next exercise we‚Äôll go deeper quantify the contributions to beta diversity.\n\n18.7.6 Beta diversity analysis\nThis exercise prompts you to implement a workflow with distance-based RDA (dbRDA). You can refer to chapter Section¬†7.3.1 for a step-by-step walkthrough, which may be simplified in the future.\n\nImport the mia and vegan packages, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\nCreate dbRDA with Bray-Curtis dissimilarities on relative abundances. Use PERMANOVA. Can differences between samples be explained with variables of sample meta data?\nAnalyze diets‚Äô association on beta diversity. Calculate dbRDA and then PERMANOVA. Visualize coefficients. Which taxa‚Äôs abundances differ the most between samples?\nInterpret your results. Is there association between community composition and location? What are those taxa that differ the most; find information from literature.\n\nUseful functions: runMDS, runRDA, anova.cca, transformAssay, mergeFeaturesByRank, ggplot, plotReducedDim, vegan::adonis2"
  },
  {
    "objectID": "pages/98_exercises.html#differential-abundance",
    "href": "pages/98_exercises.html#differential-abundance",
    "title": "18¬† Exercises",
    "section": "\n18.8 Differential abundance",
    "text": "18.8 Differential abundance\n\n18.8.1 Standard analysis with ALDEx2\n\nImport the mia and ALDEx2 packages, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\nAgglomerate the TreeSE by genus and filter by a prevalence of 10%. You can perform both operations in one go with subsetByPrevalentFeatures by specifying the rank and prevalence arguments.\nModel the counts assay of the TreeSE with aldex.clr and store it into the variable x. As a second argument, provide the grouping variable Diet, which is contained in a column of the colData.\nFeed x to the functions aldex.ttest to erform t-test and to aldex.effect to estimate effect sizes. Store the output into x_tt and x_effect, respectively.\nCreate a data.frame named aldex_out which includes both x_tt and x_effect and filter for the features with wi.eBH &lt; 0.05. Are there any significantly differential abundance taxa?\n\nExtra: If these results appear boring, repeat steps 1 - 5, but use Gender or Age as the grouping variable. Do we have any better luck with Gender? What is the problem with Age?\n\n18.8.2 Controlling for confounders\n\nImport the mia and MicrobiomeStat packages, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\nAgglomerate the TreeSE by genus and filter by a prevalence of 10%. You can perform both operations in one go with subsetByPrevalentFeatures by specifying the rank and prevalence arguments.\nModel the counts assay of the TreeSE with linda and store the output into a variable named linda_out. Provide the colData converted into a data.frame (with as.data.frame) as the second argument, and a formula with the Age, Gender and Diet as variables. For example, formula = \"~ A + B\" represents a formula with variables A and B.\nExtract the output$AgeElderly object from linda_out with $ and store it into a variable named linda_res.\nFilter linda_res for features with reject == TRUE. How many differentially abundant taxa were found? What are their names and how significant are they in terms of log-fold change and adjusted p-value?\n\n18.8.3 Comparing methods\nHere, we conduct DAA with identical parameters as in the previous exercise, but with a different method, namely ZicoSeq. We aim to compare the results between these two methods and draw better informed conclusions from such comparative approach.\n\nImport the mia and GUniFrac packages, load any of the example data sets mentioned in Chapter 3.3 with data and store it into a variable named tse.\nAgglomerate the TreeSE by genus and filter by a prevalence of 10%. You can perform both operations in one go with subsetByPrevalentFeatures by specifying the rank and prevalence arguments.\nModel the counts assay of the TreeSE with ZicoSeq as the feature.dat argument and store the output into a variable named zicoseq_out. Provide also the colData converted to a data.frame (with as.data.frame) as meta.dat. In addition, set grp.name to \"Age\", adj.name to c(\"Diet\", \"Gender\"), feature.dat.type to \"count\", return.feature.dat to TRUE and perm.no to 999.\nView the top six differentially abundant taxa and their adjusted p-values with head(sort(zicoseq_out$p.adj.fdr)). Is there any significant taxon according to ZicoSeq? Compared to the output of linda, do we see the same taxa at the top in terms of significance? Overall, to what extent do the two methods agree with one another?\n\n18.8.4 Workflow 1\n\nGet the abundances for an individual feature (taxonomic group / row)\nVisualize the abundances per group with boxplot / jitterplot\nIs the difference significant (Wilcoxon test)?\nIs the difference significant (linear model with covariates)?\nHow do transformations affect the outcome (log10, clr..)?\nGet p-values for all features (taxa), for instance with a for loop\nDo multiple testing correction\nCompare the results from different tests with a scatterplot\n\nUseful functions: [], ggplot2::geom_boxplot, ggplot2::geom_jitter, wilcox.test, lm.test, transformAssay, p.adjust\n\n18.8.5 Workflow 2\n\ninstall the latest development version of mia from GitHub.\nLoad experimental dataset from mia.\nCompare abundances of each taxa between groups. First, use Wilcoxon or Kruskall-Wallis test. Then use some other method dedicated to microbiome data.\nSummarize findings by plotting a taxa vs samples heatmap. Add column annotation that tells the group of each sample, and row annotation that tells whether the difference of certain taxa was statistically significant.\nChoose statistically significant taxa and visualize their abundances with boxplot & jitterplot.\n\nUseful functions: wilcox.test, kruskal.test, ggplot, pheatmap, ComplexHeatMap::Heatmap, ancombc, aldex2, maaslin2, mergeFeaturesByRank, transformAssay, subsetByPrevalentFeatures"
  },
  {
    "objectID": "pages/98_exercises.html#visualization-1",
    "href": "pages/98_exercises.html#visualization-1",
    "title": "18¬† Exercises",
    "section": "\n18.9 Visualization",
    "text": "18.9 Visualization\n\n18.9.1 Multivariate ordination\n\nLoad experimental dataset from mia.\nCreate PCoA with Bray-Curtis dissimilarities\nCreate PCA with Aitchison dissimilarities\nVisualize and compare both\nTest other transformations, dissimilarities, and ordination methods\n\nUseful functions: runMDS, runNMDS, transformAssay, ggplot, plotReducedDim\n\n18.9.2 Heatmap visualization\n\nLoad experimental dataset from mia.\nVisualize abundances with heatmap\nVisualize abundances with heatmap after CLR + Z transformation\n\nSee the OMA book for examples."
  },
  {
    "objectID": "pages/98_exercises.html#multiomics",
    "href": "pages/98_exercises.html#multiomics",
    "title": "18¬† Exercises",
    "section": "\n18.10 Multiomics",
    "text": "18.10 Multiomics\n\n18.10.1 Basic exploration\nHere we learn how to conduct preliminary exploration on a MAE, using HintikkaXOData as an example dataset.\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nWhich experiments make up the MAE? How many samples and features are contained by each experiment? You can get a summary for all experiments with experiments, and check for each individual experiment with dim, nrow and ncol.\nWhat are the names of the features and samples of the different experiments? You can see that with rownames and colnames, respectively.\nWhat information is known about the samples? Remember that information about samples is stored in the colData of the MAE.\n\nExtra: How do the samples of the individual experiments map to the columns of the MAE? You can find the sample mapping in the sampleMap of the MAE.\n\nSo far so good. You explored a MAE and its experiments, getting a taste of how information is organized in its internal structure.\n\n18.10.2 Experiment agglomeration\nHere we learn how to manipulate an experiment contained by a MAE and save the new modified version of the experiment in a suitable place (the altExp slot).\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nAgglomerate the microbiota experiment by Genus and store the output into the altExp slot of the microbiota experiment, with the custom name microbiota_genus.\nHow many features remain after agglomerating? What are their names?\n\nExtra: create one more alternative experiment named prevalent_microbiota_family, which contains the microbiota experiment agglomerated by Family with a prevalence threshold of 10%. You can agglomerate and in parallel select by prevalence with mergeFeaturesByPrevalence.\n\nGood job! You agglomerated one of the experiments in the MAE and stored it as an alternative experiment.\n\n18.10.3 Experiment transformation\nWe proceed with an exercise on a different type of data manipulation, that is, transformation of assays of individual experiments in the MAE.\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nWhat assays are contained by each individual experiment? You can check their names with assays.\nApply a log10 transformation to the assay of the metabolite experiment. For that you can use transformAssay and don‚Äôt forget to specify the assay to be transformed with the argument assay.type.\nApply a CLR transformation to the counts assay of the microbiota experiment. To ensure non-null values in the assay, set pseudocount equal to 1.\n\nYou made it! You learnt how to apply different transformations to the assays of individual experiments in a MAE with transformAssay, specifying optional arguments based on the used method.\n\n18.10.4 Assay extraction\nThe following exercise walks you through disassembling a MAE object in order to retrieve a specific assay, or to store its components as multiple separate csv files.\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nExtract the individual metabolite experiment from the MAE into a distinct TreeSE object named metabolites.\nWhich and how many assays are contained by metabolites? You can check that with assays or assayNames.\nWrite a csv file for the nmr assay with write.csv. You can access an individual assay of a TreeSE with assay by specifying the name of the desired assay.\n\nExtra: Repeat step 1 thorugh 4 also for the microbiota and biomarkers experiments, so that a completely disassembled version of the MAE is available.\n\nExtra: Besides experiments, MAEs also include a sampleData and a sampleMap, which are accessible with colData(mae) and sampleMap(mae), respectively. Save also each of these two elements into a csv file.\n\nWell done! You just splitted a MAE into its components and stored them as csv files. This script shows a possible approach.\n\n18.10.5 MAE reconstruction\nNext, we will try to reconstruct the same MAE from the files you created. Make sure you know their names and location! Alternatively, you can fetch or download the CSV files in this directory with the readily disassembled components of HintikkaXOData.\n\nRead in the csv files containing assays with read.csv and save each of them into a variable named &lt;assay name&gt;_assays.\nCreate one TreeSE from each assays object with the TreeSummarizedExperiment function, as explained in this exercise.\nRead in the sampleData and the sampleMap and store them into the variables sample_data and sample_map, respectively.\nCombine the components with MultiAssayExperiment, where the first argument is an ExperimentList (for now include only the microbiota and metabolites TreeSEs), the second is colData and the third is sampleMap.\nMake sure that the MAE experiments are identical to the original TreeSEs. You can do that qualitatively by checking their head and quantitatively by looking at their dim.\n\nExtra: Add the biomarkers TreeSE as a new experiment to the MAE. Note that new experiments can be added to a MAE through simple concatenation with c(mae, experiment).\n\nGood job! Now you are aware of how MAEs are built and we can proceed to some analytical exercises.\n\n18.10.6 Cross-correlation analysis\nNow we will perform a cross-correlation analysis between two of the experiments in the MAE.\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nAnalyze correlations between the microbiota and the biomarkers experiments with getExperimentCrossAssociation. Don‚Äôt forget to specify the experiments you want to compare with the arguments experiment1 and experiment2, and which of their assays with assay.type1 and assay.type2.\nWhat does the output look like? By default, correlation is measured in terms of Kendall tau coefficients. Repeat point 2, but this time change method to Spearman coefficients.\nAre you able to infer significance from the output? In order to also obtain p-values from the cross-correlation analysis, repeat point 2 with the additional argument test_significance = TRUE.\nVisualize results with a heatmap similarly to the example in section Section¬†14.1. Do you see any significant correlations? Interpret your results.\n\nExtra: Perform cross-correlation analysis between the remaining experiments (microbiota vs metabolites and metabolites vs biomarkers) and visualize results with heatmaps.\n\nGreat job! You performed a cross-correlation analysis between two experiments of a MAE and visualized the results with a heatmap. You are also able to customise the correlation method and significance testing used for the analysis."
  },
  {
    "objectID": "pages/97_extra_materials.html#slides",
    "href": "pages/97_extra_materials.html#slides",
    "title": "Appendix A ‚Äî Extra material",
    "section": "\nA.1 Slides",
    "text": "A.1 Slides\nOutreach material includes slide sets for training events."
  },
  {
    "objectID": "pages/97_extra_materials.html#sec-compare-permanova",
    "href": "pages/97_extra_materials.html#sec-compare-permanova",
    "title": "Appendix A ‚Äî Extra material",
    "section": "\nA.2 PERMANOVA comparison",
    "text": "A.2 PERMANOVA comparison\nHere we present two possible uses of the adonis2 function which performs PERMANOVA. The optional argument by has an effect on the statistical outcome, so its two options are compared here.\n\n# import necessary packages\nlibrary(gtools)\nlibrary(purrr)\nlibrary(vegan)\nlibrary(gtools)\nlibrary(purrr)\n\nLet us load the enterotype TSE object and run PERMANOVA for different orders of three variables with two different approaches: by = \"margin\" or by = \"terms\".\n\n# load and prepare data\nlibrary(mia)\ndata(\"enterotype\", package=\"mia\")\nenterotype &lt;- transformAssay(enterotype, method = \"relabundance\")\n# drop samples missing meta data\nenterotype &lt;- enterotype[ , !rowSums(is.na(colData(enterotype)[, c(\"Nationality\", \"Gender\", \"ClinicalStatus\")]) &gt; 0)]\n# define variables and list all possible combinations\nvars &lt;- c(\"Nationality\", \"Gender\", \"ClinicalStatus\")\nvar_perm &lt;- permutations(n = 3, r = 3, vars)\nformulas &lt;- apply(var_perm, 1, function(row) purrr::reduce(row, function(x, y) paste(x, \"+\", y)))\n# create empty data.frames for further storing p-values\nterms_df &lt;- data.frame(\"Formula\" = formulas,\n                       \"ClinicalStatus\" = rep(0, 6),\n                       \"Gender\" = rep(0, 6),\n                       \"Nationality\" = rep(0, 6))\nmargin_df &lt;- data.frame(\"Formula\" = formulas,\n                        \"ClinicalStatus\" = rep(0, 6),\n                        \"Gender\" = rep(0, 6),\n                        \"Nationality\" = rep(0, 6))\n\n\nfor (row_idx in 1:nrow(var_perm)) {\n  \n  # generate temporary formula (i.e. \"assay ~ ClinicalStatus + Nationality + Gender\")\n  tmp_formula &lt;- purrr::reduce(var_perm[row_idx, ], function(x, y) paste(x, \"+\", y))\n  tmp_formula &lt;- as.formula(paste0('t(assay(enterotype, \"relabundance\")) ~ ',\n                            tmp_formula))\n\n  # multiple variables, default: by = \"terms\"\n  set.seed(75)\n  with_terms &lt;- adonis2(tmp_formula, \n                by = \"terms\",\n                data = colData(enterotype),\n                permutations = 99)\n  \n  # multiple variables, by = \"margin\"\n  set.seed(75)\n  with_margin &lt;- adonis2(tmp_formula, \n                 by = \"margin\",\n                 data = colData(enterotype),\n                 permutations = 99)\n\n  # extract p-values\n  terms_p &lt;- with_terms[[\"Pr(&gt;F)\"]]\n  terms_p &lt;- terms_p[!is.na(terms_p)]\n  margin_p &lt;- with_margin[[\"Pr(&gt;F)\"]]\n  margin_p &lt;- margin_p[!is.na(margin_p)]\n  \n  # store p-values into data.frames\n  for (col_idx in 1:ncol(var_perm)) {\n    \n    terms_df[var_perm[row_idx, col_idx]][row_idx, ] &lt;- terms_p[col_idx]\n    margin_df[var_perm[row_idx, col_idx]][row_idx, ] &lt;- margin_p[col_idx]\n    \n  }\n  \n}\n\nThe following table displays the p-values for the three variables ClinicalStatus, Gender and Nationality obtained by PERMANOVA with adonis2. Note that the p-values remain identical when by = \"margin\", but change with the order of the variables in the formula when by = \"terms\" (default).\n\n\ndf &lt;- terms_df %&gt;%\n  dplyr::inner_join(margin_df, by = \"Formula\", suffix = c(\" (terms)\", \" (margin)\"))\n\nknitr::kable(df)"
  },
  {
    "objectID": "pages/97_extra_materials.html#bayesian-multinomial-logistic-normal-models",
    "href": "pages/97_extra_materials.html#bayesian-multinomial-logistic-normal-models",
    "title": "Appendix A ‚Äî Extra material",
    "section": "\nA.3 Bayesian Multinomial Logistic-Normal Models",
    "text": "A.3 Bayesian Multinomial Logistic-Normal Models\nAnalysis using such model could be performed with the function pibble from the fido package, wihch is in form of a Multinomial Logistic-Normal Linear Regression model; see vignette of package.\nThe following presents such an exemplary analysis based on the data of Sprockett et al. (2020) available through microbiomeDataSets package.\n\nSprockett, Daniel D., Melanie Martin, Elizabeth K. Costello, Adam R. Burns, Susan P. Holmes, Michael D. Gurven, and David A. Relman. 2020. ‚ÄúMicrobiota Assembly, Structure, and Dynamics Among Tsimane Horticulturalists of the Bolivian Amazon.‚Äù Nat Commun 11 (1): 3772. https://doi.org/10.1038/s41467-020-17541-6.\n\nlibrary(fido)\nlibrary(microbiomeDataSets)\ntse &lt;- SprockettTHData()\n\nWe pick three covariates (‚ÄúSex‚Äù,‚ÄúAge_Years‚Äù,‚ÄúDelivery_Mode‚Äù) during this analysis as an example, and beforehand we check for missing data:\n\nlibrary(mia)\ncov_names &lt;- c(\"Sex\",\"Age_Years\",\"Delivery_Mode\")\nna_counts &lt;- apply(is.na(colData(tse)[,cov_names]), 2, sum)\nna_summary&lt;-as.data.frame(na_counts,row.names=cov_names)\n\nWe drop missing values of the covariates:\n\ntse &lt;- tse[ , !is.na(colData(tse)$Delivery_Mode) ]\ntse &lt;- tse[ , !is.na(colData(tse)$Age_Years) ]\n\nWe agglomerate microbiome data to Phylum:\n\ntse_phylum &lt;- mergeFeaturesByRank(tse, \"Phylum\")\n\nWe extract the counts assay and covariate data to build the model matrix:\n\nY &lt;- assays(tse_phylum)$counts\n# design matrix\n# taking 3 covariates\nsample_data&lt;-as.data.frame(colData(tse_phylum)[,cov_names])\nX &lt;- t(model.matrix(~Sex+Age_Years+Delivery_Mode,data=sample_data))\n\nBuilding the parameters for the pibble call to build the model; see more at vignette:\n\nn_taxa&lt;-nrow(Y)\nupsilon &lt;- n_taxa+3\nOmega &lt;- diag(n_taxa)\nG &lt;- cbind(diag(n_taxa-1), -1)\nXi &lt;- (upsilon-n_taxa)*G%*%Omega%*%t(G)\nTheta &lt;- matrix(0, n_taxa-1, nrow(X))\nGamma &lt;- diag(nrow(X))\n\nAutomatically initializing the priors and visualizing their distributions:\n\npriors &lt;- pibble(NULL, X, upsilon, Theta, Gamma, Xi)\nnames_covariates(priors) &lt;- rownames(X)\nplot(priors, pars=\"Lambda\") + ggplot2::xlim(c(-5, 5))\n\nEstimating the posterior by including our response data Y. Note: Some computational failures could occur (see discussion) the arguments multDirichletBoot calcGradHess could be passed in such case.\n\npriors$Y &lt;- Y \nposterior &lt;- refit(priors, optim_method=\"adam\", multDirichletBoot=0.5) #calcGradHess=FALSE\n\nPrinting a summary about the posterior:\n\nppc_summary(posterior)\n\nPlotting the summary of the posterior distributions of the regression parameters:\n\nnames_categories(posterior) &lt;- rownames(Y)\nplot(posterior,par=\"Lambda\",focus.cov=rownames(X)[2:4])\n\nTaking a closer look at ‚ÄúSex‚Äù and ‚ÄúDelivery_Mode‚Äù:\n\nplot(posterior, par=\"Lambda\", focus.cov = rownames(X)[c(2,4)])"
  },
  {
    "objectID": "pages/97_extra_materials.html#interactive-3d-plots",
    "href": "pages/97_extra_materials.html#interactive-3d-plots",
    "title": "Appendix A ‚Äî Extra material",
    "section": "\nA.4 Interactive 3D Plots",
    "text": "A.4 Interactive 3D Plots\n\n# Load libraries\nlibrary(rgl)\nlibrary(plotly)\n\n\nlibrary(knitr)\nknitr::knit_hooks$set(webgl = hook_webgl)\n\nIn this section we make a 3D version of the earlier Visualizing the most dominant genus on PCoA (see Chapter¬†4), with the help of the plotly (Sievert 2020).\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n# Importing necessary libraries\nlibrary(curatedMetagenomicData)\nlibrary(dplyr)\nlibrary(DT)\nlibrary(mia)\nlibrary(scater)\n\n# Querying the data\ntse &lt;- sampleMetadata %&gt;%\n    filter(age &gt;= 18) %&gt;% # taking only data of age 18 or above\n    filter(!is.na(alcohol)) %&gt;% # excluding missing values\n    returnSamples(\"relative_abundance\")\n\ntse_Genus &lt;- mergeFeaturesByRank(tse, rank=\"genus\")\ntse_Genus &lt;- addPerSampleDominantFeatures(tse_Genus,assay.type=\"relative_abundance\", name = \"dominant_taxa\")\n\n# Performing PCoA with Bray-Curtis dissimilarity.\ntse_Genus &lt;- runMDS(tse_Genus, FUN = vegan::vegdist, ncomponents = 3,\n              name = \"PCoA_BC\", assay.type = \"relative_abundance\")\n\n# Getting the 6 top taxa\ntop_taxa &lt;- getTopFeatures(tse_Genus,top = 6, assay.type = \"relative_abundance\")\n\n# Naming all the rest of non top-taxa as \"Other\"\nmost_abundant &lt;- lapply(colData(tse_Genus)$dominant_taxa,\n                   function(x){if (x %in% top_taxa) {x} else {\"Other\"}})\n\n# Storing the previous results as a new column within colData\ncolData(tse_Genus)$most_abundant &lt;- as.character(most_abundant)\n\n# Calculating percentage of the most abundant\nmost_abundant_freq &lt;- table(as.character(most_abundant))\nmost_abundant_percent &lt;- round(most_abundant_freq/sum(most_abundant_freq)*100, 1)\n\n# Retrieving the explained variance\ne &lt;- attr(reducedDim(tse_Genus, \"PCoA_BC\"), \"eig\");\nvar_explained &lt;- e/sum(e[e&gt;0])*100"
  },
  {
    "objectID": "pages/90_acknowledgments.html",
    "href": "pages/90_acknowledgments.html",
    "title": "Appendix B ‚Äî Contributions",
    "section": "",
    "text": "Core team\nContributions to this Gitbook from the various developers are coordinated by:\n\nLeo Lahti, DSc, professor in Data Science at the Department of Computing, University of Turku, Finland, with a focus on computational microbiome analysis. Lahti obtained doctoral degree (DSc) from Aalto University in Finland (2010), developing probabilistic machine learning with applications to high-throughput life science data integration. Since then he has focused on microbiome research and developed, for instance, the phyloseq-based microbiome R package before starting to develop the TreeSummarizedExperiment / MultiAssayExperiment framework and the mia family of Bioconductor packages for microbiome data science introduced in this gitbook. Lahti led the development of national policy on open access to research methods in Finland. He is current member in the Bioconductor Community Advisory Board and runs regular training workshops in microbiome data science.\nTuomas Borman, PhD researcher and the lead developer of OMA/mia at the Department of Computing, University of Turku.\nContributors\nThis work is a remarkably collaborative effort. The full list of contributors is available via Github. Some key authors/contributors include:\n\nFelix Ernst, PhD, among the first developers of R/Bioc methods for microbiome research based on the SummarizedExperiment class and its derivatives.\nGiulio Benedetti, scientific programmer at the Department of Computing, University of Turku. His research interest is mostly related to Data Science. He has also helped to expand the SummarizedExperiment-based microbiome analysis framework to the Julia language, implementing MicrobiomeAnalysis.jl.\nSudarshan Shetty, PhD has supported the establishment of the framework and associated tools. He also maintains a list of microbiome R packages.\nHenrik Eckermann, in particular to the development of the differential abundance analyses\nChouaib Benchraka provided various contributions to the package ecosystem and the OMA book\nYaƒümur ≈ûim≈üek converted the miaSim R package to support the Bioconductor framework\nBasil Courbayre provided various contributions to the package ecosystem and the OMA book, in particular on unsupervised machine learning\nMatti Ruuskanen, PhD, added machine learning techniques for microbiome analysis\nStefanie Peschel has contributed chapters on the construction, analysis, and comparison of microbial association networks.\nChristian L. M√ºller, group leader at the Computational Health Center, Helmholtz Zentrum M√ºnchen, Germany and a Professor for Biomedical Statistics and Data Science at LMU Munich. He assisted in writing the chapters on network learning and comparison.\nShigdel Rajesh, PhD\nArtur Sannikov\nJeba Akewak\nHimmi Lindgren\nLu Yang\nJacques Serizay converted the OMA book to the BiocBook format. This allows the OMA book to be built and distributed by Bioconductor.\nAcknowledgments\nThis work would not have been possible without the countless contributions and interactions with other researchers, developers, and users. We express our gratitude to the entire Bioconductor community for developing this high-quality open research software repository for life science analytics, continuously pushing the limits in emerging fields (Gentleman et al. 2004), (Huber et al. 2015).\n\nGentleman, Robert C, Vincent J Carey, Douglas M Bates, Ben Bolstad, Marcel Dettling, Sandrine Dudoit, Byron Ellis, et al. 2004. ‚ÄúBioconductor: Open Software Development for Computational Biology and Bioinformatics.‚Äù Genome Biology 5: R80.\n\nHuber, W., V. J. Carey, R. Gentleman, S. Anders, M. Carlson, B. S. Carvalho, H. C. Bravo, et al. 2015. ‚ÄúOrchestrating High-Throughput Genomic Analysis with Bioconductor.‚Äù Nature Methods 12 (2): 115‚Äì21. http://www.nature.com/nmeth/journal/v12/n2/full/nmeth.3252.html.\n\nHuang, Ruizhu. 2020. TreeSummarizedExperiment: A S4 Class for Data with Tree Structures.\n\nErnst, F. G. M., S. A. Shetty, R. Huang, Braccia D. J., Bravo H. C., and L. Lahti. 2020. ‚ÄúThe Emerging r Ecosystem for Microbiome Research.‚Äù F1000Research 9. https://doi.org/10.7490/f1000research.1118445.1.\n\nRamos, Marcel, Lucas Schiffer, Angela Re, Rimsha Azhar, Azfar Basunia, Carmen Rodriguez Cabrera, Tiffany Chan, et al. 2017. ‚ÄúSoftware for the Integration of Multiomics Experiments in Bioconductor.‚Äù Cancer Research. https://doi.org/10.1158/0008-5472.CAN-17-0344.\n\nShetty, Sudarshan, and Leo Lahti. 2019. ‚ÄúMicrobiome Data Science.‚Äù Journal of Biosciences 44: 115. https://doi.org/10.1007/s12038-019-9930-2.\nThe presented framework for microbiome data science is based on the TreeSummarizedExperiment data container created by Ruizhu Huang and others (Huang 2020), (Ernst et al. 2020), and on the MultiAssayExperiment by Marcel Ramos et al. (Ramos et al. 2017). The idea of using these containers as a basis for microbiome data science was initially advanced by the groundwork of Domenick Braccia, H√©ctor Corrada Bravo and others and brought together with other microbiome data science developers (Shetty and Lahti 2019). Setting up the base ecosystem of packages and tutorials was then subsequently led by Tuomas Borman, Felix Ernst, and Leo Lahti. We would specifically like to thank everyone who contributed to the work supporting the TreeSummarizedExperiment ecosystem for microbiome research, including but not limited to the R packages mia, miaViz, miaTime, miaSim, philr, ANCOMBC, curatedMetagenomicData, scater, scuttle, and other packages, some of which are listed in Section Section¬†1.2. A number of other contributors have advanced the ecosystem further, and will be acknowledged in the individual packages, pull requests, issues, and other work.\nAmple demonstration data resources supporting this framework have been made available through the curatedMetagenomicData project by Edoardo Pasolli, Lucas Schiffer, Levi Waldron and others (Pasolli et al. 2017).\n\nPasolli, E, L Schiffer, P Manghi, A Renson, V Obenchain, D Truong, F Beghini, et al. 2017. ‚ÄúAccessible, Curated Metagenomic Data Through ExperimentHub.‚Äù Nature Methods 14: 1023‚Äì24. https://doi.org/10.1038/nmeth.4468.\n\nMcMurdie, PJ, and S Holmes. 2013. ‚ÄúPhyloseq: An r Package for Reproducible Interactive Analysis and Graphics of Microbiome Census Data.‚Äù PLoS ONE 8: e61217. https://doi.org/10.1371/journal.pone.0061217.\n\nAmezquita, Robert A., Aaron T. L. Lun, Etienne Becht, Vince J. Carey, Lindsay N. Carpp, Ludwig Geistlinger, Federico Marini, et al. 2020. ‚ÄúOrchestrating Single-Cell Analysis with Bioconductor.‚Äù Nature Methods 17: 137‚Äì45. https://doi.org/10.1038/s41592-019-0654-x.\nThe work has drawn initial inspiration from many sources, most notably from the work on phyloseq by Paul McMurdie and Susan Holmes (McMurdie and Holmes 2013) who pioneered the work on rigorous and reproducible microbiome data science ecosystems in R/Bioconductor. The phyloseq framework continues to provide a vast array of complementary packages and methods for microbiome studies. The Orchestrating Single-Cell Analysis with Bioconductor, or OSCA book by Robert Amezquita, Aaron Lun, Stephanie Hicks, and Raphael Gottardo (Amezquita et al. 2020) has implemented closely related work on the SummarizedExperiment data container and its derivatives in the field of single cell sequencing studies that have inspired this work.\nIn the background, the open source books by Susan Holmes and Wolfgang Huber, Modern Statistics for Modern Biology (Holmes and Huber 2019) and by Garret Grolemund and Hadley Wickham, the R for Data Science (Grolemund and Wickham 2017), and Richard McElreath‚Äôs Statistical Rethinking and the associated online resources by Solomon Kurz (McElreath 2020) are key references that have advanced reproducible data science training and dissemination.\n\nHolmes, Susan, and Wolfgang Huber. 2019. Modern Statistics for Modern Biology. New York, NY: Cambridge University Press. https://www.huber.embl.de/msmb/.\n\nGrolemund, Garret, and Hadley Wickham. 2017. R for Data Science. Vol. 77(21); e39‚Äì42. O‚ÄôReilly.\n\nMcElreath, R. 2020. Statistical Rethinking. Chapman; Hall/CRC.\n\nB.0.1 How to contribute\nTo contribute reports, follow the Git flow procedure (you can see instructions to getting started with Github):\n\nFork the project\nClone your fork\nModify the material\nCheck locally that the changes render successfully (see above)\nAdd and commit the changes to your fork\nCreate a pull request (PR) from your fork back to the original repo\nFix and discuss issues in the review process\n\nMore detailed instructions for contributing can be found on OMA README.\nSupport\nThis work has been supported by:\n\nResearch Council of Finland\nFindingPheno European Union‚Äôs Horizon 2020 research and innovation programme under grant agreement No 952914\nCOST Action network on Statistical and Machine Learning Techniques for Human Microbiome Studies (ML4microbiome) (Moreno-Indias et al. 2021).\nComputational Life Science Research Program, Biocity Turku\nTurku University Foundation\n\n\n\n\nMoreno-Indias, Isabel, Leo Lahti, Miroslava Nedyalkova, Ilze Elbere, Gennady V. Roshchupkin, Muhamed Adilovic, Onder Aydemir, et al. 2021. ‚ÄúStatistical and Machine Learning Techniques in Human Microbiome Studies: Contemporary Challenges and Solutions.‚Äù Frontiers in Microbiology 12: 277. https://doi.org/10.3389/fmicb.2021.635781.\n\n Back to top"
  },
  {
    "objectID": "pages/Session_info.html",
    "href": "pages/Session_info.html",
    "title": "Appendix C ‚Äî Session info",
    "section": "",
    "text": "sessioninfo::session_info(\n    installed.packages()[,\"Package\"], \n    include_base = TRUE\n)\n##  ‚îÄ Session info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n##   setting  value\n##   version  R Under development (unstable) (2023-11-22 r85609)\n##   os       Ubuntu 22.04.3 LTS\n##   system   x86_64, linux-gnu\n##   ui       X11\n##   language (EN)\n##   collate  C\n##   ctype    en_US.UTF-8\n##   tz       Etc/UTC\n##   date     2023-12-13\n##   pandoc   3.1.1 @ /usr/local/bin/ (via rmarkdown)\n##  \n##  ‚îÄ Packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n##   package                  * version    date (UTC) lib source\n##   abind                      1.4-5      2016-07-21 [2] CRAN (R 4.4.0)\n##   additivityTests            1.1-4.1    2022-06-24 [2] CRAN (R 4.4.0)\n##   ade4                       1.7-22     2023-02-06 [2] CRAN (R 4.4.0)\n##   ALDEx2                     1.35.0     2023-10-24 [2] Bioconductor\n##   ANCOMBC                    2.5.0      2023-10-24 [2] Bioconductor\n##   AnnotationDbi              1.65.2     2023-11-03 [2] Bioconductor\n##   AnnotationHub              3.11.1     2023-12-11 [2] Bioconductor 3.19 (R 4.4.0)\n##   ape                        5.7-1      2023-03-13 [2] CRAN (R 4.4.0)\n##   aplot                      0.2.2      2023-10-06 [2] CRAN (R 4.4.0)\n##   arrayhelpers               1.1-0      2020-02-04 [2] CRAN (R 4.4.0)\n##   askpass                    1.2.0      2023-09-03 [2] CRAN (R 4.4.0)\n##   assertthat                 0.2.1      2019-03-21 [1] CRAN (R 4.4.0)\n##   available                  1.1.0      2022-07-10 [2] CRAN (R 4.4.0)\n##   backports                  1.4.1      2021-12-13 [2] CRAN (R 4.4.0)\n##   base                     * 4.4.0      2023-11-26 [3] local\n##   base64enc                  0.1-3      2015-07-28 [2] CRAN (R 4.4.0)\n##   beachmat                   2.19.0     2023-10-24 [2] Bioconductor\n##   beeswarm                   0.4.0      2021-06-01 [2] CRAN (R 4.4.0)\n##   BH                         1.81.0-1   2023-01-22 [2] CRAN (R 4.4.0)\n##   biclust                    2.0.3.1    2023-05-19 [2] CRAN (R 4.4.0)\n##   biglm                      0.9-2.1    2020-11-27 [2] CRAN (R 4.4.0)\n##   Biobase                    2.62.0     2023-12-13 [1] bioc_xgit (@8201fbb)\n##   BiocBaseUtils              1.5.0      2023-10-24 [2] Bioconductor\n##   BiocBook                   1.1.1      2023-11-17 [2] Bioconductor 3.19 (R 4.4.0)\n##   BiocFileCache              2.11.1     2023-10-26 [2] Bioconductor\n##   BiocGenerics               0.49.1     2023-11-01 [2] Bioconductor\n##   BiocManager                1.30.22    2023-08-08 [2] CRAN (R 4.4.0)\n##   BiocNeighbors              1.21.1     2023-11-30 [2] Bioconductor 3.19 (R 4.4.0)\n##   BiocParallel               1.37.0     2023-10-24 [2] Bioconductor\n##   BiocSingular               1.19.0     2023-10-24 [2] Bioconductor\n##   BiocStyle                  2.31.0     2023-10-24 [2] Bioconductor\n##   BiocVersion                3.19.1     2023-10-26 [2] Bioconductor\n##   biomformat                 1.31.0     2023-10-24 [2] Bioconductor\n##   Biostrings                 2.71.1     2023-10-25 [2] Bioconductor\n##   bit                        4.0.5      2022-11-15 [2] CRAN (R 4.4.0)\n##   bit64                      4.0.5      2020-08-30 [2] CRAN (R 4.4.0)\n##   bitops                     1.0-7      2021-04-24 [2] CRAN (R 4.4.0)\n##   blob                       1.2.4      2023-03-17 [2] CRAN (R 4.4.0)\n##   bluster                    1.13.0     2023-10-24 [2] Bioconductor\n##   bookdown                   0.37       2023-12-01 [2] CRAN (R 4.4.0)\n##   boot                       1.3-28.1   2022-11-22 [3] CRAN (R 4.4.0)\n##   brew                       1.0-8      2022-09-29 [2] CRAN (R 4.4.0)\n##   brio                       1.1.4      2023-12-10 [2] CRAN (R 4.4.0)\n##   broom                      1.0.5      2023-06-09 [2] CRAN (R 4.4.0)\n##   bslib                      0.6.1      2023-11-28 [2] CRAN (R 4.4.0)\n##   ca                         0.71.1     2020-01-24 [2] CRAN (R 4.4.0)\n##   cachem                     1.0.8      2023-05-01 [2] CRAN (R 4.4.0)\n##   Cairo                      1.6-2      2023-11-28 [2] CRAN (R 4.4.0)\n##   callr                      3.7.3      2022-11-02 [2] CRAN (R 4.4.0)\n##   car                        3.1-2      2023-03-30 [2] CRAN (R 4.4.0)\n##   carData                    3.0-5      2022-01-06 [2] CRAN (R 4.4.0)\n##   caret                      6.0-94     2023-03-21 [2] CRAN (R 4.4.0)\n##   caTools                    1.18.2     2021-03-28 [2] CRAN (R 4.4.0)\n##   cellranger                 1.1.0      2016-07-27 [2] CRAN (R 4.4.0)\n##   checkmate                  2.3.1      2023-12-04 [2] CRAN (R 4.4.0)\n##   chemometrics               1.4.4      2023-08-25 [2] CRAN (R 4.4.0)\n##   circlize                   0.4.15     2022-05-10 [2] CRAN (R 4.4.0)\n##   class                      7.3-22     2023-05-03 [3] CRAN (R 4.4.0)\n##   cli                        3.6.2      2023-12-11 [2] CRAN (R 4.4.0)\n##   clipr                      0.8.0      2022-02-22 [2] CRAN (R 4.4.0)\n##   clisymbols                 1.2.0      2017-05-21 [2] CRAN (R 4.4.0)\n##   clock                      0.7.0      2023-05-15 [2] CRAN (R 4.4.0)\n##   clue                       0.3-65     2023-09-23 [2] CRAN (R 4.4.0)\n##   cluster                    2.1.6      2023-12-01 [3] CRAN (R 4.4.0)\n##   cobiclust                  0.1.0      2018-10-15 [2] CRAN (R 4.4.0)\n##   coda                       0.19-4     2020-09-30 [2] CRAN (R 4.4.0)\n##   CodeDepends                0.6.5      2018-07-17 [2] CRAN (R 4.4.0)\n##   codetools                  0.2-19     2023-02-01 [3] CRAN (R 4.4.0)\n##   colorspace                 2.1-0      2023-01-23 [2] CRAN (R 4.4.0)\n##   commonmark                 1.9.0      2023-03-17 [2] CRAN (R 4.4.0)\n##   compiler                   4.4.0      2023-11-26 [3] local\n##   ComplexHeatmap             2.19.0     2023-10-24 [2] Bioconductor\n##   conflicted                 1.2.0      2023-02-01 [2] CRAN (R 4.4.0)\n##   corpcor                    1.6.10     2021-09-16 [2] CRAN (R 4.4.0)\n##   corrplot                   0.92       2021-11-18 [2] CRAN (R 4.4.0)\n##   cowplot                    1.1.1      2020-12-30 [2] CRAN (R 4.4.0)\n##   cplm                       0.7-11     2023-04-18 [2] CRAN (R 4.4.0)\n##   cpp11                      0.4.7      2023-12-02 [2] CRAN (R 4.4.0)\n##   crayon                     1.5.2      2022-09-29 [2] CRAN (R 4.4.0)\n##   credentials                2.0.1      2023-09-06 [2] CRAN (R 4.4.0)\n##   crosstalk                  1.2.1      2023-11-23 [2] CRAN (R 4.4.0)\n##   cubature                   2.1.0      2023-06-11 [1] CRAN (R 4.4.0)\n##   curatedMetagenomicData     3.11.0     2023-10-31 [2] Bioconductor\n##   curl                       5.2.0      2023-12-08 [2] CRAN (R 4.4.0)\n##   CVXR                       1.0-11     2022-10-30 [2] CRAN (R 4.4.0)\n##   data.table                 1.14.10    2023-12-08 [2] CRAN (R 4.4.0)\n##   datasets                 * 4.4.0      2023-11-26 [3] local\n##   DBI                        1.1.3      2022-06-18 [2] CRAN (R 4.4.0)\n##   dbplyr                     2.4.0      2023-10-26 [2] CRAN (R 4.4.0)\n##   DECIPHER                   2.31.0     2023-10-24 [2] Bioconductor\n##   decontam                   1.23.0     2023-10-24 [2] Bioconductor\n##   DelayedArray               0.29.0     2023-10-24 [2] Bioconductor\n##   DelayedMatrixStats         1.25.1     2023-11-09 [2] Bioconductor\n##   deldir                     2.0-2      2023-11-23 [2] CRAN (R 4.4.0)\n##   dendextend                 1.17.1     2023-03-25 [2] CRAN (R 4.4.0)\n##   DEoptimR                   1.1-3      2023-10-07 [2] CRAN (R 4.4.0)\n##   desc                       1.4.3      2023-12-10 [2] CRAN (R 4.4.0)\n##   DescTools                  0.99.52    2023-12-01 [2] CRAN (R 4.4.0)\n##   devtools                   2.4.5      2022-10-11 [2] CRAN (R 4.4.0)\n##   diagram                    1.6.5      2020-09-30 [2] CRAN (R 4.4.0)\n##   diffobj                    0.3.5      2021-10-05 [2] CRAN (R 4.4.0)\n##   digest                     0.6.33     2023-07-07 [2] CRAN (R 4.4.0)\n##   dir.expiry                 1.11.0     2023-10-24 [2] Bioconductor\n##   directlabels               2023.8.25  2023-09-01 [2] CRAN (R 4.4.0)\n##   DirichletMultinomial       1.45.0     2023-10-24 [2] Bioconductor\n##   dirmult                    0.1.3-5    2022-03-21 [2] CRAN (R 4.4.0)\n##   distributional             0.3.2      2023-03-22 [2] CRAN (R 4.4.0)\n##   docopt                     0.7.1      2020-06-24 [2] CRAN (R 4.4.0)\n##   doFuture                   1.0.0      2023-03-24 [1] CRAN (R 4.4.0)\n##   doParallel                 1.0.17     2022-02-07 [2] CRAN (R 4.4.0)\n##   doRNG                      1.8.6      2023-01-16 [2] CRAN (R 4.4.0)\n##   doSNOW                     1.0.20     2022-02-04 [1] CRAN (R 4.4.0)\n##   downlit                    0.4.3      2023-06-29 [2] CRAN (R 4.4.0)\n##   dplyr                      1.1.4      2023-11-17 [2] CRAN (R 4.4.0)\n##   dqrng                      0.3.2      2023-11-29 [2] CRAN (R 4.4.0)\n##   DT                         0.31       2023-12-09 [2] CRAN (R 4.4.0)\n##   dtplyr                     1.3.1      2023-03-22 [2] CRAN (R 4.4.0)\n##   dynamicTreeCut             1.63-1     2016-03-11 [1] CRAN (R 4.4.0)\n##   e1071                      1.7-14     2023-12-06 [2] CRAN (R 4.4.0)\n##   ECOSolveR                  0.5.5      2023-05-15 [2] CRAN (R 4.4.0)\n##   edgeR                      4.1.3      2023-12-10 [2] Bioconductor 3.19 (R 4.4.0)\n##   egg                        0.4.5      2019-07-13 [1] CRAN (R 4.4.0)\n##   ellipsis                   0.3.2      2021-04-29 [2] CRAN (R 4.4.0)\n##   energy                     1.7-11     2022-12-22 [2] CRAN (R 4.4.0)\n##   evaluate                   0.23       2023-11-01 [2] CRAN (R 4.4.0)\n##   Exact                      3.2        2022-09-25 [2] CRAN (R 4.4.0)\n##   ExperimentHub              2.11.1     2023-12-11 [2] Bioconductor 3.19 (R 4.4.0)\n##   expm                       0.999-8    2023-11-29 [2] CRAN (R 4.4.0)\n##   fansi                      1.0.6      2023-12-08 [2] CRAN (R 4.4.0)\n##   farver                     2.1.1      2022-07-06 [2] CRAN (R 4.4.0)\n##   fastcluster                1.2.3      2021-05-24 [1] CRAN (R 4.4.0)\n##   fastmap                    1.1.1      2023-02-24 [2] CRAN (R 4.4.0)\n##   fBasics                    4032.96    2023-11-03 [2] CRAN (R 4.4.0)\n##   fdrtool                    1.2.17     2021-11-13 [1] CRAN (R 4.4.0)\n##   fido                       1.0.4      2023-03-24 [2] CRAN (R 4.4.0)\n##   filelock                   1.0.3      2023-12-11 [2] CRAN (R 4.4.0)\n##   filematrix                 1.3        2018-02-27 [1] CRAN (R 4.4.0)\n##   flexclust                  1.4-1      2022-04-08 [2] CRAN (R 4.4.0)\n##   fMultivar                  4031.84    2023-07-11 [1] CRAN (R 4.4.0)\n##   FNN                        1.1.3.2    2023-03-20 [2] CRAN (R 4.4.0)\n##   fontawesome                0.5.2      2023-08-19 [2] CRAN (R 4.4.0)\n##   forcats                    1.0.0      2023-01-29 [2] CRAN (R 4.4.0)\n##   foreach                    1.5.2      2022-02-02 [2] CRAN (R 4.4.0)\n##   foreign                    0.8-86     2023-11-28 [3] CRAN (R 4.4.0)\n##   formatR                    1.14       2023-01-17 [2] CRAN (R 4.4.0)\n##   Formula                    1.2-5      2023-02-24 [2] CRAN (R 4.4.0)\n##   fs                         1.6.3      2023-07-20 [2] CRAN (R 4.4.0)\n##   futile.logger              1.4.3      2016-07-10 [2] CRAN (R 4.4.0)\n##   futile.options             1.0.1      2018-04-20 [2] CRAN (R 4.4.0)\n##   future                     1.33.0     2023-07-01 [2] CRAN (R 4.4.0)\n##   future.apply               1.11.0     2023-05-21 [2] CRAN (R 4.4.0)\n##   gargle                     1.5.2      2023-07-20 [2] CRAN (R 4.4.0)\n##   gclus                      1.3.2      2019-01-07 [2] CRAN (R 4.4.0)\n##   generics                   0.1.3      2022-07-05 [2] CRAN (R 4.4.0)\n##   GenomeInfoDb               1.39.1     2023-11-08 [2] Bioconductor\n##   GenomeInfoDbData           1.2.11     2023-12-12 [2] Bioconductor\n##   GenomicRanges              1.55.1     2023-10-29 [2] Bioconductor\n##   geometry                   0.4.7      2023-02-03 [1] CRAN (R 4.4.0)\n##   gert                       2.0.1      2023-12-04 [2] CRAN (R 4.4.0)\n##   getopt                     1.20.4     2023-10-01 [2] CRAN (R 4.4.0)\n##   GetoptLong                 1.0.5      2020-12-15 [2] CRAN (R 4.4.0)\n##   ggbeeswarm                 0.7.2      2023-04-29 [2] CRAN (R 4.4.0)\n##   ggdist                     3.3.1      2023-11-27 [2] CRAN (R 4.4.0)\n##   ggforce                    0.4.1      2022-10-04 [2] CRAN (R 4.4.0)\n##   ggfun                      0.1.3      2023-09-15 [2] CRAN (R 4.4.0)\n##   ggnewscale                 0.4.9      2023-05-25 [2] CRAN (R 4.4.0)\n##   ggplot2                    3.4.4      2023-10-12 [2] CRAN (R 4.4.0)\n##   ggplotify                  0.1.2      2023-08-09 [2] CRAN (R 4.4.0)\n##   ggpubr                     0.6.0      2023-02-10 [2] CRAN (R 4.4.0)\n##   ggraph                     2.1.0      2022-10-09 [2] CRAN (R 4.4.0)\n##   ggrastr                    1.0.2      2023-06-01 [2] CRAN (R 4.4.0)\n##   ggrepel                    0.9.4      2023-10-13 [2] CRAN (R 4.4.0)\n##   ggsci                      3.0.0      2023-03-08 [2] CRAN (R 4.4.0)\n##   ggsignif                   0.6.4      2022-10-13 [2] CRAN (R 4.4.0)\n##   ggtree                     3.11.0     2023-10-24 [2] Bioconductor\n##   gh                         1.4.0      2023-02-22 [2] CRAN (R 4.4.0)\n##   gitcreds                   0.1.2      2022-09-08 [2] CRAN (R 4.4.0)\n##   glasso                     1.11       2019-10-01 [1] CRAN (R 4.4.0)\n##   gld                        2.6.6      2022-10-23 [2] CRAN (R 4.4.0)\n##   glmmTMB                    1.1.8      2023-10-07 [2] CRAN (R 4.4.0)\n##   glmnet                     4.1-8      2023-08-22 [2] CRAN (R 4.4.0)\n##   GlobalOptions              0.1.2      2020-06-10 [2] CRAN (R 4.4.0)\n##   globals                    0.16.2     2022-11-21 [2] CRAN (R 4.4.0)\n##   glue                       1.6.2      2022-02-24 [2] CRAN (R 4.4.0)\n##   gmp                        0.7-3      2023-11-28 [2] CRAN (R 4.4.0)\n##   GO.db                      3.18.0     2023-12-13 [1] Bioconductor\n##   googledrive                2.1.1      2023-06-11 [2] CRAN (R 4.4.0)\n##   googlesheets4              1.1.1      2023-06-11 [2] CRAN (R 4.4.0)\n##   gower                      1.0.1      2022-12-22 [2] CRAN (R 4.4.0)\n##   gplots                     3.1.3      2022-04-25 [2] CRAN (R 4.4.0)\n##   graph                      1.81.0     2023-10-24 [2] Bioconductor\n##   graphics                 * 4.4.0      2023-11-26 [3] local\n##   graphlayouts               1.0.2      2023-11-03 [2] CRAN (R 4.4.0)\n##   grDevices                * 4.4.0      2023-11-26 [3] local\n##   grid                       4.4.0      2023-11-26 [3] local\n##   gridExtra                  2.3        2017-09-09 [2] CRAN (R 4.4.0)\n##   gridGraphics               0.5-1      2020-12-13 [2] CRAN (R 4.4.0)\n##   gsl                        2.1-8      2023-01-24 [2] CRAN (R 4.4.0)\n##   gss                        2.2-7      2023-08-16 [2] CRAN (R 4.4.0)\n##   gtable                     0.3.4      2023-08-21 [2] CRAN (R 4.4.0)\n##   gtools                     3.9.5      2023-11-20 [2] CRAN (R 4.4.0)\n##   GUniFrac                   1.8        2023-09-14 [2] CRAN (R 4.4.0)\n##   hardhat                    1.3.0      2023-03-30 [2] CRAN (R 4.4.0)\n##   hash                       2.2.6.3    2023-08-19 [2] CRAN (R 4.4.0)\n##   haven                      2.5.4      2023-11-30 [2] CRAN (R 4.4.0)\n##   heatmaply                  1.5.0      2023-10-06 [1] CRAN (R 4.4.0)\n##   here                       1.0.1      2020-12-13 [2] CRAN (R 4.4.0)\n##   highr                      0.10       2022-12-22 [2] CRAN (R 4.4.0)\n##   Hmisc                      5.1-1      2023-09-12 [2] CRAN (R 4.4.0)\n##   hms                        1.1.3      2023-03-21 [2] CRAN (R 4.4.0)\n##   htmlTable                  2.4.2      2023-10-29 [2] CRAN (R 4.4.0)\n##   htmltools                  0.5.7      2023-11-03 [2] CRAN (R 4.4.0)\n##   htmlwidgets                1.6.4      2023-12-06 [2] CRAN (R 4.4.0)\n##   httpuv                     1.6.13     2023-12-06 [2] CRAN (R 4.4.0)\n##   httr                       1.4.7      2023-08-15 [2] CRAN (R 4.4.0)\n##   httr2                      1.0.0      2023-11-14 [2] CRAN (R 4.4.0)\n##   huge                       1.3.5      2021-06-30 [1] CRAN (R 4.4.0)\n##   ids                        1.0.1      2017-05-31 [2] CRAN (R 4.4.0)\n##   igraph                     1.6.0      2023-12-11 [2] CRAN (R 4.4.0)\n##   impute                     1.77.0     2023-10-24 [1] Bioconductor\n##   ini                        0.3.1      2018-05-20 [2] CRAN (R 4.4.0)\n##   inline                     0.3.19     2021-05-31 [2] CRAN (R 4.4.0)\n##   interp                     1.1-5      2023-11-27 [2] CRAN (R 4.4.0)\n##   ipred                      0.9-14     2023-03-09 [2] CRAN (R 4.4.0)\n##   IRanges                    2.37.0     2023-10-24 [2] Bioconductor\n##   irlba                      2.3.5.1    2022-10-03 [2] CRAN (R 4.4.0)\n##   isoband                    0.2.7      2022-12-20 [2] CRAN (R 4.4.0)\n##   iterators                  1.0.14     2022-02-05 [2] CRAN (R 4.4.0)\n##   janeaustenr                1.0.0      2022-08-26 [2] CRAN (R 4.4.0)\n##   jpeg                       0.1-10     2022-11-29 [2] CRAN (R 4.4.0)\n##   jquerylib                  0.1.4      2021-04-26 [2] CRAN (R 4.4.0)\n##   jsonlite                   1.8.8      2023-12-04 [2] CRAN (R 4.4.0)\n##   kableExtra                 1.3.4      2021-02-20 [2] CRAN (R 4.4.0)\n##   KEGGREST                   1.43.0     2023-10-24 [2] Bioconductor\n##   kernlab                    0.9-32     2023-01-31 [2] CRAN (R 4.4.0)\n##   KernSmooth                 2.23-22    2023-07-10 [3] CRAN (R 4.4.0)\n##   knitr                      1.45       2023-10-30 [2] CRAN (R 4.4.0)\n##   labeling                   0.4.3      2023-08-29 [2] CRAN (R 4.4.0)\n##   lambda.r                   1.2.4      2019-09-18 [2] CRAN (R 4.4.0)\n##   lars                       1.3        2022-04-13 [2] CRAN (R 4.4.0)\n##   latentcor                  2.0.1      2022-09-05 [1] CRAN (R 4.4.0)\n##   later                      1.3.2      2023-12-06 [2] CRAN (R 4.4.0)\n##   lattice                    0.22-5     2023-10-24 [3] CRAN (R 4.4.0)\n##   latticeExtra               0.6-30     2022-07-04 [2] CRAN (R 4.4.0)\n##   lava                       1.7.3      2023-11-04 [2] CRAN (R 4.4.0)\n##   lavaan                     0.6-16     2023-07-19 [1] CRAN (R 4.4.0)\n##   lazyeval                   0.2.2      2019-03-15 [2] CRAN (R 4.4.0)\n##   lifecycle                  1.0.4      2023-11-07 [2] CRAN (R 4.4.0)\n##   limma                      3.59.1     2023-10-30 [2] Bioconductor\n##   linprog                    0.9-4      2022-03-09 [1] CRAN (R 4.4.0)\n##   listenv                    0.9.0      2022-12-16 [2] CRAN (R 4.4.0)\n##   littler                    0.3.18     2023-03-26 [2] CRAN (R 4.4.0)\n##   lme4                       1.1-35.1   2023-11-05 [2] CRAN (R 4.4.0)\n##   lmerTest                   3.1-3      2020-10-23 [2] CRAN (R 4.4.0)\n##   lmom                       3.0        2023-08-29 [2] CRAN (R 4.4.0)\n##   locfit                     1.5-9.8    2023-06-11 [2] CRAN (R 4.4.0)\n##   logging                    0.10-108   2019-07-14 [2] CRAN (R 4.4.0)\n##   lpSolve                    5.6.20     2023-12-10 [1] CRAN (R 4.4.0)\n##   lubridate                  1.9.3      2023-09-27 [2] CRAN (R 4.4.0)\n##   Maaslin2                   1.17.0     2023-10-24 [2] Bioconductor\n##   magic                      1.6-1      2022-11-16 [1] CRAN (R 4.4.0)\n##   magrittr                   2.0.3      2022-03-30 [2] CRAN (R 4.4.0)\n##   MASS                       7.3-60.1   2023-11-26 [3] local\n##   Matrix                     1.6-4      2023-11-30 [3] CRAN (R 4.4.0)\n##   MatrixGenerics             1.15.0     2023-10-24 [2] Bioconductor\n##   MatrixModels               0.5-3      2023-11-06 [2] CRAN (R 4.4.0)\n##   matrixStats                1.2.0      2023-12-11 [2] CRAN (R 4.4.0)\n##   mclust                     6.0.1      2023-11-15 [2] CRAN (R 4.4.0)\n##   memoise                    2.0.1      2021-11-26 [2] CRAN (R 4.4.0)\n##   metagenomeSeq              1.45.0     2023-10-24 [2] Bioconductor\n##   methods                  * 4.4.0      2023-11-26 [3] local\n##   mgcv                       1.9-0      2023-07-11 [3] CRAN (R 4.4.0)\n##   mia                        1.11.0     2023-10-24 [2] Bioconductor\n##   miaTime                    0.1.21     2023-12-12 [2] Github (microbiome/miaTime@9fe9771)\n##   miaViz                     1.11.0     2023-10-25 [2] Bioconductor\n##   microbenchmark             1.4.10     2023-04-28 [1] CRAN (R 4.4.0)\n##   microbiomeDataSets         1.11.0     2023-10-26 [2] Bioconductor\n##   MicrobiomeStat             1.1        2022-01-24 [2] CRAN (R 4.4.0)\n##   mikropml                   1.6.1      2023-08-21 [2] CRAN (R 4.4.0)\n##   mime                       0.12       2021-09-28 [2] CRAN (R 4.4.0)\n##   miniUI                     0.1.1.1    2018-05-18 [2] CRAN (R 4.4.0)\n##   minqa                      1.2.6      2023-09-11 [2] CRAN (R 4.4.0)\n##   mixedCCA                   1.6.2      2023-12-13 [1] Github (irinagain/mixedCCA@4c2b63f)\n##   MLeval                     0.3        2020-02-12 [2] CRAN (R 4.4.0)\n##   MLmetrics                  1.1.1      2016-05-13 [2] CRAN (R 4.4.0)\n##   mnormt                     2.1.1      2022-09-26 [1] CRAN (R 4.4.0)\n##   modeest                    2.4.0      2019-11-18 [2] CRAN (R 4.4.0)\n##   ModelMetrics               1.2.2.2    2020-03-17 [2] CRAN (R 4.4.0)\n##   modelr                     0.1.11     2023-03-22 [2] CRAN (R 4.4.0)\n##   modeltools                 0.2-23     2020-03-05 [2] CRAN (R 4.4.0)\n##   multcomp                   1.4-25     2023-06-20 [2] CRAN (R 4.4.0)\n##   MultiAssayExperiment       1.29.0     2023-10-24 [2] Bioconductor\n##   multtest                   2.59.0     2023-10-24 [2] Bioconductor\n##   munsell                    0.5.0      2018-06-12 [2] CRAN (R 4.4.0)\n##   mvtnorm                    1.2-4      2023-11-27 [2] CRAN (R 4.4.0)\n##   NADA                       1.6-1.1    2020-03-22 [2] CRAN (R 4.4.0)\n##   NbClust                    3.0.1      2022-05-02 [2] CRAN (R 4.4.0)\n##   NetCoMi                    1.1.0.9000 2023-12-13 [1] Github (stefpeschel/NetCoMi@03abaf1)\n##   nlme                       3.1-164    2023-11-27 [3] CRAN (R 4.4.0)\n##   nloptr                     2.0.3      2022-05-26 [2] CRAN (R 4.4.0)\n##   nnet                       7.3-19     2023-05-03 [3] CRAN (R 4.4.0)\n##   numDeriv                   2016.8-1.1 2019-06-06 [2] CRAN (R 4.4.0)\n##   OMA                        0.98.16    2023-12-12 [1] Bioconductor\n##   openssl                    2.1.1      2023-09-25 [2] CRAN (R 4.4.0)\n##   optparse                   1.7.3      2022-07-20 [2] CRAN (R 4.4.0)\n##   orca                       1.1-1      2016-07-28 [1] CRAN (R 4.4.0)\n##   osqp                       0.6.3.2    2023-10-20 [2] CRAN (R 4.4.0)\n##   packrat                    0.9.2      2023-09-05 [2] CRAN (R 4.4.0)\n##   parallel                   4.4.0      2023-11-26 [3] local\n##   parallelly                 1.36.0     2023-05-26 [2] CRAN (R 4.4.0)\n##   patchwork                  1.1.3      2023-08-14 [2] CRAN (R 4.4.0)\n##   pbapply                    1.7-2      2023-06-27 [2] CRAN (R 4.4.0)\n##   pbivnorm                   0.6.0      2015-01-23 [1] CRAN (R 4.4.0)\n##   pbkrtest                   0.5.2      2023-01-19 [2] CRAN (R 4.4.0)\n##   pcaPP                      2.0-4      2023-12-07 [2] CRAN (R 4.4.0)\n##   permute                    0.9-7      2022-01-27 [2] CRAN (R 4.4.0)\n##   pheatmap                   1.0.12     2019-01-04 [2] CRAN (R 4.4.0)\n##   phyloseq                   1.46.0     2023-12-13 [1] bioc_xgit (@7320133)\n##   pillar                     1.9.0      2023-03-22 [2] CRAN (R 4.4.0)\n##   pixmap                     0.4-12     2021-01-29 [2] CRAN (R 4.4.0)\n##   pkgbuild                   1.4.3      2023-12-10 [2] CRAN (R 4.4.0)\n##   pkgconfig                  2.0.3      2019-09-22 [2] CRAN (R 4.4.0)\n##   pkgdown                    2.0.7      2022-12-14 [2] CRAN (R 4.4.0)\n##   pkgload                    1.3.3      2023-09-22 [2] CRAN (R 4.4.0)\n##   plogr                      0.2.0      2018-03-25 [2] CRAN (R 4.4.0)\n##   plotly                     4.10.3     2023-10-21 [2] CRAN (R 4.4.0)\n##   pls                        2.8-3      2023-11-17 [2] CRAN (R 4.4.0)\n##   plyr                       1.8.9      2023-10-02 [2] CRAN (R 4.4.0)\n##   png                        0.1-8      2022-11-29 [2] CRAN (R 4.4.0)\n##   polyclip                   1.10-6     2023-09-27 [2] CRAN (R 4.4.0)\n##   polynom                    1.4-1      2022-04-11 [2] CRAN (R 4.4.0)\n##   posterior                  1.5.0      2023-10-31 [2] CRAN (R 4.4.0)\n##   praise                     1.0.0      2015-08-11 [2] CRAN (R 4.4.0)\n##   preprocessCore             1.65.0     2023-10-24 [2] Bioconductor\n##   prettyunits                1.2.0      2023-09-24 [2] CRAN (R 4.4.0)\n##   pROC                       1.18.5     2023-11-01 [2] CRAN (R 4.4.0)\n##   processx                   3.8.3      2023-12-10 [2] CRAN (R 4.4.0)\n##   prodlim                    2023.08.28 2023-08-28 [2] CRAN (R 4.4.0)\n##   profvis                    0.3.8      2023-05-02 [2] CRAN (R 4.4.0)\n##   progress                   1.2.3      2023-12-06 [2] CRAN (R 4.4.0)\n##   progressr                  0.14.0     2023-08-10 [2] CRAN (R 4.4.0)\n##   promises                   1.2.1      2023-08-10 [2] CRAN (R 4.4.0)\n##   proxy                      0.4-27     2022-06-09 [2] CRAN (R 4.4.0)\n##   ps                         1.7.5      2023-04-18 [2] CRAN (R 4.4.0)\n##   pscl                       1.5.5.1    2023-05-10 [2] CRAN (R 4.4.0)\n##   psych                      2.3.9      2023-09-26 [1] CRAN (R 4.4.0)\n##   pulsar                     0.3.11     2023-09-24 [1] CRAN (R 4.4.0)\n##   purrr                      1.0.2      2023-08-10 [2] CRAN (R 4.4.0)\n##   qap                        0.1-2      2022-06-27 [2] CRAN (R 4.4.0)\n##   qgraph                     1.9.8      2023-11-03 [1] CRAN (R 4.4.0)\n##   quadprog                   1.5-8      2019-11-20 [2] CRAN (R 4.4.0)\n##   quantreg                   5.97       2023-08-19 [2] CRAN (R 4.4.0)\n##   quarto                     1.3        2023-09-19 [2] CRAN (R 4.4.0)\n##   R6                         2.5.1      2021-08-19 [2] CRAN (R 4.4.0)\n##   ragg                       1.2.7      2023-12-11 [2] CRAN (R 4.4.0)\n##   randomcoloR                1.1.0.1    2019-11-24 [2] CRAN (R 4.4.0)\n##   randomForest               4.7-1.1    2022-05-23 [2] CRAN (R 4.4.0)\n##   rappdirs                   0.3.3      2021-01-31 [2] CRAN (R 4.4.0)\n##   rbibutils                  2.2.16     2023-10-25 [2] CRAN (R 4.4.0)\n##   rcmdcheck                  1.4.0      2021-09-27 [2] CRAN (R 4.4.0)\n##   RColorBrewer               1.1-3      2022-04-03 [2] CRAN (R 4.4.0)\n##   Rcpp                       1.0.11     2023-07-06 [2] CRAN (R 4.4.0)\n##   RcppAnnoy                  0.0.21     2023-07-02 [2] CRAN (R 4.4.0)\n##   RcppArmadillo              0.12.6.6.1 2023-12-04 [2] CRAN (R 4.4.0)\n##   RcppEigen                  0.3.3.9.4  2023-11-02 [2] CRAN (R 4.4.0)\n##   RcppGSL                    0.3.13     2023-01-13 [2] CRAN (R 4.4.0)\n##   RcppHNSW                   0.5.0      2023-09-19 [2] CRAN (R 4.4.0)\n##   RcppML                     0.3.7      2021-09-21 [2] CRAN (R 4.4.0)\n##   RcppNumerical              0.6-0      2023-09-06 [2] CRAN (R 4.4.0)\n##   RcppParallel               5.1.7      2023-02-27 [2] CRAN (R 4.4.0)\n##   RcppProgress               0.4.2      2020-02-06 [2] CRAN (R 4.4.0)\n##   RcppTOML                   0.2.2      2023-01-29 [2] CRAN (R 4.4.0)\n##   RcppZiggurat               0.1.6      2020-10-20 [2] CRAN (R 4.4.0)\n##   RCurl                      1.98-1.13  2023-11-02 [2] CRAN (R 4.4.0)\n##   Rdpack                     2.6        2023-11-08 [2] CRAN (R 4.4.0)\n##   readr                      2.1.4      2023-02-10 [2] CRAN (R 4.4.0)\n##   readxl                     1.4.3      2023-07-06 [2] CRAN (R 4.4.0)\n##   rebook                     1.13.0     2023-10-24 [2] Bioconductor\n##   recipes                    1.0.8      2023-08-25 [2] CRAN (R 4.4.0)\n##   registry                   0.5-1      2019-03-05 [2] CRAN (R 4.4.0)\n##   rematch                    2.0.0      2023-08-30 [2] CRAN (R 4.4.0)\n##   rematch2                   2.1.2      2020-05-01 [2] CRAN (R 4.4.0)\n##   remotes                    2.4.2.1    2023-07-18 [2] CRAN (R 4.4.0)\n##   renv                       1.0.3      2023-09-19 [2] CRAN (R 4.4.0)\n##   reprex                     2.0.2      2022-08-17 [2] CRAN (R 4.4.0)\n##   reshape2                   1.4.4      2020-04-09 [2] CRAN (R 4.4.0)\n##   reticulate                 1.34.0     2023-10-12 [2] CRAN (R 4.4.0)\n##   Rfast                      2.1.0      2023-11-09 [2] CRAN (R 4.4.0)\n##   rgl                        1.2.8      2023-11-29 [2] CRAN (R 4.4.0)\n##   rhdf5                      2.47.1     2023-11-29 [2] Bioconductor 3.19 (R 4.4.0)\n##   rhdf5filters               1.15.1     2023-11-06 [2] Bioconductor\n##   Rhdf5lib                   1.25.1     2023-12-11 [2] Bioconductor 3.19 (R 4.4.0)\n##   rjson                      0.2.21     2022-01-09 [2] CRAN (R 4.4.0)\n##   rlang                      1.1.2      2023-11-04 [2] CRAN (R 4.4.0)\n##   rmarkdown                  2.25       2023-09-18 [2] CRAN (R 4.4.0)\n##   Rmpfr                      0.9-4      2023-12-04 [2] CRAN (R 4.4.0)\n##   rmutil                     1.1.10     2022-10-27 [2] CRAN (R 4.4.0)\n##   rngtools                   1.5.2      2021-09-20 [2] CRAN (R 4.4.0)\n##   robustbase                 0.99-1     2023-11-29 [2] CRAN (R 4.4.0)\n##   ROCR                       1.0-11     2020-05-02 [2] CRAN (R 4.4.0)\n##   rootSolve                  1.8.2.4    2023-09-21 [2] CRAN (R 4.4.0)\n##   roxygen2                   7.2.3      2022-12-08 [2] CRAN (R 4.4.0)\n##   rpart                      4.1.23     2023-12-05 [3] CRAN (R 4.4.0)\n##   rprojroot                  2.0.4      2023-11-05 [2] CRAN (R 4.4.0)\n##   rsconnect                  1.1.1      2023-10-04 [2] CRAN (R 4.4.0)\n##   RSQLite                    2.3.4      2023-12-08 [2] CRAN (R 4.4.0)\n##   rstatix                    0.7.2      2023-02-01 [2] CRAN (R 4.4.0)\n##   rstudioapi                 0.15.0     2023-07-07 [2] CRAN (R 4.4.0)\n##   rsvd                       1.0.5      2021-04-16 [2] CRAN (R 4.4.0)\n##   Rtsne                      0.17       2023-12-07 [2] CRAN (R 4.4.0)\n##   rversions                  2.1.2      2022-08-31 [2] CRAN (R 4.4.0)\n##   rvest                      1.0.3      2022-08-19 [2] CRAN (R 4.4.0)\n##   S4Arrays                   1.3.1      2023-11-27 [2] Bioconductor 3.19 (R 4.4.0)\n##   S4Vectors                  0.41.2     2023-11-23 [2] Bioconductor 3.19 (R 4.4.0)\n##   sandwich                   3.1-0      2023-12-11 [2] CRAN (R 4.4.0)\n##   sass                       0.4.8      2023-12-06 [2] CRAN (R 4.4.0)\n##   ScaledMatrix               1.11.0     2023-10-24 [2] Bioconductor\n##   scales                     1.3.0      2023-11-28 [2] CRAN (R 4.4.0)\n##   scater                     1.31.1     2023-11-16 [2] Bioconductor 3.19 (R 4.4.0)\n##   scs                        3.2.4      2023-04-11 [2] CRAN (R 4.4.0)\n##   scuttle                    1.13.0     2023-10-24 [2] Bioconductor\n##   sechm                      1.11.0     2023-10-24 [2] Bioconductor\n##   selectr                    0.4-2      2019-11-20 [2] CRAN (R 4.4.0)\n##   seriation                  1.5.4      2023-12-12 [2] CRAN (R 4.4.0)\n##   sessioninfo                1.2.2      2021-12-06 [2] CRAN (R 4.4.0)\n##   shape                      1.4.6      2021-05-19 [2] CRAN (R 4.4.0)\n##   shiny                      1.8.0      2023-11-17 [2] CRAN (R 4.4.0)\n##   SingleCellExperiment       1.25.0     2023-10-24 [2] Bioconductor\n##   sitmo                      2.0.2      2021-10-13 [2] CRAN (R 4.4.0)\n##   sn                         2.1.1      2023-04-04 [1] CRAN (R 4.4.0)\n##   snow                       0.4-4      2021-10-27 [2] CRAN (R 4.4.0)\n##   SnowballC                  0.7.1      2023-04-25 [2] CRAN (R 4.4.0)\n##   som                        0.3-5.1    2016-07-06 [2] CRAN (R 4.4.0)\n##   sourcetools                0.1.7-1    2023-02-01 [2] CRAN (R 4.4.0)\n##   sp                         2.1-2      2023-11-26 [2] CRAN (R 4.4.0)\n##   SparseArray                1.3.1      2023-11-07 [2] Bioconductor\n##   SparseM                    1.81       2021-02-18 [2] CRAN (R 4.4.0)\n##   sparseMatrixStats          1.15.0     2023-10-24 [2] Bioconductor\n##   spatial                    7.3-17     2023-07-20 [3] CRAN (R 4.4.0)\n##   SpiecEasi                  1.1.3      2023-12-13 [1] Github (zdk123/SpiecEasi@5f396da)\n##   splines                    4.4.0      2023-11-26 [3] local\n##   SPRING                     1.0.4      2023-12-13 [1] Github (GraceYoon/SPRING@3d641a4)\n##   SQUAREM                    2021.1     2021-01-13 [2] CRAN (R 4.4.0)\n##   stable                     1.1.6      2022-03-02 [2] CRAN (R 4.4.0)\n##   stabledist                 0.7-1      2016-09-12 [2] CRAN (R 4.4.0)\n##   statip                     0.2.3      2019-11-17 [2] CRAN (R 4.4.0)\n##   statmod                    1.5.0      2023-01-06 [2] CRAN (R 4.4.0)\n##   stats                    * 4.4.0      2023-11-26 [3] local\n##   stats4                     4.4.0      2023-11-26 [3] local\n##   stringdist                 0.9.12     2023-11-28 [2] CRAN (R 4.4.0)\n##   stringi                    1.8.3      2023-12-11 [2] CRAN (R 4.4.0)\n##   stringr                    1.5.1      2023-11-14 [2] CRAN (R 4.4.0)\n##   SummarizedExperiment       1.33.1     2023-11-28 [2] Bioconductor 3.19 (R 4.4.0)\n##   survival                   3.5-7      2023-08-14 [3] CRAN (R 4.4.0)\n##   svglite                    2.1.3      2023-12-08 [2] CRAN (R 4.4.0)\n##   svUnit                     1.0.6      2021-04-19 [2] CRAN (R 4.4.0)\n##   sys                        3.4.2      2023-05-23 [2] CRAN (R 4.4.0)\n##   systemfonts                1.0.5      2023-10-09 [2] CRAN (R 4.4.0)\n##   tcltk                      4.4.0      2023-11-26 [3] local\n##   tensorA                    0.36.2     2020-11-19 [2] CRAN (R 4.4.0)\n##   testthat                   3.2.1      2023-12-02 [2] CRAN (R 4.4.0)\n##   textshaping                0.3.7      2023-10-09 [2] CRAN (R 4.4.0)\n##   TH.data                    1.1-2      2023-04-17 [2] CRAN (R 4.4.0)\n##   tibble                     3.2.1      2023-03-20 [2] CRAN (R 4.4.0)\n##   tidybayes                  3.0.6      2023-08-12 [2] CRAN (R 4.4.0)\n##   tidygraph                  1.2.3      2023-02-01 [2] CRAN (R 4.4.0)\n##   tidyr                      1.3.0      2023-01-24 [2] CRAN (R 4.4.0)\n##   tidyselect                 1.2.0      2022-10-10 [2] CRAN (R 4.4.0)\n##   tidytext                   0.4.1      2023-01-07 [2] CRAN (R 4.4.0)\n##   tidytree                   0.4.6      2023-12-12 [2] CRAN (R 4.4.0)\n##   tidyverse                  2.0.0      2023-02-22 [2] CRAN (R 4.4.0)\n##   timechange                 0.2.0      2023-01-11 [2] CRAN (R 4.4.0)\n##   timeDate                   4022.108   2023-01-07 [2] CRAN (R 4.4.0)\n##   timeSeries                 4031.107   2023-08-26 [2] CRAN (R 4.4.0)\n##   tinytex                    0.49       2023-11-22 [2] CRAN (R 4.4.0)\n##   TMB                        1.9.10     2023-12-12 [2] CRAN (R 4.4.0)\n##   tokenizers                 0.3.0      2022-12-22 [2] CRAN (R 4.4.0)\n##   tools                      4.4.0      2023-11-26 [3] local\n##   treeio                     1.27.0     2023-10-24 [2] Bioconductor\n##   TreeSummarizedExperiment   2.11.0     2023-10-24 [2] Bioconductor\n##   truncnorm                  1.0-9      2023-03-20 [2] CRAN (R 4.4.0)\n##   TSP                        1.2-4      2023-04-04 [2] CRAN (R 4.4.0)\n##   tweedie                    2.3.5      2022-08-17 [2] CRAN (R 4.4.0)\n##   tweenr                     2.0.2      2022-09-06 [2] CRAN (R 4.4.0)\n##   tzdb                       0.4.0      2023-05-12 [2] CRAN (R 4.4.0)\n##   urlchecker                 1.0.1      2021-11-30 [2] CRAN (R 4.4.0)\n##   usethis                    2.2.2      2023-07-06 [2] CRAN (R 4.4.0)\n##   utf8                       1.2.4      2023-10-22 [2] CRAN (R 4.4.0)\n##   utils                    * 4.4.0      2023-11-26 [3] local\n##   uuid                       1.1-1      2023-08-17 [2] CRAN (R 4.4.0)\n##   uwot                       0.1.16     2023-06-29 [2] CRAN (R 4.4.0)\n##   V8                         4.4.1      2023-12-04 [2] CRAN (R 4.4.0)\n##   vctrs                      0.6.5      2023-12-01 [2] CRAN (R 4.4.0)\n##   vegan                      2.6-4      2022-10-11 [2] CRAN (R 4.4.0)\n##   VGAM                       1.1-9      2023-09-19 [1] CRAN (R 4.4.0)\n##   vipor                      0.4.5      2017-03-22 [2] CRAN (R 4.4.0)\n##   viridis                    0.6.4      2023-07-22 [2] CRAN (R 4.4.0)\n##   viridisLite                0.4.2      2023-05-02 [2] CRAN (R 4.4.0)\n##   vroom                      1.6.5      2023-12-05 [2] CRAN (R 4.4.0)\n##   waldo                      0.5.2      2023-11-02 [2] CRAN (R 4.4.0)\n##   webshot                    0.5.5      2023-06-26 [2] CRAN (R 4.4.0)\n##   WGCNA                      1.72-5     2023-12-07 [1] CRAN (R 4.4.0)\n##   whisker                    0.4.1      2022-12-05 [2] CRAN (R 4.4.0)\n##   withr                      2.5.2      2023-10-30 [2] CRAN (R 4.4.0)\n##   Wrench                     1.21.0     2023-10-24 [2] Bioconductor\n##   xfun                       0.41       2023-11-01 [2] CRAN (R 4.4.0)\n##   xgboost                    1.7.6.1    2023-12-06 [2] CRAN (R 4.4.0)\n##   XML                        3.99-0.16  2023-11-29 [2] CRAN (R 4.4.0)\n##   xml2                       1.3.6      2023-12-04 [2] CRAN (R 4.4.0)\n##   xopen                      1.0.0      2018-09-17 [2] CRAN (R 4.4.0)\n##   xtable                     1.8-4      2019-04-21 [2] CRAN (R 4.4.0)\n##   XVector                    0.43.0     2023-10-24 [2] Bioconductor\n##   yaml                       2.3.8      2023-12-11 [2] CRAN (R 4.4.0)\n##   yesno                      0.1.2      2020-07-10 [2] CRAN (R 4.4.0)\n##   yulab.utils                0.1.1      2023-12-11 [2] CRAN (R 4.4.0)\n##   zCompositions              1.5        2023-12-07 [2] CRAN (R 4.4.0)\n##   zip                        2.3.0      2023-04-17 [2] CRAN (R 4.4.0)\n##   zlibbioc                   1.49.0     2023-10-24 [2] Bioconductor\n##   zoo                        1.8-12     2023-04-13 [2] CRAN (R 4.4.0)\n##  \n##   [1] /tmp/Rtmpe5QBwZ/Rinstb8ef89be\n##   [2] /usr/local/lib/R/site-library\n##   [3] /usr/local/lib/R/library\n##  \n##  ‚îÄ Python configuration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n##   Python is not available\n##  \n##  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n\n\n\n Back to top"
  }
]