# Network learning and analysis {#network-learning}

```{r setup, echo=FALSE, results="asis"}
library(rebook)
chapterPreamble()
```

Learning and analyzing microbial association networks is another common exploratory data analysis approach aimed at understanding the complex interplay of microbial communities in their natural habitat. Microbial networks consist of nodes, representing microbial species or taxa, and edges, expressing their association. The mathematical representation of a network is the adjacency matrix, which has a non-zero entry for each edge in the network.

A typical workflow for estimating a microbial network involves several steps, including data preprocessing, estimating microbial associations, and transforming them into edge weights. The resulting network can be analyzed using local network properties, such as centrality measures, or global measures that describe the overall structure of the network. Network plots provide further insight into the microbial community structure and allow for exploratory analysis of microbial relationships.

In this chapter, we go through the complete workflow of constructing and analyzing a single microbial network, step by step. A potential next analysis task is to compare networks between groups, such as patients and controls, different environmental conditions, or different time points. How to compare networks between two groups is explained in chapter \@ref(network-comparison)

## Network learning

### Typical workflow {#network-learning-workflow}

Figure \@ref(fig:network-workflow) shows the workflow for learning/constructing a microbial association network as proposed by @peschel2021netcomi. The respective steps are explained below.

```{r network-workflow, echo=FALSE, out.width='100%', fig.cap='The typical input is a $p$ x $n$ dimensional count matrix coming from a sequencing process, where $n$ is the number of samples and $p$ the number of features / ASVs / OTUs. Steps 1 through 6 are explained below. Each matrix resulting from steps 4, 5, and 6 plays a specific role in the final network: The adjacency matrix is used for edge colors, dissimilarity for layout, and similarity for edge weights. In weighted networks, the similarity matrix equals the adjacency matrix.'}
knitr::include_graphics("general/figures/FigureNetworkLearning.png")
```

1.  **Zero replacement:** Since the following steps usually require non-zero entries in the read count matrix, zero counts must be replaced. A simple solution is to add a pseudo count to the data. Other possible approaches are implemented in the R package [zCompositions](https://cran.r-project.org/web/packages/zCompositions/index.html)

2.  **Normalization:** To avoid compositional effects, the data are normalized using a compositionality aware transformation. A common approach is the centered log-ratio (clr) transformation, which moves the data from a $p$-dimensional simplex to Euclidean space so that standard statistical analysis methods are valid. A variance stabilizing transformation (vst) is also a suitable approach for normalizing microbial count data [@badri2020shrinkage].

3.  **Association estimation:**

    -   **Correlation:** Two popular measures of ecological association are Pearson's correlation coefficient and Spearman's rank correlation coefficient, both of which can be inferred from empirical (sample) covariances. However, in the $p\gg n$ setting, which most microbiome datasets are in, sample covariances and correlations are unreliable because the parameters being estimated are typically underdetermined. One way to improve sample covariance estimates is to assume that the underlying covariance matrix is sparse and use a regularized covariance estimator to implement this structural assumption. The Schäfer-Strimmer shrinkage estimator [@schafer2005shrinkage] is one possible method for estimating a sparse correlation matrix. Other popular methods, especially designed to estimate correlations for compositional data, are SparCC ("Sparse Correlations for Compositional data") by @Friedman2012, CCREPE ("Compositionality Corrected by REnormalization and PErmutation") by @faust2012microbial, and CCLasso ("Correlation inference for Compositional data through Lasso") by @fang2015cclasso. The latter three methods already include a compositionality aware normalization, and SparCC also includes a zero replacement approach.

        **Compositionality aware correlation estimation methods:**
        -   Pearson's correlation coefficient (+ normalization)
        -   Spearman's rank correlation coefficient (+ normalization)
        -   Covariance shrinkage ([corpcor](https://strimmerlab.github.io/software/corpcor/) package) (+ normalization)
        -   SparCC (implemented in [SpiecEasi](https://rdrr.io/github/zdk123/SpiecEasi/man/sparcc.html)); applied in section \@ref(sparcc-correlation)
        -   CCREPE ([ccrepe](https://bioconductor.org/packages/release/bioc/html/ccrepe.html) package)
        -   CCLasso ([R code on GitHub](https://github.com/huayingfang/CCLasso))

    -   **Conditional dependence:** Since standard correlations include both direct and indirect dependencies, conditional dependence or partial correlation is often preferred for measuring association. Unlike (marginal) correlation, it expresses the relationship between two features conditioned on all other features in the data set. The approach and R package [SpiecEasi](https://github.com/zdk123/SpiecEasi) ("Sparse InversE Covariance estimation for Ecological Association and Statistical Inference") by @Kurtz2015 is specifically designed for inferring ecological networks from microbiome data and includes two approaches for estimating conditional dependence structures between taxa: Neighborhood Selection; short "MB" [@meinshausen2006high] and (inverse) covariance selection [@friedman2008sparse], which is based on a penalized maximum likelihood approach and is also known as "graphical lasso". Another approach and R package for inferring partial correlations from microbiome data is [SPRING](https://github.com/GraceYoon/SPRING) ("Semi-Parametric Rank-based approach for INference in Graphical model") by @yoon2019microbial. They also use the MB neighborhood selection method, but introduce a novel semi-parametric rank-based approach for sparse partial correlation estimation that can naturally handle the excess of zeros in the data. gCoda [@fang2017gcoda] is another conditional dependence measure based on penalized maximum likelihood estimation. All of the aforementionedconditional dependence measures address the high dimensionality of microbiome data.

        **Compositionality aware measures of conditional dependence / partial correlation:**
        -   [SpiecEasi](https://github.com/zdk123/SpiecEasi) with Meinshausen and Bühlmann (MB) neighborhood selection; applied in section \@ref(spieceasi-mb)
        -   [SpiecEasi](https://github.com/zdk123/SpiecEasi) with the graphical lasso (glasso)
        -   gCoda ([R code on GitHub](https://github.com/huayingfang/gCoda))
        -   [SPRING](https://github.com/GraceYoon/SPRING); applied in section \@ref(netcomi-spring)

    -   **Proportionality:** @lovell2015proportionality introduce proportionality as an alternative measure of pairwise association for compositional data. The idea is that if the relative abundances between two taxa $i$ and $j$ are proportional, then their corresponding absolute abundances are also proportional: $\frac{\omega_i}{m} \propto \frac{\omega_j}{m} \Rightarrow \omega_i \propto \omega_j$, where $m$ is the sum of counts in the sample. It follows that proportionality is identical for the observed (relative) read counts and the true unobserved counts. The proportionality measure proposed by @lovell2015proportionality is based on log-ratio variance $var(log \frac{x_i}{x_j})$, which is zero when $\omega_i$ and $\omega_j$ are perfectly proportional. Proportionality is implemented in the R package [propr](https://github.com/tpq/propr). @badri2020shrinkage extend the proportionality measure to a so-called "shrinkage proportionality estimator". It combines proportionality with the covariance shrinkage approach to obtain consistent association estimates even with small sample sizes.

        **Proportionality measures (proportionality aware by definition):**
        - [propr](https://github.com/tpq/propr)
        - [Shrinkage proportionality estimator](https://github.com/MichelleBadri/NormCorr-manuscript/blob/master/code/helpers/norm_functions.R); applied in section \@ref(shrinkage-prop) 
      

4.  **Sparsification:** Transforming the estimated associations directly into adjacencies would lead to a dense network where all nodes are connected and only weighted network measures are meaningful. Therefore, the association matrix is usually sparsified to select edges of interest. A common sparsification approach for correlations is thresholding, where correlations with a magnitude below the threshold are set to zero. Another possibility is a statistical test (Student's t-test or permutation test) with the null hypothesis that the correlation is equal to zero. SpiecEasi uses the StARS stability selection approach [@liu2010stability] to decide on an appropriate sparsification level of the inferred conditional dependence graph.

5.  **Transformation into dissimilarity:** A common next step is to simply use the absolute values of the sparsified associations as edge weights. In this way, correlations of high magnitude (both positive and negative) will have a high edge weight. From a biological point of view, it would also make sense to assign a low edge weight to taxa that are strongly negatively associated, which would correspond to a high dissimilarity value. Here we follow @vanDongen2012metric to directly transform the sparse associations $r_{ij}^*$ into dissimilarities, which can later be used for shortest path network measures. Depending on the desired handling of negative associations, one of the two proposed transformations should be chosen:

    5a: **"signed":** $d_{ij} = \sqrt{0.5(1-r^*_{ij})}$, where strongly negatively associated taxa have the largest distance and are placed further apart in the network.

    5b: **"unsigned":** $d_{ij} = \sqrt{1-{r_{ij}^*}^2}$, resulting in a small distance between strongly associated taxa (regardless of the sign).

6.  **Transformation into similarity / edge weight:** Finally, the dissimilarities are transformed into similarities by $s_{ij} = 1 - d_{ij}$, which are used as edge weights. Thus, the similarity matrix is equal to the adjacency matrix in a weighted network.

In the following, we show an application for each of the three types of association: correlation, proportionality, and partial correlation. 

We demonstrate the workflow using the the **PeerJ data set** [@potbhare2022skin]. It contains skin microbial profiles of 58 subjects.

```{r, message=FALSE, warning=FALSE}
library(mia)
```

```{r load_data}
data("peerj13075", package = "mia")
tse <- peerj13075
dim(tse)
```

```{r, echo=FALSE}
# The networks shown in this chapter take several minutes to generate. 
# Therefore, the network objects have been stored in a folder and are loaded 
# here to reduce the time needed to knit the book.
load("general/network_data/networks.RData")
```

### Install packages

Three packages used in this section are available on GitHub only: `SpiecEasi`, `SPRING`, and `NetCoMi`. We recommend that you install these packages before proceeding.

```{r install_packages}
if(!require(SpiecEasi)){
  devtools::install_github("zdk123/SpiecEasi")
}

if(!require(SPRING)){
  devtools::install_github("GraceYoon/SPRING")
}

if(!require(NetCoMi)){
  devtools::install_github("stefpeschel/NetCoMi", force = TRUE,
                           dependencies = c("Depends", "Imports", "LinkingTo"),
                           repos = c("https://cloud.r-project.org/",
                                     BiocManager::repositories()))
}
```


### Data preparation

Before we apply the network learning methods, we perform some data preparation steps similar to that in section \@ref(differential-abundance):

-   Aggregate to genus level (would not be necessary here since the data is already at genus level)
-   Prevalence filtering (keep genera with prevalence \> 20%)
-   Add assay with clr-transformed abundances

```{r preprocessing}
# Agglomerate by genus and subset by prevalence
tse <- subsetByPrevalentFeatures(tse,
                                 rank = "genus",
                                 prevalence = 0.2,
                                 detection = 0)

# Add clr-transformed abundances
tse <- transformAssay(tse, method="clr", pseudocount=1)

dim(tse)
```

Since we want to use the phylum names for node colors later in the network plot, we assign low abundant phyla to a new class "Other" to reduce the number of colors needed in the plot.

```{r}
# Assign low abundant phyla to a "Other" class
phyla <- rowData(tse)$phylum
low_abundant <- names(table(phyla)[table(phyla) <= 3])
phyla[phyla %in% low_abundant] <- "Other"
rowData(tse)$phylum <- phyla

# Take a look at the table
table(rowData(tse)$phylum)
```


### SparCC correlation {#sparcc-correlation}

The first association measure we look at is SparCC ("Sparse Correlations for Compositional data"), introduced by @Friedman2012. It estimates Pearson correlations while taking into account the compositional structure of the data. The [SpiecEasi](https://rdrr.io/github/zdk123/SpiecEasi/man/sparcc.html) package provides an implementation of this method.

```{r, eval=FALSE}
# Set seed for reproducibility
set.seed(13075)
# Compute correlation matrix
sparcc_cor <- SpiecEasi::sparcc(t(assay(tse, "counts")))$Cor
rownames(sparcc_cor) <- colnames(sparcc_cor) <- rownames(tse)
```

As explained in Section \@ref(network-learning-workflow), the estimated associations are then sparsified, transformed into dissimilarities, and finally transformed into similarities, which are the adjacency values. We write a function for these steps, which will be reused in the following subsections.

To be consistent with the workflow, we provide two dissimilarity transformations: "signed" and "unsigned" (see Section \@ref(network-learning-workflow) for an explanation). These transformations were introduced by @vanDongen2012metric. We use the "signed" transformation in our examples so that strongly negatively associated genera have low edge weights.

The output of the function is an `igraph` object, which can be plotted and analyzed using functions from the `igraph` package.

```{r transform_function}
# Arguments:
# - assoMat: association matrix
# - threshold: associations below the threshold are set to zero
# - dissTrans: dissimilarity transformation ("signed" or "unsigned")

transform_asso <- function(assoMat, thresh = NULL, dissTrans = "signed") {
  # Sparsification
  if (!is.null(thresh)) {
    assoMat[abs(assoMat) < thresh] <- 0
  }
  
  # Compute dissimilarity matrix
  if (dissTrans == "signed") {
    dissMat <- sqrt(0.5 * (1 - assoMat))
  } else {
    dissMat <- sqrt(1 - assoMat^2)
  }
  
  # Dissimilarity between nodes with zero correlation is set to 1
  # (these nodes are unconnected and thus should have maximum dissimilarity)
  dissMat[assoMat == 0] <- 1
  
  # Compute similarity matrix
  simMat <- 1 - dissMat
  
  # Turn into igraph object
  graphObj <- SpiecEasi::adj2igraph(simMat)
  
  return(list(graph = graphObj, adja = simMat, asso = assoMat, diss = dissMat))
}
```

Two threshold values are used to see the effect of sparsification later in the network plot.

```{r transform_sparcc}
sparcc_trans03 <- transform_asso(sparcc_cor, thresh = 0.3)
sparcc_trans04 <- transform_asso(sparcc_cor, thresh = 0.4)

sparcc_graph03 <- sparcc_trans03$graph
sparcc_graph04 <- sparcc_trans04$graph
```

### Shrinkage proportionality {#shrinkage-prop}

In the second example, microbial associations are measured by proportionality, originally introduced by @lovell2015proportionality. We use the shrinkage proportionality estimator proposed by @badri2020shrinkage, which gives consistent results even for small sample sizes. Since there is no R package implementing this estimator, we use the `rho_shrink_est()` function provided in the [GitHub repository](https://github.com/MichelleBadri/NormCorr-manuscript/blob/master/code/helpers/norm_functions.R) associated with the paper. The function is slightly modified to take normalized counts as input.

```{r, message=FALSE, warning=FALSE}
library(corpcor)
```

```{r}
# norm_counts: clr-transformed count matrix with samples in rows
rho_shrink_est <- function(norm_counts, ...) {
  shrunk_cov <- cov.shrink(norm_counts, ...)
  p <- ncol(norm_counts)
  J <- matrix(rep(diag(shrunk_cov), p), p)
  rho <- 2 * shrunk_cov / (J + t(J))
  (rho + t(rho)) / 2
}
```

```{r compute_shrink_prop}
# Apply the shrinkage proportionality estimator to the clr-transformed counts
prop_est <- as(rho_shrink_est(t(assay(tse, "clr"))), "matrix")
```

Again, we use our transformation function to convert the association matrix into a graph object.

```{r transform_shrink_prop}
prop_trans <- transform_asso(prop_est, thresh = 0.4)
prop_graph <- prop_trans$graph
```

### SpiecEasi - MB {#spieceasi-mb}

The third association measure introduced is partial correlation (or conditional dependence). We use the SpiecEasi ("Sparse InversE Covariance estimation for Ecological Association and Statistical Inference") approach proposed by @Kurtz2015 to estimate a sparse correlation matrix. The neighborhood selection method ("MB") introduced by @meinshausen2006high is used for network learning. The approach is implemented in the R package [SpiecEasi](https://github.com/zdk123/SpiecEasi). 

```{r, message=FALSE, warning=FALSE}
library(SpiecEasi)
```

```{r, eval=FALSE}
set.seed(13075)
se_mb_est <- spiec.easi(t(assay(tse, "counts")), 
                        method = 'mb', nlambda = 20, 
                        pulsar.params = list(rep.num = 20))
```

Since `SpiecEasi` uses the StARS ("Stability Approach to Regularization Selection") method [@liu2010stability] to obtain a sparse association matrix, we don't need to set a threshold here. We store the partial correlations corresponding to the StARS-optimal lambda and convert them into an `igraph` object.

```{r transform_se_mb}
# Get optimal matrix with partial correlations
se_mb_cor <- as.matrix(getOptBeta(se_mb_est))
se_mb_cor <- as.matrix(symBeta(se_mb_cor))
rownames(se_mb_cor) <- colnames(se_mb_cor) <- rownames(tse)
diag(se_mb_cor) <- 1

# Create graph object
se_mb_graph <- transform_asso(se_mb_cor)$graph
```

### Network plots

The graph objects can now be plotted using the [igraph](https://r.igraph.org/) package, which is a state-of-the-art package for network analysis and visualization. Other packages that could be used for network plotting are the [qgraph](https://rdrr.io/cran/qgraph/) package or the [ggnet2](https://briatte.github.io/ggnet/) package. Since we are going to use igraph for network analysis later on, we are using its plotting function here as well.

The four graph objects are plotted side-by-side using the same layout so that the networks are comparable.

```{r, message=FALSE, warning=FALSE}
library(igraph)
```

```{r nets_sparcc_prop_se, fig.height=10, fig.width=10}
# Node sizes
vsize <- colMeans(t(assay(tse, "clr"))) + 6

# Use Fruchterman-Reingold (force-directed) layout
set.seed(13075)
lay_fr <- layout_with_fr(se_mb_graph)

par(mfrow = c(2,2))
plot(sparcc_graph03, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "SparCC (thresh 0.3)")
plot(sparcc_graph04, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "SparCC (thresh 0.4)")
plot(prop_graph, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "Shrinkage proportionality\n(thresh 0.4)")
plot(se_mb_graph, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "SpiecEasi (MB)")
```
**A view observations:**  
The density of SparCC (threshold 0.4), proportionality and SpiecEasi is comparable, while the SparCC correlation network with threshold 0.3 is much denser. However, there are edges in the proportionality and SpiecEasi networks that are not present in the two correlation networks. The SpiecEasi network has less highly connected nodes than the other three networks, but more nodes with one or two connections.

We will look at the degree distribution in Section \@ref(network-analysis) to quantify these observations.

### NetCoMi - SPRING {#netcomi-spring}

The [NetCoMi](https://github.com/stefpeschel/NetCoMi) [@peschel2021netcomi] package is specifically designed to construct, analyze, and compare networks for microbiome data and implements the complete workflow described in Section \@ref(network-learning-workflow). Instead of using several functions for each of the steps, `NetCoMi` provides a single function for network construction (`netConstruct()`), so the package streamlines the workflow considerably. The user can choose from a variety of methods for data preprocessing, association estimation, sparsification, and transformation. The returned `microNet` object can then be passed to `netAnalyze()` (the network analysis function) so that all necessary information is available for the network analysis workflow.
 
```{r, message=FALSE, warning=FALSE}
library(NetCoMi)
```

We use the [SPRING](https://github.com/GraceYoon/SPRING) ("Semi-Parametric Rank-based approach for INference in Graphical model") method proposed by @yoon2019microbial to demonstrate the use of `NetCoMi`. SPRING is another approach to learn a conditional dependence graph for compositional data.

To demonstrate how taxa are filtered with `netConstruct()`, we use the unfiltered `tse` object, which has been agglomerated to genus level. The filtering is the same as before: Taxa occurring in less than 20% of the samples are removed.

```{r netcomi_net_single, eval=FALSE}
spring_net <- netConstruct(tse,
                           taxRank = "genus",
                           filtTax = "numbSamp",
                           filtTaxPar = list(numbSamp = 0.2),
                           measure = "spring",
                           measurePar = list(nlambda = 20, 
                                             rep.num = 20,
                                             thresh = 0.05,
                                             Rmethod = "approx"),
                           sparsMethod = "none", 
                           dissFunc = "signed",
                           seed = 13075)
```

`netConstruct()` returns an object of the class `microNet`, which contains all matrices generated during network construction.

The object also contains an edge list, giving each edge's estimated association, dissimilarity, and adjacency. Let's take a quick look at the edges with the highest and lowest edge weights:

```{r edge_list}
edgelist <- spring_net$edgelist1[order(spring_net$edgelist1$adja, decreasing = TRUE), ]
head(edgelist)
tail(edgelist)
```

To compare all three network learning approaches considered in this section, we again generate some basic network plots using the `igraph` package.

We compare the SPRING network to two previously created networks: Sparcc (with threshold 0.4) and SpiecEasi with MB.

As before, the adjacency matrix is converted into an `igraph` object. Further steps like sparsification and transformation are not necessary because they are done internally by `netConstruct()`.

```{r transform_spring, fig.height=4, fig.width=10}
spring_graph <- SpiecEasi::adj2igraph(abs(spring_net$adjaMat1))
```

```{r nets_sparcc_se_spring, fig.height=4, fig.width=10}
par(mfrow = c(1,3))
plot(sparcc_graph04, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "SparCC (thresh 0.4)")
plot(se_mb_graph, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "SpiecEasi (MB)")
plot(spring_graph, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "NetCoMi (SPRING)")
```

The sparsity level of the `SpiecEasi` and `NetCoMi` networks is comparable (which we would expect since we used the same StARS threshold of 0.05), but there is a significant amount of edges that are different. The `SparCC` network is even more different, which is also expected since `SparCC` estimates Pearson correlations instead of conditional dependence. 

These findings are in line with those described by @yoon2019microbial, except that they used a modification of `SparCC`, called "invSparCC", which combines the original SparCC approach with the MB method.

## Network analysis {#network-analysis}

The computed networks are now analyzed using appropriate methods. The `igraph` package will be used first. Later we will use NetCoMi's `netAnalyze()` function to analyze the constructed `microNet` object.

In the following, we will focus on the `SPRING` network and compare it to other previously created networks only when appropriate.

### Network analysis with igraph

We start by creating a list with all graph objects that we will need later.

```{r graphlist}
graphlist <- list(SparCC = sparcc_graph04, 
                  Proportionality = prop_graph,
                  SpiecEasi = se_mb_graph,
                  SPRING = spring_graph)
```

#### Centrality measures

Centrality measures express the importance of nodes within the network. Common measures are the degree, betweenness, closeness, and eigenvector centrality. The `igraph` package provides functions to compute these measures.

```{r}
centr_df <- data.frame(degree = igraph::degree(spring_graph))
centr_df$betweenness <- igraph::betweenness(spring_graph)
centr_df$closeness <- igraph::closeness(spring_graph)
centr_df$eigenvec <- igraph::eigen_centrality(spring_graph)$vector

rownames(centr_df) <- rownames(spring_net$adjaMat1)
head(centr_df, 15)
```

#### Scale node sizes by degree

Centrality measures can be visualized in the network plot by scaling the node sizes according to one of these measures. We plot the four networks based on SparCC, Proportionality, SpiecEasi, and SPRING once more, but this time we scale the node sizes by their degrees. The layout is the same as before. The `igraph` plot function is again used for the visualization.

```{r netplot_degree, fig.width=7, fig.height=7, out.width='80%'}
deglist <- lapply(graphlist, igraph::degree)
```

```{r, fig.height=10, fig.width=10}
par(mfrow = c(2,2))
for (i in seq_along(graphlist)) {
  plot(graphlist[[i]], layout = lay_fr, vertex.size = deglist[[i]], 
     vertex.label = NA, main = names(graphlist)[i])
}
```

#### Degree distribution

The degree distribution is another popular measure that expresses the probability distribution of degrees over the entire network. It thus provides insight into the overall network structure. We plot the degree distribution for all four association estimation methods to compare the network structure.

```{r, message=FALSE, warning=FALSE}
library(ggplot2)
```

```{r}
# Compute degree distributions
ddlist <- lapply(graphlist, igraph::degree.distribution)

# Maximum degree
maxdeg <- max(lengths(ddlist))

# Make list elements the same length
for(i in seq_along(graphlist)) {
  length(ddlist[[i]]) <- maxdeg
}

# Data frame needed for ggplot2
df <- data.frame(Degree = rep(1:maxdeg, length(graphlist)), 
                 Fraction = unlist(ddlist), 
                 Method = rep(names(graphlist), each = maxdeg))

ggplot(df, aes(x = Degree, y = Fraction, group = Method)) +
  geom_line(aes(color = Method)) +
  geom_point(aes(color = Method)) +
  theme_bw()
```

The SparCC and shrinkage proportionality networks have a considerably higher proportion of singletons (zero-degree nodes) than the two conditional dependency graphs, but a lower proportion of nodes with degrees between one and five. The MB and SPRING graphs, on the other hand, have a higher proportion of low degree nodes, but no highly connected nodes with a degree greater than eleven.

#### Clustered heatmaps

Using the `ComplexHeatmap` package, we plot heatmaps of the association matrices for the four considered association measures. Rows and columns are sorted according to the clusters identified via hierarchical clustering.

```{r, message=FALSE, warning=FALSE}
library(ComplexHeatmap)
library(circlize)
library(patchwork)
```

For each association measure, we select the 50 nodes with the highest sum of edge weights.

```{r select_nodes}
# Function for selecting taxa with highest sum of edge weights
select_taxa <- function(adja, ntaxa = 50) {
  sel <- names(sort(rowSums(adja), decreasing = TRUE))[1:ntaxa]
  adja[sel, sel]
}

assolist <- list()
assolist$SparCC <- select_taxa(sparcc_trans04$adja)
assolist$Proportionality <- select_taxa(prop_trans$adja)
assolist$SpiecEasi <- select_taxa(se_mb_cor)
assolist$SPRING <- select_taxa(spring_net$assoEst1)
```


```{r clustered_heatmap, fig.width=10, fig.height=10}
# Color vector for the legend
col <- colorRamp2(c(-1, -0.5, 0, 0.5, 1), 
                  c("royalblue4", "lightblue", "white", "orange", "firebrick3"))

hm_list <- list()

for(i in seq_along(assolist)) {
  if (i %in% c(2, 4)) {
    showlegend <- TRUE
  } else {
    showlegend <- FALSE
  }
  
  hm_list[[i]] <- Heatmap(assolist[[i]], 
                          col = col, 
                          rect_gp = gpar(col = "gray", lwd = 1),
                          show_row_names = FALSE, 
                          show_column_names = FALSE,
                          column_title = names(assolist)[i], 
                          name = "Association",
                          show_heatmap_legend = showlegend) %>% 
    draw() %>% 
    grid.grabExpr()
}

# Plot with wrap_plots() function from patchwork package
wrap_plots(hm_list, ncol = 2, widths = c(8, 10, 8, 10))
```


The SparCC and the proportionality network show a block structure, where each block corresponds to a cluster. The clusters are less pronounced in the conditional dependence networks. The latter also generally have lower edge weights.

#### Global network measures

Global measures describe the overall network structure. We take a look at three common measures: density, transitivity, and average path length. The values are computed with `igraph` functions.

##### Density

Definition: Proportion of present edges from all possible edges.

```{r glob_density}
# Compute density and store in a data frame
glob <- data.frame(Density = unlist(lapply(graphlist, edge_density)))
```

##### Transitivity (clustering coefficient)

Here, we consider only the global clustering coefficient, which is defined as the ratio of triangles to connected triples.

```{r glob_transitivity}
glob$Transitivity <- unlist(lapply(graphlist, transitivity))
```

##### Average path length

Definition: Mean of the shortest distance between each pair of nodes.

```{r glob_avpath}
glob$Av.path <- unlist(lapply(graphlist, average.path.length))
```

```{r}
glob
```

### Network analysis with NetCoMi

The `spring_net` object of class `microNet` created before is now passed to `netAnalyze()` to perform network analysis with `NetCoMi`.

The function computes several common network characteristics such as centrality measures, cluster assignment, the graphlet correlation matrix, as well as global network measures.

The user has several options to choose from, such as a clustering method, how to define hubs, and whether or not to normalize centrality values. See the help page `?netAnalyze` for a description of the arguments.

By default, a heatmap of the Graphlet Correlation Matrix (GCM) is returned (with graphlet correlations in the upper triangle and significance codes resulting from Student's t-test in the lower triangle). See `?calcGCM` and `?testGCM` for details.

```{r netAnalyze_single, fig.width=7, fig.height=7, out.width='75%'}
spring_netprops <- netAnalyze(spring_net, 
                              clustMethod = "cluster_fast_greedy",
                              hubPar = "eigenvector",
                              normDeg = FALSE)
```

```{r summary_single}
summary(spring_netprops, numbNodes = 5)

spring_netprops$globalProps$avPath1
```

**Interpretation of some findings:**

-   The largest connected component (LCC) has `r spring_netprops$compSize1[1, 1]` nodes and the network contains `r spring_netprops$compSize1[2, spring_netprops$compSize1[1, ] == 1]` singletons.
-   `r max(spring_netprops$clustering$clust1)` clusters have been identified, containing `r min(table(spring_netprops$clustering$clust1)[-1])` to `r max(table(spring_netprops$clustering$clust1)[-1])` nodes.
-   There are `r length(spring_netprops$hubs$hubs1)` hub nodes detected, which by definition are the nodes with the highest eigenvector centrality.
  -   The average path length in the whole network is `r spring_netprops$globalProps$avPath1`. This means that on average it takes `r spring_netprops$globalProps$avPath1` steps (step length is the average dissimilarity) to get from one node to another node in the network. Note that the average path length in `NetCoMi` is defined differently than in the `igraph` package, which is why the values differ.
-   Low values of edge density and the connectivity measures indicate that the network is rather sparse and not robust to perturbations (i.e., removal of nodes or edges).

## Network visualization

Further insight into the network structure can be gained by visualizing the network. We have already seen examples of how to plot a network using the `igraph` package. Here we will use NetCoMi's plot function. It takes as input the `microNetProps` object returned by `netAnalyze()`, which contains all computed network properties. This has the advantage that the user can choose which properties to plot by simply changing some arguments. The plot function is based on [qgraph](https://rdrr.io/cran/qgraph/), which is another state-of-the-art R package for network visualization. The help page can be accessed via `?plot.microNetProps`.

### Highlight node properties

In the first plot, node colors represent the detected clusters and node sizes are scaled by eigenvector centrality. Hub nodes are highlighted by default. Singletons are not included in the plot. To improve the readability, NetCoMi's "intelligent" label shortening approach is used.

Note that nodes are sometimes placed too close together so that the labels overlap. You may need to play around with the repulsion argument until you find a value where the labels are legible, but also the clusters are still well recognizable.

```{r network_plot_single_cluster, fig.width=13, fig.height=10}
plot(spring_netprops,
     repulsion = 0.98,
     rmSingles = TRUE,
     shortenLabels = "intelligent",
     labelScale = FALSE,
     nodeSize = "eigenvector",
     nodeSizeSpread = 3,
     nodeColor = "cluster", 
     hubBorderCol = "gray40",
     cexNodes = 1.8,
     edgeTranspHigh = 20,
     title1 = "Network on genus level", 
     showTitle = TRUE,
     cexTitle = 2.3,
     mar = c(1, 3, 4, 8))

legend(0.7, 1.1, cex = 1.7, title = "estimated correlation:",
       legend = c("+","-"), lty = 1, lwd = 3, col = c("#009900","red"), 
       bty = "n", horiz = TRUE)
```

### Highlight data features

We now color nodes according to their phylum. The sizes of the nodes are scaled by the clr-transformed abundances of the genera.

```{r}
# Generate vector with phylum names for node coloring
phyla <- as.factor(rowData(tse)$phylum)
names(phyla) <- rowData(tse)$genus
length(levels(phyla))
```

`r length(levels(phyla))` colors are needed.

```{r network_plot_single_phylum, fig.width=15, fig.height=10}
# Color vector
colvec <- c("cyan",  "red", "blue3", "lawngreen")

plot(spring_netprops,
     repulsion = 0.98,
     rmSingles = TRUE,
     shortenLabels = "intelligent",
     labelScale = FALSE,
     nodeSize = "clr",
     nodeColor = "feature", 
     featVecCol = phyla, 
     colorVec =  colvec,
     highlightHubs = FALSE,
     cexNodes = 1.8,
     edgeTranspHigh = 20,
     title1 = "Network on genus level", 
     showTitle = TRUE,
     cexTitle = 2.3,
     mar = c(1, 10, 4, 6))

# Add legends
legend(0.7, 1.1, cex = 1.7, title = "estimated correlation:",
       legend = c("+","-"), lty = 1, lwd = 3, col = c("#009900","red"), 
       bty = "n", horiz = TRUE)

# Colors used in the legend should be equally transparent as in the plot
col_transp <- colToTransp(colvec, 60)

legend(-1.8, 1.1, cex = 1.7, pt.cex = 2.5, title = "Phylum:", 
       legend=levels(phyla), col = col_transp, bty = "n", pch = 16) 
```

**A few things to observe:**

-   Genera belonging to the same phylum tend to cluster together, though not perfectly.
-   Genera with a low total count play a rather unimportant role in the network, i.e., they have a low centrality.
-   There is only one negative edge in the network. This edge is between two clusters, as expected when using the "signed" transformation.

```{r, eval=FALSE, echo=FALSE}
save(se_mb_est, sparcc_cor, spring_net, 
     file = "general/network_data/networks.RData")
```

## Which method(s) to choose?

Throughout all the steps from primary data to potentially significant network features, there is a variety of methods and parameters to choose from. However, there is no general consensus in the community on the "right" way to estimate and analyze microbial networks. In the absence of a "best method" for inferring and analyzing microbial networks, researchers may be tempted to try different methods and report only the optimal results or those that fit some prior knowledge. This carries the risk of "overfitting" the analysis to the existing data so that the results are not replicable for new data [@ullmann2023over].

Therefore, the selection of the workflow building blocks should be set up once and independently of any hypothesis about the data, thus avoiding the fallacy of starting to "fish" for results that best fit a previously formulated hypothesis. For example, one should ask prior to the analysis whether correlation or conditional dependence as a measure of association better fits the research question and choose the method accordingly. Another example is the choice of transformation from estimated association to dissimilarity (i.e., "signed" or "unsigned"), which completely changes the interpretation and characteristics of the network. This choice should be made based on the research question before starting the analysis.
