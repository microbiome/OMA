# Differential abundance {#differential-abundance}
```{r setup, echo=FALSE, results="asis"}
library(rebook)
chapterPreamble()
```


## Differential abundance analysis


This section provides an overview and examples of *differential
abundance analysis (DAA)* based on one of the [openly available
datasets](https://microbiome.github.io/mia/reference/mia-datasets.html)
in mia to illustrate how to perform differential abundance analysis
(DAA). DAA identifies differences in the abundances of individual
taxonomic groups between two or more groups (e.g. treatment vs
control). This can be performed at any phylogenetic level.

We perform DAA to identify biomarkers and/or gain understanding of a
complex system by looking at its isolated components. For example,
identifying that a bacterial taxon is different between a patient
group with disease *X* vs a healthy control group might lead to
important insights into the pathophysiology. Changes in the microbiota
might be cause or a consequence of a disease. Either way, it can
help to understand the system as a whole. Be aware that this approach
has also been criticized recently [@Quinn2021].


### Examples and tools

Due to the complex data characteristics of microbiome sequencing data,
differential abundance analysis of microbiome data faces many
statistical challenges [@Yang2022], including:
  
- Highly variable. The abundance of a specific taxon could range over
  several orders of magnitude.
  
- Zero-inflated. In a typical microbiome dataset, more than 70% of the
  values are zeros. Zeros could be due to either physical absence
  (structural zeros) or insufficient sampling effort (sampling zeros).
  
- Compositional. Increase or decrease in the (absolute) abundance of
  one taxon at the sampling site will lead to apparent changes in the
  relative abundances of other taxa in the sample.

As summarized in @Yang2022, to address the above statistical
chanllenegs:

- Over-dispersed count models has been proposed to address zero
  inflation, such as the negative binomial model used by edgeR
  [@Chen2016] and DESeq2 [@Love2014], the beta-binomial model used by
  corncorb [@Martin2021].

- Zero-inflated mixture models has aslo been proposed to address zero
  inflation, such as zero-inflated log-normal/normal mixture model
  used by metagenomeSeq [@Paulson2017] and RAIDA [@Sohn2015],
  zero-inflated beta-binomial model used by ZIBB [@ZIBB2018], and
  zero-inflated negative binomial model used by Omnibus
  [@Omnibus2018].

- Bayesian methods have been used to impute the zeros for methods
  working on proportion data, accounting for sampling variability and
  sequencing depth variation. Examples include ALDEx2 [@Gloor2016] and
  eBay [@Liu2020].

- Other methods use the pseudo-count approach to impute the zeros,
  such as MaAsLin2 [@Mallick2020] and ANCOMBC [@ancombc2020].

- Different strategies have been used to address compositional
  effects, including:

  - Robust normalization. For example, trimmed mean of M-values (TMM)
    normalization used by edgeR, relative log expression (RLE)
    normalization used by DESeq2 [@Love2014], cumulative sum scaling
    (CSS) normalization used by metagenomeSeq, centered log-ratio
    transformation (CLR) normalization used by ALDEx2 [@Gloor2016] and
    geometric mean of pairwise ratios (GMPR) normalization used by
    Omnibus [@Omnibus2018]. Wrench normalization [@Kumar2018] corrects
    the compositional bias by an empirical Bayes approach, which has
    been recommended in metagenomeSeq [@Paulson2017] tutorial.
  
  - Reference taxa approach used by DACOMP [@Brill2019] and RAIDA [@Sohn2015].
  
  - Analyzing the pattern of pairwise log ratios, such as ANCOM [@Mandal2015].
  
  - Bias-correction used by ANCOMBC [@ancombc2020].

The most popular tools, without going into evaluating whether or not
they perform well for this task, are:

- ALDEx2 [@Gloor2016] 
- ANCOMBC [@ancombc2020]
- corncob [@Martin2021]
- DESeq2 [@Love2014] 
- edgeR [@Chen2016]
- lefser [@Khlebrodova2021]
- MaAsLin2 [@Mallick2020]
- metagenomeSeq [@Paulson2017]
- limma [@Ritchie2015]
- LinDA [@Zhou2022]
- ZicoSeq [@Yang2022]
- LDM [@Hu2020]
- RAIDA [@Sohn2015]
- DACOMP [@Brill2019]
- Omnibus [@Omnibus2018]
- eBay [@Liu2020]
- ZINQ [@Ling2021]
- ANCOM [@Mandal2015]
- fastANCOM [@fastANCOM2022]
- [t-test](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/t.test)  
- [Wilcoxon test](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/wilcox.test)  


We recommend to have a look at @Nearing2022 who compared all these
listed methods across 38 different datasets. Because different methods
use different approaches (parametric vs non-parametric, different
normalization techiniques, assumptions etc.), results can differ
between methods.  Unfortunately, as @Nearing2022 point out, they can
differ substantially. Also, more recently @Yang2022 comprehensively
evaluated these methods via a Semi-parametric framework and 106 real
datasets. @Yang2022 also pointed out, different DAA tools could
sometimes produce quite discordant results, opening to the possibility
of cherry-picking the tool in favor of oneâ€™s own
hypothesis. Therefore, it is highly recommended to pick several
methods to get an idea about how robust and potentially reproducible
your findings are depending on the method. In this section we
demonstrate 4 methods that can be recommended based on recent
literature (ANCOM-BC [@ancombc2020], ALDEx2 [@Gloor2016], Maaslin2
[@Mallick2020], LinDA [@Zhou2022] and ZicoSeq [@Yang2022]) and we will
compare the results between them.

Note that the purpose of this section is to show how to perform DAA in
R, not how to correctly do causal inference. Depending on your
experimental setup and your theory, you must determine how to specify
any model exactly.  E.g., there might be confounding factors that
might drive (the absence of) differences between the shown groups that
we ignore here for simplicity. Or your dataset is repeated sampling
design, matched-pair design or the general longitudianl design.
However, we will show how you could include covariates in those
models.  Furthermore, we picked a dataset that merely has microbial
abundances in a TSE object as well as a grouping variable in the
sample data. We simplify the analysis by only including 2 of the 3
groups.


```{r load-pkg-data}
library(mia)
library(patchwork)
library(tidySummarizedExperiment)
library(knitr)
library(tidyverse)
library(ALDEx2)
library(Maaslin2)
library(MicrobiomeStat)
library(ANCOMBC)
library(GUniFrac)

# set random seed because some tools can randomly vary and then produce 
# different results:
set.seed(13253)

# we use a demo dataset and restrict it to two geo locations
# for easy illustration
data(peerj13075)
tse0 <- peerj13075
tse0 <- tse0[ ,tse0$Geographical_location %in% c("Pune", "Nashik")]
# Let us make this a factor
tse0$Geographical_location <- factor(tse0$Geographical_location)

# how many observations do we have per group?
as.data.frame(colData(tse0)) %>% 
count(Geographical_location) %>%
  kable()
```

### Prevalence Filtering 

Before we jump to our analyses, we may want to perform some data
manipulation.

Let us here do aggregation to genus level, add relative abundance
assay, and perform prevalence filtering.

```{r datasetup}
tse <- agglomerateByRank(tse0, rank = "genus") %>%
       transformCounts(assay.type = "counts",
                       method = "relabundance",
		       MARGIN = "samples") %>%
       # subset based on the relative abundance assay		       
       subsetByPrevalentTaxa(detection = 0,
                             prevalence = 10/100,
			     assay.type = "relabundance")

# Add also clr abundances
tse <- transformCounts(tse, method="clr", pseudocount=1) # not bale to run
```

Regarding prevalence filtering, @Nearing2022 found that applying a 10%
threshold for the prevalence of the taxa generally resulted in more
robust results. Some tools have builtin arguments for that. By
applying the threshold to our input data, we can make sure it is
applied for all tools. 



### ALDEx2

In this section, we will show how to perform a simple ALDEx2 analysis. 
If you wanted to pick a single method, this method could be recommended to use.
According to the developers experience, it tends to identify the common
features identified by other methods. This statement is in line with a recent
independent evaluation by @Nearing2022.  
Please also have a look at the more extensive 
[vignette](https://bioconductor.org/packages/release/bioc/vignettes/ALDEx2/inst/doc/ALDEx2_vignette.html) 
that covers this flexible tool in more depth. ALDEx2 estimates technical
variation within each sample per taxon by utilizing the Dirichlet distribution.
It furthermore applies the centered-log-ratio transformation (or closely
related log-ratio transforms). Depending on the experimental setup, it will
perform a two sample Welch's T-test and Wilcoxon-test or a one-way ANOVA and
Kruskal-Wallis-test. For more complex study designs, there is a possibility to 
utilize the `glm` functionality within ALDEx2. The Benjamini-Hochberg procedure
is applied in any case to correct for multiple testing. Below we show a simple
example that illustrates the workflow.


```{r, aldex2, eval=TRUE}
# Generate Monte Carlo samples of the Dirichlet distribution for each sample.
# Convert each instance using the centered log-ratio transform.
# This is the input for all further analyses.
set.seed(254)
x <- aldex.clr(assay(tse), tse$Geographical_location)     
```


The t-test:

```{r, aldex2_ttest, eval=TRUE}
# calculates expected values of the Welch's t-test and Wilcoxon rank
# test on the data returned by aldex.clr
x_tt <- aldex.ttest(x, paired.test = FALSE, verbose = FALSE)
```


Effect sizes:

```{r, aldex2_efs, eval=TRUE}
# determines the median clr abundance of the feature in all samples and in
# groups, the median difference between the two groups, the median variation
# within each group and the effect size, which is the median of the ratio
# of the between group difference and the larger of the variance within groups
x_effect <- aldex.effect(x, CI = TRUE, verbose = FALSE)

# combine all outputs 
aldex_out <- data.frame(x_tt, x_effect)
```

Now, we can create a so called Bland-Altman or MA plot (left). It shows the
association between the relative abundance and the magnitude of the difference
per sample. Next to that, we can also create a plot that shows the dispersion
on the x-axis instead of log-ratio abundance. Red dots represent genera that are
differentially abundant ($q \leq 0.1$) between the 2 groups. Black points are
rare taxa and grey ones are abundant taxa. The dashed line represent an effect
size of 1. See @Gloor2016 to learn more about these plots.

```{r, eval=TRUE}
par(mfrow = c(1, 2))
  aldex.plot(
    aldex_out, 
    type = "MA", 
    test = "welch", 
    xlab = "Log-ratio abundance",
    ylab = "Difference",
    cutoff = 0.05
  )
  aldex.plot(
    aldex_out, 
    type = "MW", 
    test = "welch",
    xlab = "Dispersion",
    ylab = "Difference",
    cutoff = 0.05
  )
```

The evaluation as differential abundant in above plots is based on the
corrected p-value. According to the ALDEx2 developers, the safest
approach is to identify those features where the 95% CI of the effect
size does not cross 0. As we can see in below table, this is not the
case for any of the identified genera (see overlap column, which
indicates the proportion of overlap). Also, the authors recommend to
focus on effect sizes and CIs rather than interpreting the p-value. To
keep the comparison simple, we will here use the p-value as decision
criterion. But please be aware that the effect size together with the
CI is a better answer to the question we are typically interested in
(see also [this
article](https://www.nature.com/articles/d41586-019-00857-9)).


```{r, eval=TRUE}
rownames_to_column(aldex_out, "genus") %>%
  filter(wi.eBH <= 0.05)  %>% # here we chose the wilcoxon output rather than tt
  dplyr::select(genus, we.eBH, wi.eBH, effect, overlap) %>%
  kable()
```

### ANCOM-BC

The analysis of composition of microbiomes with bias correction
(ANCOM-BC) [@ancombc2020] is a recently developed method for differential
abundance testing. It is based on an earlier published approach
[@Mandal2015].  The previous version of ANCOM was among the methods
that produced the most consistent results and is probably a
conservative approach [@Nearing2022].  However, the new ANCOM-BC
method operates quite differently compared to the former ANCOM method.

As the only method, ANCOM-BC incorporates the so called *sampling
fraction* into the model. The latter term could be empirically
estimated by the ratio of the library size to the microbial
load. According to the authors, variations in this sampling fraction
would bias differential abundance analyses if ignored.  Furthermore,
this method provides p-values and confidence intervals for each
taxon. It also controls the FDR and it is computationally simple to
implement.

Note that the original method was implemented in the `ancombc()` function (see 
[extended tutorial](https://www.bioconductor.org/packages/release/bioc/vignettes/ANCOMBC/inst/doc/ANCOMBC.html)).
The method has since then been updated and new features have been added to enable
multi-group comparisons and repeated measurements among other improvements. 
We do not cover the more advanced features of ANCOMBC in this tutorial 
as these features are documented in detail in this 
[tutorial](https://www.bioconductor.org/packages/release/bioc/vignettes/ANCOMBC/inst/doc/ANCOMBC2.html).

We now proceed with a simple example.  First, we specify a formula. In this 
formula, other covariates could potentially be included to adjust for 
confounding. We show this further below. Again, please make sure to check the 
[function documentation](https://rdrr.io/github/FrederickHuangLin/ANCOMBC/man/ancombc.html)
as well as the linked tutorials to learn about the additional arguments 
that we specify.


```{r ancombc2, warning = FALSE, eval=TRUE}
# Run ANCOM-BC 
out <- ancombc2(
  data = tse,
  assay_name = "counts", 
  tax_level = "genus", 
  fix_formula = "Geographical_location", 
  p_adj_method = "fdr", 
  lib_cut = 0,
  prv_cut = 0,
  group = "Geographical_location", 
  struc_zero = TRUE, 
  neg_lb = TRUE,
  alpha = 0.05, 
  global = TRUE # multi group comparison will be deactivated automatically 
)
```

```{r ancombc2b, warning = FALSE, eval=TRUE}
# store the FDR adjusted results [test on v2.0.3] 
ancombc_result <- cbind.data.frame(taxid = out$res$taxon,
                       ancombc = as.vector(out$res$q_Geographical_locationPune))
```


```{r ancombc2c, warning = FALSE, eval=TRUE}
# store the FDR adjusted results [test on v1.2.2] 
ancombc_result <- out$res$q_val %>% rownames_to_column('taxid') %>%
                                    dplyr::rename(ancombc = 2)
```

The object `out` contains all model output. Again, see the 
[documentation of the function](https://rdrr.io/github/FrederickHuangLin/ANCOMBC/man/ancombc.html) 
under **Value** for an explanation of all the output objects. Our question
whether taxa are differentially abundant can be answered by looking at the
`res` object, which now contains dataframes with the coefficients, 
standard errors, p-values and q-values. Conveniently, there is a dataframe
`diff_abn`. Here, for each taxon it is indicated whether it is differentially
abundant between the groups (again, keep in mind that the answer is not 
black-white). Below we show the first 6 entries of this dataframe.

```{r ancom_kable, eval=FALSE}
kable(head(ancombc_result))
```



### MaAsLin2 

Let us next illustrate MaAsLin2 [@Mallick2020]. This method is based on
generalized linear models and flexible for different study designs
and covariate structures. For details, check their
[Biobakery tutorial](https://github.com/biobakery/biobakery/wiki/maaslin2).

```{r maaslin2, results = "hide", eval=TRUE}
# maaslin expects features as columns and samples as rows 
# for both the abundance table as well as metadata 

# We can specify different GLMs/normalizations/transforms.
# Let us use similar settings as in Nearing et al. (2021):
maaslin2_out <- Maaslin2(
  t(assay(tse)),
  data.frame(colData(tse)),
  output = "DAA example",
  transform = "AST",
  fixed_effects = "Geographical_location",
  # random_effects = c(...), # you can also fit MLM by specifying random effects
  # specifying a ref is especially important if you have more than 2 levels
  reference = "Geographical_location,Pune",  
  normalization = "TSS",
  standardize = FALSE,
  min_prevalence = 0 # prev filterin already done
)
```

Which genera are identified as differentially abundant? (leave out "head" to see all).

```{r, maaslin2kable, eval=FALSE}
kable(head(filter(maaslin2_out$results, qval <= 0.05)))
```

This will create a folder that is called like in the output specified
above. It contains also figures to visualize difference between
significant taxa.


### LinDA 

Lastly, we cover linear models for differential abundance analysis of
microbiome compositional data (@Zhou2022). This is very similar to
ANCOMBC with few differences: 1) LinDA correct for the compositional
bias differently using the mode of all regression coefficients. 2) it
is faster (100x-1000x than ANCOMBC and according to the authors); 3)
it supports hierarchical models. The latest ANCOMBC versions are also
supporting hierarchical models. Nevertheless, LinDA seems a promising
tool that achieves a very good power/fdr trade-off together with
ANCOMBC according to the review. The speed improvements might make it
critical especially for datasets that have higher sample or feature
set sizes.


```{r linda, eval=TRUE}
meta <- as.data.frame(colData(tse)) %>% dplyr::select(Geographical_location)
linda.res <- linda(
  as.data.frame(assay(tse)), 
  meta, 
  formula = '~Geographical_location', 
  alpha = 0.05, 
  prev.filter = 0, 
  mean.abund.filter = 0)

linda_out <- linda.res$output$Geographical_locationPune
```

```{r linda2, eval=FALSE}
# to scan the table for genera where H0 could be rejected:
kable(head(filter(as.data.frame(linda_out), reject)))
```

### ZicoSeq

Subsequently, we add a linear model and permutation-based method, see
details at [tutorial](https://cran.r-project.org/web/packages/GUniFrac/vignettes/ZicoSeq.html).

This approach has been assessed to exhibit high power and a low false
discovery rate, which has the following components:

  1. Winsorization to decrease the influence of outliers;
  
  1. Posterior sampling based on a beta mixture prior to address
  sampling variability and zero inflation;
  
  1. Reference-based multiple-stage normalization to address
  compositional effects;


```{r ZicoSeq, eval=TRUE}
set.seed(123)
meta <- as.data.frame(colData(tse))
zicoseq.obj <- GUniFrac::ZicoSeq(meta.dat = meta, 
                                 feature.dat = as.matrix(assay(tse)),
                                 grp.name = 'Geographical_location',
                                 adj.name = NULL, 
                                 feature.dat.type = 'count',
                                 prev.filter = 0,
                                 perm.no = 999,
                                 mean.abund.filter = 0,
                                 max.abund.filter = 0,
                                 return.feature.dat = T)
zicoseq_out <- cbind.data.frame(p.raw=zicoseq.obj$p.raw, p.adj.fdr=zicoseq.obj$p.adj.fdr) 


```{r ZicoSeq_kable, eval=FALSE}
kable(head(filter(zicoseq_out, p.adj.fdr<0.05)))
```


```{r ZicoSeqplot, eval=TRUE}
## x-axis is the effect size: R2 * direction of coefficient
ZicoSeq.plot(ZicoSeq.obj = zicoseq.obj,
             meta.dat = meta,
	     pvalue.type ='p.adj.fdr')
```



### Comparison of the methods

When we compare the methods in the context of a research question, we could
look at e.g. at whether they agree based on the applied decision criterion
(e.g. adjusted p value <= 0.05). That is what we illustrate here. First we will 
look at how many taxa were identified by each method to begin with. In the next
step we will look at the intersection of identified taxa. To achieve that, we
first create a dataframe that summarises the decision criterion for each method
and shows a score from 0 to 3 indicating how many methods agreed on a particular
taxon.

```{r comparison, eval=TRUE}
aldex_result <- rownames_to_column(aldex_out, "taxid") %>% dplyr::select(taxid, aldex2 = wi.eBH)
summ <- full_join(aldex_result, ancombc_result, by = "taxid") %>%
  full_join(
    dplyr::select(maaslin2_out$results, taxid = feature, maaslin2 = qval), 
    by = "taxid") %>%
    full_join(linda_out %>% rename(LinDA=padj) %>% dplyr::select(LinDA)%>% rownames_to_column('taxid') ) %>%
  full_join(zicoseq_out %>% dplyr::select(p.adj.fdr) %>% rename(ZicoSeq = p.adj.fdr) %>% rownames_to_column('taxid')) %>%
  mutate(
    across(c(aldex2: ZicoSeq), ~ .x <= 0.05),
    # the following line would be necessary without prevalence filtering 
    # as some methods output NA
    #across(-taxid, function(x) ifelse(is.na(x), FALSE, x)),
    score = rowSums(across(c(aldex2, ancombc, maaslin2, LinDA, ZicoSeq)))
  )

# Mark all NAs as FALSE
summ[is.na(summ)] <- FALSE

# This is how it looks like:
kable(head(summ))
```

Now we can answer our questions:

```{r, eval=FALSE}
# how many genera were identified by each method?
summarise(summ, across(where(is.logical), sum)) %>%
  kable()
# which genera are identified by all methods?
filter(summ, score == 5) %>% kable()
```

We see that each method identified at least some genera as
differentially abundant. Many of those that were identified by ALDEx2,
were also identified by the other methods. Let us plot the data for
any method or for those taxa that were identified by all methods.


```{r, daplotting, eval=TRUE, fig.width=20,fig.height=4}
# Create a jittered boxplot for each genus 
assay.type <- "relabundance"
plot_data <- data.frame(t(assay(tse, assay.type)))
plot_data$Geographical_location <- tse$Geographical_location
plots <- pmap(dplyr::select(summ, taxid, score), function(taxid, score) {
  ggplot(plot_data, aes_string(x="Geographical_location", y=taxid)) +
    geom_boxplot(outlier.shape = NA) +
    geom_jitter(width = 0.2) +
    # scale_y_log10() + # log trans will cause 0 values missing 
    scale_y_sqrt() + 
    labs(title=glue::glue("{taxid}"),
         x="",
	 y=glue::glue("Abundance ({assay.type})")) +    
    theme_bw() +
    theme(legend.position = "none")
})

# now we can show just those genera that have at least score 5 (or 4
# or 3 or 2 or 1)

robust_plots <- plots[summ$score == 4 & !is.na(summ$score)] 

# to display this nicely in the book we use patchwork here:
# (we show first ones)
robust_plots[[1]] + 
  robust_plots[[2]] + 
  robust_plots[[3]] + 
  robust_plots[[4]] +
  robust_plots[[5]] +
  plot_layout(nrow = 1)
  
# or if we have most trust in any specific method we can show genera that 
# are differentially abundant according to that method and then look in the
# title how many methods also identified it (we only show first 6 here):
ancombc_plots <- plots[summ$ancombc & !is.na(summ$score)] 
ancombc_plots[[1]] + 
  ancombc_plots[[2]] + 
  ancombc_plots[[3]] + 
  ancombc_plots[[4]] +
  ancombc_plots[[5]] +
  ancombc_plots[[6]] +
  plot_layout(nrow = 1)
```



### Confounding variables

Confounders are common in experimental research. In general, these can be
classified into 3 types:

- Biological confounder, such as age, sex, etc. 

- Technical confounder that caused by data collection, storage, DNA
  extraction, sequencing process, etc.

- Confounder caused by experimental models, such as cage effect,
  sample background, etc.

Adjusting confounder is necessary and important to reach a valid
conclusion. To perform causal inference, it is crucial that the method
is able to include covariates in the model. This is not possible with
e.g. the Wilcoxon test. Other methods such as DESeq2, edgeR, ANCOMBC,
LDM, Aldex2, Corncob, MaAsLin2, ZicoSeq, fastANCOM and ZINQ allow
this. Below we show how to include a confounder/covariate in ANCOMBC,
LinDA and ZicoSeq.


#### ANCOMBC

```{r ancombc_adj, eval=TRUE}
# perform the analysis 
ancombc_cov <- ancombc2(
  data = tse,
  assay_name = "counts",
  tax_level = "genus",
  fix_formula = "Geographical_location + Age", 
  p_adj_method = "fdr", 
  lib_cut = 0, 
  group = "Geographical_location", 
  struc_zero = TRUE, 
  neg_lb = TRUE,
  alpha = 0.05, 
  global = TRUE # multi group comparison will be deactivated automatically 
)
# now the model answers the question: holding Age constant, are 
# bacterial taxa differentially abundant? Or, if that is of interest,
# holding phenotype constant, is Age associated with bacterial abundance?
# Again we only show the first 6 entries.
```

```{r ancombc_adj2, eval=FALSE}
kable(head(ancombc_cov$res$q_val))
```

#### LinDA

```{r linda_adj, eval=TRUE}
otu.tab <- as.data.frame(assay(tse))
meta <- as.data.frame(colData(tse))
linda_cov <- linda(
  otu.tab, 
  meta, 
  formula = '~ Geographical_location + Age', 
  alpha = 0.05, 
  prev.filter = 0, 
  mean.abund.filter = 0)
linda.res <- linda_cov$output$Geographical_locationPune
```

```{r linda_adj2, eval=FALSE}
kable(head(filter(linda.res, reject==T)))
```



#### ZicoSeq

```{r ZicoSeq_adj, eval=TRUE}
set.seed(123)
zicoseq.obj <- GUniFrac::ZicoSeq(meta.dat = as.data.frame(colData(tse)) , 
                                 feature.dat = as.matrix(assay(tse)),
                                 grp.name = 'Geographical_location',
                                 adj.name = 'Gender', 
                                 feature.dat.type = 'count',
                                 prev.filter = 0,
                                 perm.no = 999,
                                 mean.abund.filter = 0,
                                 max.abund.filter = 0,
                                 return.feature.dat = T)
zicoseq_out <- cbind.data.frame(p.raw=zicoseq.obj$p.raw,
                                p.adj.fdr=zicoseq.obj$p.adj.fdr) 
```

```{r ZicoSeq_adj2, eval=FALSE}
kable(head(filter(zicoseq_out, p.adj.fdr<0.05)))
```



## Tree-based methods

Let us next cover phylogeny-aware methods to perform group-wise
associations.

### Group-wise associations testing based on balances

For testing associations based on balances, check the philr
R/Bioconductor package.


## Session Info {-}

```{r sessionInfo, echo=FALSE, results='asis'}
prettySessionInfo()
```


