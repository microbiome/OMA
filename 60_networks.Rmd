# Network learning and inference {#network-inference}

```{r setup, echo=FALSE, results="asis"}
library(rebook)
chapterPreamble()
```

Learning and analyzing microbial association networks is another common exploratory data analysis approach aimed at understanding the complex interplay of microbial communities in their natural habitat. Microbial networks consist of nodes, representing microbial species or taxa, and edges, expressing their association. The mathematical representation of a network is the adjacency matrix, which has a non-zero entry for each edge in the network.

A typical workflow for estimating a microbial network involves several steps, including data preprocessing, estimating microbial associations, and transforming them into edge weights. The resulting network can be analyzed using local network properties, such as centrality measures, or global measures that describe the overall structure of the network. Network plots provide further insight into the microbial community structure and allow for exploratory analysis of microbial relationships.

Since microbial interactions are likely to change between conditions, such as between healthy individuals and patients, identifying network differences between groups is often an integral secondary analysis step. Differences can be detected visually by plotting the two networks side by side, or quantitatively using differential network analysis tools.

In this section, we go through the complete workflow step by step.

## Typical workflow

```{r echo=FALSE, out.width='100%', fig.cap='The typical input is a $p$ x $n$ dimensional count matrix coming from a sequencing process, where $n$ is the number of samples and $p$ the number of features / ASVs / OTUs. Steps 1 through 6 are explained below. Each matrix resulting from steps 4, 5, and 6 plays a specific role in the final network: The adjacency matrix is used for edge colors, dissimilarity for layout, and similarity for edge weights. In weighted networks, the similarity matrix equals the adjacency matrix.'}
knitr::include_graphics("general/figures/FigureNetworkLearning.png")
```

1.  **Zero replacement:** Since the following steps usually require non-zero entries in the read count matrix, zero counts must be replaced. A simple solution is to add a pseudo count to the data. Other approaches are implemented in the R package [zCompositions](https://cran.r-project.org/web/packages/zCompositions/index.html)
2.  **Normalization:** To avoid compositional effects, the data are normalized using a compositionality aware transformation. A common approach is the centered log-ratio (clr) transformation, which moves the data from a $p$-dimensional simplex to Euclidean space so that standard statistical analysis methods are valid. A variance stabilizing transformation (vst) is also a suitable approach for normalizing microbial count data [@badri2020shrinkage].
3.  **Association estimation:**
    -   **Correlation:** Two popular measures of ecological association are Pearson's correlation coefficient and Spearman's rank correlation coefficient, both of which can be inferred from empirical (sample) covariances. However, in the $p\gg n$ setting, which most microbiome datasets are in, sample covariances and correlations are unreliable because the parameters being estimated are typically underdetermined. One way to improve sample covariance estimates is to assume that the underlying covariance matrix is sparse and use a regularized covariance estimator to implement this structural assumption. The Schäfer-Strimmer shrinkage estimator [@schafer2005shrinkage] is one possible method for estimating a sparse correlation matrix. Other popular methods, especially designed to estimate correlations for compositional data, are SparCC ("Sparse Correlations for Compositional data") by @Friedman2012, CCREPE ("Compositionality Corrected by REnormalization and PErmutation") by @faust2012microbial, and CCLasso ("Correlation inference for Compositional data through Lasso") by @fang2015cclasso. The latter three methods already include a compositionality aware normalization, and SparCC also includes a zero replacement approach.

        **Compositionality aware correlation estimation methods:**

        -   Pearson's correlation coefficient (+ normalization)
        -   Spearman's rank correlation coefficient (+ normalization)
        -   Covariance shrinkage ([corpcor](https://strimmerlab.github.io/software/corpcor/) package) (+ normalization)
        -   SparCC (implemented in [SpiecEasi](https://rdrr.io/github/zdk123/SpiecEasi/man/sparcc.html))
        -   CCREPE ([ccrepe](https://bioconductor.org/packages/release/bioc/html/ccrepe.html) package)
        -   CCLasso ([R code on GitHub](https://github.com/huayingfang/CCLasso))

    -   **Conditional dependence:** Since standard correlations include both direct and indirect dependencies, conditional dependence or partial correlation is often preferred for measuring association. Unlike (marginal) correlation, it expresses the relationship between two features conditioned on all other features in the data set. The approach and R package [SpiecEasi](https://github.com/zdk123/SpiecEasi) ("Sparse InversE Covariance estimation for Ecological Association and Statistical Inference") by @Kurtz2015 is specifically designed for inferring ecological networks from microbiome data and includes two approaches for estimating conditional dependence structures between taxa: Neighborhood Selection (short: MB; introduced by @meinshausen2006high) and (inverse) covariance selection [@friedman2008sparse], which is based on a penalized maximum likelihood approach and is also known as "graphical lasso". Another approach and R package for inferring partial correlations from microbiome data is [SPRING](https://github.com/GraceYoon/SPRING) ("Semi-Parametric Rank-based approach for INference in Graphical model") by @yoon2019microbial. They also use the MB neighborhood selection method, but introduce a novel semi-parametric rank-based approach for sparse partial correlation estimation that can naturally handle the excess of zeros in the data. gCoda [@fang2017gcoda] is another conditional dependence measure based on penalized maximum likelihood estimation. All of the aforementionedconditional dependence measures address the high dimensionality of microbiome data.

        **Compositionality aware measures of conditional dependence / partial correlation:**

        -   [SpiecEasi](https://github.com/zdk123/SpiecEasi) with Meinshausen and Bühlmann (MB) neighborhood selection
        -   [SpiecEasi](https://github.com/zdk123/SpiecEasi) with the graphical lasso (glasso)
        -   gCoda ([R code on GitHub](https://github.com/huayingfang/gCoda))
        -   [SPRING](https://github.com/GraceYoon/SPRING)

    -   **Proportionality:** @lovell2015proportionality introduce proportionality as an alternative measure of pairwise association for compositional data. The idea is that if the relative abundances between two taxa $i$ and $j$ are proportional, then their corresponding absolute abundances are also proportional: $\frac{\omega_i}{m} \propto \frac{\omega_j}{m} \Rightarrow \omega_i \propto \omega_j$, where $m$ is the sum of counts in the sample. It follows that proportionality is identical for the observed (relative) read counts and the true unobserved counts. The proportionality measure proposed by @lovell2015proportionality is based on log-ratio variance $var(log \frac{x_i}{x_j})$, which is zero when $\omega_i$ and $\omega_j$ are perfectly proportional. Proportionality is implemented in the R package [propr](https://github.com/tpq/propr). @badri2020shrinkage extend the proportionality measure to a so-called "shrinkage proportionality estimator". It combines proportionality with the covariance shrinkage approach to obtain consistent association estimates even with small sample sizes.

4.  **Sparsification:** Transforming the estimated associations directly into adjacencies would lead to a dense network where all nodes are connected and only weighted network measures are meaningful. Therefore, the association matrix is usually sparsified to select edges of interest. A common sparsification approach for correlations is thresholding, where correlations with a magnitude below the threshold are set to zero. Another possibility is a statistical test (Student's t-test or permutation test) with the null hypothesis that the correlation is equal to zero. SpiecEasi uses the StARS stability selection approach [@liu2010stability] to decide on an appropriate sparsification level of the inferred conditional dependence graph.

5.  **Transformation into dissimilarity:** A common next step is to simply use the absolute values of the sparsified associations as edge weights. In this way, correlations of high magnitude (both positive and negative) will have a high edge weight. To assign a low edge weight to negatively associated taxa, however, a more complex transformation would be required. Here we follow @vanDongen2012metric to directly transform the sparse associations $r_{ij}^*$ into dissimilarities, which can later be used for shortest path network measures. Depending on the desired handling of negative associations, one of the two proposed transformations should be chosen:

    5a: **"signed":** $d_{ij} = \sqrt{0.5(1-r^*_{ij})}$, where strongly negatively associated taxa have the largest distance and are placed further apart in the network.

    5b: **"unsigned":** $d_{ij} = \sqrt{1-{r_{ij}^*}^2}$, resulting in a small distance between strongly associated taxa (regardless of the sign).

6.  **Transformation into similarity / edge weight:** Finally, the dissimilarities are transformed into similarities by $s_{ij} = 1 - d_{ij}$, which are used as edge weights. Thus, the similarity matrix is equal to the adjacency matrix in a weighted network.

**NetCoMi package:** All of the above steps are also implemented in the R package [NetCoMi](https://github.com/stefpeschel/NetCoMi) [@peschel2021netcomi], which provides functionality for the complete workflow of constructing, analyzing, and comparing networks for microbiome data. A large part of this section, in particular the visualization and comparison of networks, is carried out using NetCoMi.

## Load packages and data

We start by installing `NetCoMi` from GitHub and loading other necessary packages used in this section.

```{r install-pkg, eval=FALSE}
if(!require(NetCoMi)){
  devtools::install_github("stefpeschel/NetCoMi", force = TRUE,
                         dependencies = c("Depends", "Imports", "LinkingTo"),
                         repos = c("https://cloud.r-project.org/",
                                   BiocManager::repositories()))
}
```

```{r load_packages, message=FALSE, warning=FALSE}
library(NetCoMi)
library(igraph)
library(mia)
library(phyloseq)
library(corpcor)
library(pheatmap)
library(grid)
library(gridExtra)
library(RColorBrewer)
```

The PeerJ data set [@potbhare2022skin] is used in this section. It contains skin microbial profiles of 58 subjects.

```{r load_data}
data("peerj13075", package = "mia")

tse0 <- peerj13075
```

```{r, echo=FALSE}
load("general/network_data/networks.RData")
```

## Network learning

### Prevalence Filtering

Before we apply the network learning methods, we perform some preprocessing steps similar to that in section \@ref(differential-abundance):

-   Aggregation to genus level
-   Add relative abundance assay
-   Prevalence filtering (keep genera with prevalence \> 20%)
-   Add assay with clr-transformed abundances

```{r}
# Agglomerate to genus level
tse_genus <- agglomerateByRank(tse0, rank = "genus") 

# Add relative abundances
#debugonce(vegan::decostand)
tse <- transformAssay(tse_genus,
                       assay.type = "counts",
                       method = "relabundance",
                       MARGIN = "samples") 

# Filter by prevalence
tse <- subsetByPrevalentFeatures(tse,
                                 detection = 0,
                                 prevalence = 0.2,
                                 assay.type = "relabundance")


# Add clr-transformed abundances
tse <- transformAssay(tse, method="clr", pseudocount=1)

dim(tse0)
dim(tse)
```

### SparCC correlation

We start by estimating a sparse correlation matrix using SparCC.

```{r, eval=FALSE}
sparcc_cor <- SpiecEasi::sparcc(t(assay(tse, "counts")))$Cor
rownames(sparcc_cor) <- colnames(sparcc_cor) <- rownames(tse)
```

Two threshold values are used to see the effect of sparsification later in the network plot.

```{r}
sparcc_cor03 <- sparcc_cor

# Sparsification (threshold = 0.3)
sparcc_cor03[abs(sparcc_cor03) < 0.3] <- 0

# Compute dissimilarity matrix
sparcc_diss03 <- sqrt(0.5 * (1 - sparcc_cor03))

# Dissimilarities between nodes with zero correlation are set to 1
# (these nodes are unconnected and thus have maximum dissimilarity).
sparcc_diss03[sparcc_cor03 == 0] <- 1

# Compute similarity matrix
sparcc_sim03 <- 1 - sparcc_diss03

# Turn into graph
sparcc_graph03 <- adj2igraph(sparcc_sim03)

# Repeat with threshold = 0.4
sparcc_cor04 <- sparcc_cor
sparcc_cor04[abs(sparcc_cor04) < 0.4] <- 0
sparcc_diss04 <- sqrt(0.5 * (1 - sparcc_cor04))
sparcc_diss04[sparcc_cor04 == 0] <- 1
sparcc_sim04 <- 1 - sparcc_diss04
sparcc_graph04 <- adj2igraph(sparcc_sim04)
```

### Shrinkage proportionality

Since there is no R package implementing the shrinkage proportionality estimator as suggested by [@badri2020shrinkage], we use the `rho_shrink_est()` function provided in the GitHub repository associated with the paper. The function is slightly modified to expect normalized counts as input.

```{r}
# norm_counts: clr-transformed count matrix with samples in rows
rho_shrink_est <- function(norm_counts, ...) {
  shrunk_cov <- cov.shrink(norm_counts, ...)
  p <- ncol(norm_counts)
  J <- matrix(rep(diag(shrunk_cov), p), p)
  rho <- 2 * shrunk_cov / (J + t(J))
  (rho + t(rho)) / 2
}
```

```{r}
# Apply the shrinkage proportionality estimator to the clr-transformed counts
prop_est <- as(rho_shrink_est(t(assay(tse, "clr"))), "matrix")
```

A threshold of 0.4 is used to sparsify the estimated proportionality matrix.

```{r}
# Sparsification
prop_est[abs(prop_est) < 0.4] <- 0

# Compute dissimilarity matrix
prop_diss <- sqrt(0.5 * (1 - prop_est))

# Dissimilarities between nodes with zero correlation are set to 1
# (these nodes are unconnected and thus have maximum dissimilarity).
prop_diss[prop_est == 0] <- 1

# Compute similarity matrix
prop_sim <- 1 - prop_diss

# Turn into graph
prop_graph <- adj2igraph(prop_sim)
```

### SpiecEasi - MB

This third example estimates partial correlations using the MB approach implemented in `SPIEC-EASI`.

```{r}
# Extract the count matrix, which spiec.easi needs as input
counts <- t(assay(tse, "counts"))
```

```{r, eval=FALSE}
set.seed(13075)
se_mb_est <- spiec.easi(counts, method = 'mb', nlambda = 20, 
                        pulsar.params = list(rep.num = 20))
```

We store the partial correlations corresponding to the StARS-optimal lambda and turn them into an `igraph` object.

```{r}
# Get optimal matrix with partial correlations
se_mb_cor <- as.matrix(getOptBeta(se_mb_est))
se_mb_cor <- as.matrix(symBeta(se_mb_cor))
rownames(se_mb_cor) <- colnames(se_mb_cor) <- rownames(tse)
diag(se_mb_cor) <- 1

# Transform into similarity values
se_mb_diss <- sqrt(0.5 * (1 - se_mb_cor))
se_mb_diss[se_mb_cor == 0] <- 1
se_mb_sim <- 1 - se_mb_diss

# Create igraph object
se_mb_graph <- adj2igraph(se_mb_sim)
```

The four graph objects can now be plotted side by side using the same layout for all networks.

```{r, fig.height=10, fig.width=10}
# Node sizes
vsize <- colMeans(t(assay(tse, "clr"))) + 6

# Use Fruchterman-Reingold (force-directed) layout
set.seed(13075)
lay_fr <- layout_with_fr(se_mb_graph)

par(mfrow = c(2,2))
plot(sparcc_graph03, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "SparCC (thresh 0.3)")
plot(sparcc_graph04, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "SparCC (thresh 0.4)")
plot(prop_graph, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "Shrinkage proportionality\n(thresh 0.4)")
plot(se_mb_graph, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "SpiecEasi (MB)")
```

The density of SparCC (threshold 0.4), proportionality and SpiecEasi is comparable, while the correlation network with threshold 0.3 is much denser. However, there are edges in the proportionality and SpiecEasi networks that are not present in the two correlation networks. The SpiecEasi network has less highly connected nodes than the other three networks, but more nodes with one or two connections.

We will look at the degree distribution later to quantify these observations.

### NetCoMi - SPRING {#netconstruct-netcomi}

Here, we use NetCoMi with the SPRING approach to learn a conditional dependence graph.

NetCoMi consists of three main functions: `netConstruct` for network construction, `netAnalyze` for network analysis, and `netCompare` for network comparison. We start with `netConstruct`. For each step of the workflow shown at the beginning of this section, the function offers a variety of approaches to choose from.

To demonstrate how taxa are filtered with `netConstruct`, we use the unfiltered `tse` object, which has been agglomerated to genus level. The filtering is the same as before: Taxa occurring in less than 20% of the samples are removed.

```{r netcomi_net_single, eval=FALSE}
spring_net <- netConstruct(tse_genus,
                           taxRank = "genus",
                           filtTax = "numbSamp",
                           filtTaxPar = list(numbSamp = 0.2),
                           measure = "spring",
                           measurePar = list(nlambda = 20, 
                                             rep.num = 20,
                                             thresh = 0.05,
                                             Rmethod = "approx"),
                           sparsMethod = "none", 
                           dissFunc = "signed",
                           seed = 13075)
```

`netConstruct` returns an object of the class `microNet`, which contains all matrices generated during network construction. These are the basis for the network analysis.

The object also contains an edge list, giving each edge's estimated association, dissimilarity, and adjacency. Let's take a quick look at the edges with the highest and lowest edge weights:

```{r}
edgelist <- spring_net$edgelist1[order(spring_net$edgelist1$adja, decreasing = TRUE), ]
head(edgelist)
tail(edgelist)
```

To compare all three network learning approaches considered in this section, we again generate some basic network plots using the igraph package.

```{r, fig.height=4, fig.width=10}
spring_graph <- adj2igraph(abs(spring_net$assoEst1))

par(mfrow = c(1,3))
plot(sparcc_graph04, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "SparCC (thresh 0.4)")
plot(se_mb_graph, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "SpiecEasi (MB)")
plot(spring_graph, layout = lay_fr, vertex.size = vsize, 
     vertex.label = NA, main = "NetCoMi (SPRING)")
```

The sparsity level of the two networks generated with SpiecEasi and NetCoMi is comparable, however, there is a considerable amount of edges that are different.

## Network analysis

In the following, we will focus on the SPRING network and compare all previously created networks only when appropriate.

### Network measures with igraph

#### Centrality measures

Centrality measures express the importance of nodes within the network. Common measures are the degree, betweenness, closeness, and eigenvector centrality. They can be computed using the igraph package.

```{r}
deg <- degree(spring_graph)
betw <- betweenness(spring_graph)
close <- closeness(spring_graph)
eigen <- eigen_centrality(spring_graph)$vector

# Create data frame with all centrality values
centr_df <- data.frame(degree = deg, betweenness = betw, closeness = close, 
                        eigen.centr = eigen)
rownames(centr_df) <- rownames(spring_net$adjaMat1)
head(centr_df, 15)
```

#### Scale node sizes by degree

Centrality measures can be visualized in the network plot by scaling the node sizes according to one of these measures. We plot the SparCC, proportionality, MB, and SPRING networks again, but this time scaling node sizes by their degrees. The layout is the same as before.

```{r netplot_degree, fig.width=7, fig.height=7, out.width='80%'}
deg_sparcc <- degree(sparcc_graph04)
deg_prop <- degree(prop_graph)
deg_se_mb <- degree(se_mb_graph)
```

```{r, fig.height=10, fig.width=10}
par(mfrow = c(2,2))
plot(sparcc_graph04, layout = lay_fr, vertex.size = deg_sparcc, 
     vertex.label = NA, main = "SparCC (thresh 0.4)")
plot(prop_graph, layout = lay_fr, vertex.size = deg_prop, 
     vertex.label = NA, main = "Shrinkage proportionality\n(thresh 0.4)")
plot(se_mb_graph, layout = lay_fr, vertex.size = deg_se_mb, 
     vertex.label = NA, main = "SpiecEasi (MB)")
plot(spring_graph, layout = lay_fr, vertex.size = deg, 
     vertex.label = NA, main = "NetCoMi (SPRING)")
```

#### Degree distribution

The degree distribution is another popular measure that expresses the probability distribution of degrees over the entire network. It thus provides insight into the overall network structure. We plot the degree distribution for all four association estimation methods to compare the network structure.

```{r}
dd_sparcc <- degree.distribution(sparcc_graph04)
dd_prop <- degree.distribution(prop_graph)
dd_se_mb <- degree.distribution(se_mb_graph)
dd_spring <- degree.distribution(spring_graph)

ymax <- max(dd_sparcc, dd_prop, dd_se_mb, dd_spring)
xmax <- max(length(dd_sparcc), length(dd_prop), 
            length(dd_se_mb), length(dd_spring))

plot(0:(length(dd_spring)-1), dd_spring, ylim=c(0, ymax), xlim = c(0, xmax),
     type='b',
      ylab="Fraction of nodes", xlab="Degree", main = "Degree Distributions")
abline(h = 0, col = "lightgray")
points(0:(length(dd_sparcc)-1), dd_sparcc, col = "orange", type='b')
points(0:(length(dd_prop)-1), dd_prop, col = "red", type='b')
points(0:(length(dd_se_mb)-1), dd_se_mb, col = "blue", type='b')


legend("topright", 
       c("SparCC", "Proportionality", "SpiecEasi (MB)", "NetCoMi (SPRING)"),
       col=c("orange", "red", "blue", "black"), pch=1, lty=1)
```

The SparCC and shrinkage proportionality networks have a considerably higher proportion of singletons (zero-degree nodes) than the two conditional dependency graphs, but a lower proportion of nodes with degrees between one and four. The MB and SPRING graphs, on the other hand, have a higher proportion of low degree nodes, but no highly connected nodes with a degree greater than ten.

#### Clustered heatmaps

Using the `pheatmap` function, we plot heatmaps of the association matrices for the four association measures. Rows and columns are sorted according to the clusters identified via hierarchical clustering with complete linkage.

For each association measure, we select the 50 nodes with the highest sum of edge weights.

```{r, fig.width=10, fig.height=10}
sel <- names(sort(rowSums(sparcc_cor04), decreasing = TRUE))[1:50]
asso_sparcc <- sparcc_cor04[sel, sel]

sel <- names(sort(rowSums(prop_est), decreasing = TRUE))[1:50]
asso_prop <- prop_est[sel, sel]

sel <- names(sort(rowSums(se_mb_cor), decreasing = TRUE))[1:50]
asso_se_mb <- se_mb_cor[sel, sel]

sel <- names(sort(rowSums(spring_net$assoEst1), decreasing = TRUE))[1:50]
asso_spring <- spring_net$assoEst1[sel, sel]

# Create color sequence
br <- seq(-1, 1, length.out = 30)
col <- colorRampPalette(rev(brewer.pal(n = 10, name = "RdYlBu")))(length(br)-1)
col <- c(head(col, (length(col) / 2)), "white", tail(col, (length(col) / 2)))

# Arguments that are the same for all plots are stored as list
args <- list(color = col, breaks = br, silent = TRUE,
                show_rownames = FALSE, show_colnames = FALSE)

# Call pheatmap()
hm1 <- do.call("pheatmap", c(list(mat = asso_sparcc, 
                                  main = "SparCC (thresh 0.4)"), args))
hm2 <- do.call("pheatmap", c(list(mat = asso_prop, 
                                  main = "Shrinkage proportionality"), args))
hm3 <- do.call("pheatmap", c(list(mat = asso_se_mb, 
                                  main = "SpiecEasi (MB)"), args))
hm4 <- do.call("pheatmap", c(list(mat = asso_spring, 
                                  main = "NetCoMi (SPRING)"), args))

# Layout matrix
lm <- rbind(c(1, 2), c(3, 4))

grid.arrange(grobs = list(hm1[[4]], hm2[[4]], hm3[[4]], hm4[[4]]),
             layout_matrix = lm)
```

The SparCC and the proportionality network show a block structure, where each block corresponds to a cluster. The clusters are less pronounced in the conditional dependence networks. The latter also generally have lower edge weights.

#### Global network measures

Global measures describe the overall network structure. We take a look at three common measures: density, transitivity, and average path length. The values are computed with `igraph` and stored in a matrix.

```{r}
gm <- matrix(NA, nrow = 3, ncol = 4)
dimnames(gm) <- list(c("Density", "Transitivity", "Av.path"), 
                     c("SparCC", "Prop", "MB", "SPRING"))
```

##### Density

Definition: Proportion of present edges from all possible edges.

```{r}
gm["Density", "SparCC"] <- edge_density(sparcc_graph04, loops=F)
gm["Density", "Prop"] <- edge_density(prop_graph, loops=F)
gm["Density", "MB"] <- edge_density(se_mb_graph, loops=F)
gm["Density", "SPRING"] <- edge_density(spring_graph, loops=F)
```

##### Transitivity (clustering coefficient)

Here, we consider only the global clustering coefficient, which is defined as the ratio of triangles to connected triples.

```{r}
gm["Transitivity", "SparCC"] <- transitivity(sparcc_graph04, type="global")
gm["Transitivity", "Prop"] <- transitivity(prop_graph, type="global")
gm["Transitivity", "MB"] <- transitivity(se_mb_graph, type="global")
gm["Transitivity", "SPRING"] <- transitivity(spring_graph, type="global")
```

##### Average path length

Definition: Mean of the shortest distance between each pair of nodes.

```{r}
gm["Av.path", "SparCC"] <- average.path.length(sparcc_graph04)
gm["Av.path", "Prop"] <- average.path.length(prop_graph)
gm["Av.path", "MB"] <- average.path.length(se_mb_graph)
gm["Av.path", "SPRING"] <- average.path.length(spring_graph)
```

```{r}
gm
```

### Network analysis with NetCoMi

The `microNet` object created in section \@ref(netconstruct-netcomi) is now passed to `netAnalyze` to perform network analysis with NetCoMi.

The function computes several common network characteristics such as centrality measures, cluster assignment, the graphlet correlation matrix, as well as global network measures.

The user has several options to choose from, such as a clustering method, how to define hubs, and whether or not to normalize centrality values. See the help page `?netAnalyze` for a description of the arguments.

By default, a heatmap of the Graphlet Correlation Matrix (GCM) is returned (with graphlet correlations in the upper triangle and significance codes resulting from Student's t-test in the lower triangle). See `?calcGCM` and `?testGCM` for details.

```{r netAnalyze_single, fig.width=7, fig.height=7, out.width='75%'}
spring_netprops <- netAnalyze(spring_net, 
                              clustMethod = "cluster_fast_greedy",
                              hubPar = "eigenvector",
                              normDeg = FALSE)
```

```{r summary_single}
summary(spring_netprops, numbNodes = 5)
```

**Interpretation of some findings:**

-   The largest connected component (LCC) has 103 nodes and the network contains 42 singletons.
-   9 clusters have been identified, containing 2 to 16 nodes.
-   There are eight hub nodes detected, which by definition are the nodes with the highest eigenvector centrality.
-   The average path length is 3.81. This means that on average it takes 3.81 steps (step length is the average dissimilarity) to get from one node to another node in the network. Note that the average path length in NetCoMi is defined differently than in the igraph package, which is why the values differ.
-   Low values of edge density and the connectivity measures indicate that the network is rather sparse and not robust to perturbations (i.e., removal of nodes or edges).

## Network visualization

Further insight into the network structure can be gained by visualizing the network, which is done using NetCoMi's plot function. The help page can be accessed via `?plot.microNetProps`.

### Highlight node properties

In the first plot, node colors represent the detected clusters and node sizes are scaled by eigenvector centrality. Hub nodes are highlighted by default. Singletons are not included in the plot. To improve the readability, NetCoMi's "intelligent" label shortening approach is used.

Note that nodes are sometimes placed too close together so that the labels overlap. You may need to play around with the repulsion argument until you find a value where the labels are legible, but also the clusters are still well recognizable.

```{r network_plot_single_cluster, fig.width=13, fig.height=10}
plot(spring_netprops,
     repulsion = 0.98,
     rmSingles = TRUE,
     shortenLabels = "intelligent",
     labelScale = FALSE,
     nodeSize = "eigenvector",
     nodeSizeSpread = 3,
     nodeColor = "cluster", 
     hubBorderCol = "darkgray",
     cexNodes = 1.8,
     edgeTranspHigh = 20,
     title1 = "Network on genus level", 
     showTitle = TRUE,
     cexTitle = 2.3,
     mar = c(1, 3, 4, 8))

legend(0.7, 1.1, cex = 1.7, title = "estimated correlation:",
       legend = c("+","-"), lty = 1, lwd = 3, col = c("#009900","red"), 
       bty = "n", horiz = TRUE)
```

### Highlight data features

We now color nodes according to their phylum. The sizes of the nodes are scaled by the clr-transformed abundances of the genera, since SPRING uses this transformation to account for compositionality.

```{r network_plot_single_phylum, fig.width=15, fig.height=10}
# Get phyla names
taxtab <- as.data.frame(rowData(tse_genus))
phyla <- gsub("p__", "", taxtab[, "phylum"])
names(phyla) <- taxtab[, "genus"]

# Assign low abundant phyla to a "Other" class
low_abundant <- names(table(phyla)[table(phyla) <= 3])
phyla[phyla %in% low_abundant] <- "Other"

# Take a look at the table
table(phyla)
phyla <- as.factor(phyla)

# Define phylum colors
phylcol <- c("cyan", "blue3", "red", "lawngreen", "yellow", "deeppink", "orange")

plot(spring_netprops,
     repulsion = 0.98,
     rmSingles = TRUE,
     shortenLabels = "intelligent",
     labelScale = FALSE,
     nodeSize = "clr",
     nodeColor = "feature", 
     featVecCol = phyla, 
     colorVec =  phylcol,
     hubBorderCol = "darkgray",
     cexNodes = 1.8,
     edgeTranspHigh = 20,
     title1 = "Network on genus level", 
     showTitle = TRUE,
     cexTitle = 2.3,
     mar = c(1, 10, 4, 6))

# Add legends
legend(0.7, 1.1, cex = 1.7, title = "estimated correlation:",
       legend = c("+","-"), lty = 1, lwd = 3, col = c("#009900","red"), 
       bty = "n", horiz = TRUE)

# Colors used in the legend should be equally transparent as in the plot
phylcol_transp <- colToTransp(phylcol, 60)

legend(-1.8, 1.1, cex = 1.7, pt.cex = 2.5, title = "Phylum:", 
       legend=levels(phyla), col = phylcol_transp, bty = "n", pch = 16) 
```

**A few things to observe:**

-   Genera belonging to the same phylum tend to cluster together, though not perfectly.
-   Genera with a low total count play a rather unimportant role in the network, i.e., they have a low centrality.
-   There is only one negative edge in the network. This edge is between two clusters, as expected when using the "signed" transformation.

## Differential network analysis

In addition to the count matrix, the data set also includes information on the subjects' geographical location, gender, age, and diet.

An interesting question to explore now is whether the skin microbiome differs between people whose diets are different.

```{r sample_data}
table(colData(tse_genus)$Diet)
```

We split the data set into two phyloseq objects: One with mixed diet subjects and one with vegetarian subjects. Both subsets have nearly the same sample size and are therefore comparable.

```{r split_data}
tse_mixed <- tse[, colData(tse_genus)$Diet == "Mixed"]
tse_veg <- tse[, colData(tse_genus)$Diet == "Veg"]
```

### Network construction

The approach starts again with network construction and analysis, but this time we pass the two data sets to `netConstruct` to perform a network comparison.

The `rep.num` argument is set to 10 to perform only 10 repetitions in the model selection approach. This speeds up the permutation tests performed later, and has a negligible effect for this data set.

```{r netConstruct_diet, eval=FALSE}
spring_net_diet <- netConstruct(data = tse_mixed,
                                data2 = tse_veg,
                                taxRank = "genus",
                                filtTax = "highestFreq",
                                filtTaxPar = list(highestFreq  = 100),
                                measure = "spring",
                                measurePar = list(nlambda = 20, 
                                                  rep.num = 10,
                                                  thresh = 0.05,
                                                  Rmethod = "approx"),
                                sparsMethod = "none", 
                                dissFunc = "signed",
                                verbose = 3,
                                seed = 13075)
```

### Network analysis

All network measures are now computed for both networks. Also, both GCMs are plotted together with a third matrix containing the differences between the GCMs and significance codes that express if the differences are significantly different from zero.

```{r netAnalyze_diet, fig.width=10, fig.height=10}
spring_netprops_diet <- netAnalyze(spring_net_diet, 
                                   clustMethod = "cluster_fast_greedy",
                                   hubPar = "eigenvector",
                                   normDeg = FALSE)
```

In both of the networks, some correlations are significantly different from zero. However, none of the differences between the correlations are significantly different from zero.

```{r summary_diet}
summary(spring_netprops_diet, groupNames = c("Mixed diet", "Vegetarian"))
```

For each centrality measure, the five nodes with the highest centrality in each group are plotted by default.

We notice some differences in the network properties. Using NetCoMi's `netCompare` function, we will later check if the differences are significant.

### Network plot

The network plots enable a visual comparison. We use the same configuration as before.

```{r network_plot_diet_difflay, fig.width=17, fig.height=8}
plot(spring_netprops_diet,
     repulsion = 0.97,
     rmSingles = TRUE,
     labelScale = FALSE,
     nodeSize = "eigenvector",
     nodeSizeSpread = 2,
     nodeColor = "cluster", 
     sameColThresh = 2,
     hubBorderCol = "darkgray",
     cexNodes = 2,
     edgeTranspHigh = 20,
     title1 = "Mixed diet", 
     title2 = "Vegetarian",
     showTitle = TRUE,
     cexTitle = 2,
     mar = c(1, 4, 4, 4))

# Overlay a transparent plot on which the legend is plotted
par(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 0, 0), new=TRUE)
plot(0, 0, type='n', bty='n', xaxt='n', yaxt='n')

legend(-0.2, -0.9, cex = 1.5, title = "estimated correlation:",
       legend = c("+","-"), lty = 1, lwd = 3, col = c("#009900","red"), 
       bty = "n", horiz = TRUE)
```

The layout is computed separately for each network, making it difficult to visually compare certain associations. It is therefore recommended to use the same layout for both groups (argument `sameLayout`). Instead of simply copying one layout to the other network, we set `layoutGroup` to "union". This ensures that the nodes are placed as optimally as possible for both networks.

```{r network_plot_diet_samelay, fig.width=17, fig.height=8}
plot(spring_netprops_diet,
     sameLayout = TRUE,
     repulsion = 0.96,
     rmSingles = "inboth",
     labelScale = FALSE,
     nodeSize = "eigenvector",
     nodeSizeSpread = 2,
     nodeColor = "cluster", 
     sameColThresh = 2,
     hubBorderCol = "darkgray",
     cexNodes = 2,
     edgeTranspHigh = 20,
     title1 = "Mixed diet", 
     title2 = "Vegetarian",
     showTitle = TRUE,
     cexTitle = 2,
     mar = c(1, 4, 4, 4))

# Add legend
par(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 0, 0), new=TRUE)
plot(0, 0, type='n', bty='n', xaxt='n', yaxt='n')
legend(-0.2, -0.8, cex = 1.7, title = "estimated correlation:",
       legend = c("+","-"), lty = 1, lwd = 3, col = c("#009900","red"), 
       bty = "n", horiz = TRUE)
```

**A few notes:**

-   Differences in the edge weights can now be seen at first glance. For example, Serratia and Citrobacter are strongly associated in the mixed diet group, but not at all in the vegetarian group.
-   Clusters must share at least two nodes (`sameColThresh` argument) to be colored equally in both networks, which is why the color of some clusters differs between the groups.
-   The clustering generally differs markedly. In particular, the cluster assignment of many of the nodes in the largest connected component differs between the two groups.

As before, we also generate a network plot using phylum names to color the nodes and clr-transformed abundances to scale the nodes.

```{r network_plot_diet_phyla, fig.width=17, fig.height=8}
p_diet <- plot(spring_netprops_diet,
               sameLayout = TRUE,
               repulsion = 0.96,
               rmSingles = "inboth",
               labelScale = FALSE,
               nodeSize = "clr",
               nodeColor = "feature", 
               featVecCol = phyla, 
               colorVec =  phylcol,
               sameColThresh = 2,
               hubBorderCol = "darkgray",
               cexNodes = 2,
               edgeTranspHigh = 20,
               title1 = "Mixed diet", 
               title2 = "Vegetarian",
               showTitle = TRUE,
               cexTitle = 2,
               mar = c(1, 4, 4, 4))

# Add legends
par(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 0, 0), new=TRUE)
plot(0, 0, type='n', bty='n', xaxt='n', yaxt='n')
legend(-0.15, -0.8, cex = 1.7, title = "estimated correlation:",
       legend = c("+","-"), lty = 1, lwd = 3, col = c("#009900","red"), 
       bty = "n", horiz = TRUE)
legend(-0.15, 1.3, cex = 1.7, pt.cex = 2.5, title = "Phylum:", 
       legend=levels(phyla), col = phylcol_transp, bty = "n", pch = 16) 
```

### Network comparison {#netcomp}

`netCompare` provides a quantitative comparison of networks using comparative measures such as Jaccard's Index, Adjusted Rand Index, and permutation tests.

To test for statistical significance of differences in network properties, we perform permutation tests with 1000 permutations. Multiple CPU cores are used to save run time. The association matrices that are estimated for all permutations are stored in an external file. They can be used later for differential network construction, or `netCompare` can be rerun with different parameter settings.

```{r netcomp_diet_permute, eval=FALSE}
spring_netcomp_diet <- netCompare(spring_netprops_diet, 
                                  permTest = TRUE,
                                  nPerm = 1000,
                                  cores = 6,
                                  seed = 13075,
                                  storeAssoPerm = TRUE,
                                  fileStoreAssoPerm = "general/network_data/spring_assoPerm",
                                  verbose = TRUE)
```

```{r summary_netcomp_diet}
summary(spring_netcomp_diet, 
        groupNames = c("Mixed diet", "Vegetarian"),
        numbNodes = 5)
```

**Interpreting some results:**

-   Almost all global network properties are significantly different between the groups (for $\alpha=0.1$), thus reflecting the different overall network structure, which could also be seen in the plots.
-   For the Jaccard index of degree, closeness, and eigenvector centrality, the probability P(\>=Jacc) is significant, meaning that the sets of the most central nodes are quite similar for these three measures. The Jaccard index for the hub nodes, on the other hand, is low because the two networks share only one hub node ("Erwinia").
-   As indicated by some similarities in the clusterings, the adjusted Rand index (ARI) of the whole network is significantly different from zero and thus from random clustering. The ARI of the largest connected component (LCC), however, is close to zero due to the different clusterings in the LCC.
-   The two GCD values are significantly different from zero, indicating substantial differences in the overall network structures.
-   All nodes are also tested for having significantly different centrality (only the five nodes with the highest absolute difference are shown in the summary). For $\alpha=0.05$, some nodes have a significantly different closeness centrality, and for $\alpha=0.1$ also a significantly different eigenvector centrality. Most of these nodes have a high centrality in the one group, but are not connected in the other group.

## Differential association analysis

The \`diffnet' function provides statistical tests to assess whether the associations themselves are significantly different between the two groups. NetCoMi also provides a plot function to generate a differential network, where two nodes are connected if they are differentially associated between the groups.

### Differential network

Since we have already computed the permutation association matrices before, we can reuse them here (argument `fileLoadAssoPerm`).

The local false discovery rate is controlled at level 0.2 to account for multiplicity.

```{r diffnet_diet, eval=FALSE, message=FALSE, results='hide'}
spring_diffnet <- diffnet(spring_net_diet,
                          diffMethod = "perm",
                          cores = 5,
                          fileLoadAssoPerm = "general/network_data/spring_assoPerm",
                          adjust = "lfdr")
```

```{r hist_pvals, out.width='80%'}
sum(spring_diffnet$pAdjustVec < 0.05)
sum(spring_diffnet$pvalsVec < 0.05)
```

Some of the unadjusted p-values are below the usual 5% significance level. However, none of the differences remain significant after adjusting for multiple testing so that the differential network would be empty.

To demonstrate the interpretation of a differential network, we set `adjust` to "none", which is actually statistically incorrect.

```{r diffnet_diet_unadjusted, message=FALSE, results='hide'}
spring_diffnet_unadj <- diffnet(spring_net_diet,
                                pvalsVec = spring_diffnet$pvalsVec,
                                diffMethod = "perm",
                                alpha = 0.05,
                                adjust = "none")
```

NetCoMi comes with a plot function to visualize the differential associations.

```{r diffnet_plot, fig.width=20, fig.height=14}
plot(spring_diffnet_unadj, 
     cexLabels = 2,
     cexNodes = 0.7, 
     cexLegend = 2.5,
     cexTitle = 3,
     mar = c(3,2,5,15),
     legendGroupnames = c("Mixed diet", "Vegetarian"),
     legendPos = c(1.2,1.5),
     legendArgs = list(lwd = 4),
     fade = FALSE)
```

Edge colors represent the direction of the associations in the two groups. For example, if two OTUs are positively correlated in the mixed diet group and uncorrelated in the vegetarian group (such as Serratia and Citrobacter), the edge color is dark green.

```{r, eval=FALSE, echo=FALSE}
save(se_mb_est, sparcc_cor, spring_diffnet, spring_net, spring_net_diet, 
     spring_netcomp_diet, file = "general/network_data/networks.RData")
```

## Which method(s) to choose?

Throughout all the steps from primary data to potentially significant network features, there is a variety of methods and parameters to choose from. However, there is no general consensus in the community on the "right" way to estimate and analyze microbial networks. In the absence of a "best method" for inferring and analyzing microbial networks, researchers may be tempted to try different methods and report only the optimal results or those that fit some prior knowledge. This carries the risk of "overfitting" the analysis to the existing data so that the results are not replicable for new data [@ullmann2023over].

Therefore, the selection of the workflow building blocks should be set up once and independently of any hypothesis about the data, thus avoiding the fallacy of starting to "fish" for results that best fit a previously formulated hypothesis. For example, one should ask prior to the analysis whether correlation or conditional dependence as a measure of association better fits the research question and choose the method accordingly. Another example is the choice of transformation from estimated association to dissimilarity (i.e., "signed" or "unsigned"), which completely changes the interpretation and characteristics of the network. This choice should be made based on the research question before starting the analysis.
